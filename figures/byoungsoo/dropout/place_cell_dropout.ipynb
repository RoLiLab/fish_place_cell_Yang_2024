{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e1296-ace2-4fe0-8c6d-de0cee511e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using _Data, _Math\n",
    "using ProgressMeter, PyCall, PyPlot, Images, HDF5,NaNStatistics, Statistics, DSP, Lasso, JLD2, BenchmarkTools, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb580a1-0b63-4c88-82bf-aa5e4ffc0e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pyimport numpy\n",
    "@pyimport scipy.stats as stats\n",
    "@pyimport matplotlib.colors as mpl_colors\n",
    "@pyimport matplotlib.cm as cm \n",
    "@pyimport sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c0ef1-7ba7-410c-8631-50059cb183f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rc_params = PyDict(pyimport(\"matplotlib\")[\"rcParams\"]);\n",
    "rc_params[\"font.sans-serif\"] = [\"Arial\"];\n",
    "rc_params[\"font.size\"] = 7;\n",
    "rc_params[\"lines.linewidth\"] = 1;\n",
    "rc_params[\"lines.markersize\"] = 4;\n",
    "rc_params[\"xtick.major.size\"] = 2;\n",
    "rc_params[\"ytick.major.size\"] = 2;\n",
    "rc_params[\"xtick.major.pad\"] = 2;\n",
    "rc_params[\"ytick.major.pad\"] = 2;\n",
    "# rc_params[\"axes.labelpad\"] = 2;\n",
    "rc_params[\"axes.spines.right\"] = false\n",
    "rc_params[\"axes.spines.top\"] = false\n",
    "\n",
    "cim(img::Matrix{UInt32}) = CairoImageSurface(img, Cairo.FORMAT_RGB24; flipxy = false) \n",
    "cim(img::Matrix{ARGB32}) = cim(reinterpret(UInt32, img))\n",
    "cim(img::Matrix{RGB24}) = cim(reinterpret(UInt32, img))\n",
    "cim(img::Matrix{UInt8}) = cim(Gray.(reinterpret(N0f8, img)))\n",
    "cim(img::Array{UInt8,3}) = cim(RGB24.(reinterpret(N0f8, img[:,:,1]), reinterpret(N0f8, img[:,:,2]), reinterpret(N0f8, img[:,:,3])));downsample(img,n=4) = +([img[i:n:n*div(size(img,1)-1,n), j:n:n*div(size(img,2)-1,n)] for i = 1:n, j = 1:n]...)/(n*n);\n",
    "downsample(img,n=4) = +([img[i:n:n*div(size(img,1)-1,n), j:n:n*div(size(img,2)-1,n)] for i = 1:n, j = 1:n]...)/(n*n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f27f7-812f-430c-9f28-9ea9475bb5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(\"../../../functions/func_map.jl\")\n",
    "include(\"../../../functions/func_stat.jl\")\n",
    "include(\"../../../functions/func_data.jl\")\n",
    "include(\"../../../functions/func_plot.jl\")\n",
    "include(\"../../../functions/utils.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934a0dc-ced6-46ed-8d7b-083af97097b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = \"chuyu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0108a-e39e-400d-942e-e7500304f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_dict = load(\"/home/byoungsoo/Notebooks/project_place_cell/figures/chuyu/figure_data_info.jld2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf487863-ca58-4b0c-b8f7-658ac7c6f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys(data_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c5c92-1eff-49dd-811a-e4dd6650fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_names_ordered = [\n",
    " \"corner_cue_rotation_whole\"\n",
    " \"landmark_removal\"\n",
    " \"boundary_morphing\"\n",
    " \"job_retangular_half_circle_rotation\"\n",
    "\n",
    "    \n",
    " \"hedgehog_rotation_bottom_out\"\n",
    " \"hedgehog_landmark_removal\"\n",
    " \"hedgehog_circle\"\n",
    " \"corner_cue_circle\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "job_names_figure = [\n",
    " \"Chamber rotation\"\n",
    " \"Landmark removal\"\n",
    " \"Wall morphing\"\n",
    "    \n",
    " \"Wall rotation\"\n",
    "    \n",
    " \"No change\"\n",
    " \"Landmark removal\"\n",
    " \"Wall morphing\"\n",
    " \"Wall morphing + \\n Landmark removal\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f17643-b486-4649-b158-549878a39208",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = \"/home/byoungsoo/Notebooks/project_place_cell/figures/output/review_figures/new_dropout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578d965-c44d-46ad-930b-b3628e49da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_all = reduce(vcat, [data_info_dict[job_name] for job_name in keys(data_info_dict)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86921e-dc1e-44a2-a500-b0f316352a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of area overlap in PF\n",
    "function PF_overlap(which_map_1, which_map_2)\n",
    "    PF1 = map_field(which_map_1)\n",
    "    PF2 = map_field(which_map_2)\n",
    "    overlap_PF = PF1.*PF2\n",
    "    union_PF = (PF1.+PF2 .> 0)\n",
    "    \n",
    "    size_unionPF = sum(union_PF)\n",
    "    size_overlapPF = sum(overlap_PF)\n",
    "\n",
    "    overlap_percentage = size_overlapPF/size_unionPF\n",
    "\n",
    "    return overlap_percentage\n",
    "end\n",
    "\n",
    "function PF_corr(which_map_1, which_map_2)\n",
    "    PF1 = map_field(which_map_1)\n",
    "    PF2 = map_field(which_map_2)\n",
    "    union_PF = (PF1.+PF2 .> 0)\n",
    "\n",
    "    PF_map_1 = fill(NaN32, size(which_map_1))\n",
    "    PF_map_1[union_PF] .= which_map_1[union_PF]\n",
    "    PF_map_2 = fill(NaN32, size(which_map_2))\n",
    "    PF_map_2[union_PF] .= which_map_2[union_PF]\n",
    "\n",
    "    return corr_2d_original(PF_map_1,PF_map_2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e63ad4-6e8a-475a-96a7-8d517515d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_dict[\"hedgehog_landmark_removal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92519e-6d21-4da5-8c89-28150b6a0385",
   "metadata": {},
   "outputs": [],
   "source": [
    "morphing_need_data = [data_info_dict[\"boundary_morphing\"];data_info_dict[\"hedgehog_circle\"];data_info_dict[\"corner_cue_circle\"]]\n",
    "morphing_need_filename = [data_info[3] for data_info in morphing_need_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb7511b-cee9-49a2-99ec-cdb49f8ce719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PF overlap\n",
    "fig = figure(figsize=(7,1.5))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "\n",
    "trials_place_cell_1_tog = []\n",
    "trials_place_cell_2_tog = []\n",
    "trials_union_place_cell_tog = []\n",
    "trials_original_PFcor_tog = []\n",
    "trials_original_PFcov_tog = []\n",
    "trials_suffled_PFcov_tog = []\n",
    "trials_PFoverlap_tog = []\n",
    "\n",
    "earlylate_place_cell_1_tog = []\n",
    "earlylate_place_cell_2_tog = []\n",
    "earlylate_union_place_cell_tog = []\n",
    "earlylate_original_PFcor_tog = []\n",
    "earlylate_original_PFcov_tog = []\n",
    "earlylate_suffled_PFcov_tog = []\n",
    "earlylate_PFoverlap_tog = []\n",
    "\n",
    "for (i_job, job_name) in enumerate(job_names_ordered)\n",
    "    data_info_all = data_info_dict[job_name]\n",
    "    job_name = job_names_figure[i_job]\n",
    "    \n",
    "    println(job_name)\n",
    "    println(i_job)\n",
    "    \n",
    "    trials_median_tog = []\n",
    "    earlylate_median_tog = []\n",
    "    \n",
    "    flag = 0\n",
    "    if job_name == \"Chamber rotation\"\n",
    "        flag = 1\n",
    "    end\n",
    "\n",
    "    for which_data in 1:length(data_info_all)\n",
    "        data_info = data_info_all[which_data]\n",
    "    \n",
    "        experiment_filename_1 = data_info[1]\n",
    "        server_1 = data_info[2]\n",
    "    \n",
    "        experiment_filename_2 = data_info[3]\n",
    "        server_2 = data_info[4]\n",
    "        experimenter = data_info[end]\n",
    "\n",
    "        if job_name == \"Chamber rotation\"\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "        ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "        ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "        \n",
    "        ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "        ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "        ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"region_roi_bool.h5\")\n",
    "        file = h5open(info_filename, \"r\")\n",
    "        whether_tel = HDF5.readmmap(file[\"whether_tel\"])\n",
    "        close(file) \n",
    "\n",
    "        all_files = readdir(data_path(ds_save_cy_1))\n",
    "        which_file = [occursin(experiment_filename_1, all_files[i])*occursin(\"A_dF\", all_files[i])*occursin(\"neuron\", all_files[i]) for i in 1:length(all_files)]\n",
    "        @assert(length(all_files[which_file]) == 1)\n",
    "        save_file_name = all_files[which_file][1]\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), save_file_name)\n",
    "        file = h5open(info_filename, \"r\")\n",
    "        place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "        specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "        specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "        specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "        stability_1 = HDF5.readmmap(file[\"stability_all\"])\n",
    "        close(file)    \n",
    "    \n",
    "        all_files = readdir(data_path(ds_save_cy_2))\n",
    "        which_file = [occursin(experiment_filename_2, all_files[i])*occursin(\"A_dF\", all_files[i])*occursin(\"neuron\", all_files[i]) for i in 1:length(all_files)]\n",
    "        @assert(length(all_files[which_file]) == 1)\n",
    "        save_file_name = all_files[which_file][1]\n",
    "        info_filename = joinpath(data_path(ds_save_cy_2), save_file_name)\n",
    "        file = h5open(info_filename, \"r\")\n",
    "        place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "        specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "        specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "        specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "        stability_2 = HDF5.readmmap(file[\"stability_all\"])\n",
    "        close(file)\n",
    "\n",
    "        if flag == 1\n",
    "            which_file = [occursin(experiment_filename_1, all_files[i])*occursin(\"A_dF\", all_files[i])*occursin(\"neuron\", all_files[i]) for i in 1:length(all_files)]          \n",
    "            @assert(length(all_files[which_file]) == 1)\n",
    "            save_file_name = all_files[which_file][1]\n",
    "            info_filename = joinpath(data_path(ds_save_cy_2), save_file_name)\n",
    "            file = h5open(info_filename, \"r\")\n",
    "            place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "            close(file)\n",
    "        end\n",
    "\n",
    "        if experiment_filename_2 in morphing_need_filename\n",
    "            println(\"true\")\n",
    "            all_files = readdir(data_path(ds_save_cy_2))\n",
    "            which_file = [occursin(\"boundary_morph_matchangle_v2.h5\", all_files[i]) for i in 1:length(all_files)]\n",
    "            @assert(length(all_files[which_file]) == 1)\n",
    "            save_file_name = all_files[which_file][1]\n",
    "            info_filename = joinpath(data_path(ds_save_cy_2), save_file_name)\n",
    "            file = h5open(info_filename, \"r\")\n",
    "            mapped_map_all = HDF5.readmmap(file[\"mapped_map_all\"])\n",
    "            close(file)\n",
    "        end\n",
    "        \n",
    "        place_cell_index_1 = intersect(findall(specificity_population_z_1.>3), findall(specificity_shuffle_z_1.>5), findall(specificity_1.>0.01), findall(whether_tel));\n",
    "        place_cell_index_2 = intersect(findall(specificity_population_z_2.>3), findall(specificity_shuffle_z_2.>5), findall(specificity_2.>0.01), findall(whether_tel));\n",
    "        union_place_cell_index = union(place_cell_index_1,place_cell_index_2)\n",
    "    \n",
    "        append!(trials_place_cell_1_tog, [place_cell_index_1])\n",
    "        append!(trials_place_cell_2_tog, [place_cell_index_2])\n",
    "        append!(trials_union_place_cell_tog, [union_place_cell_index])\n",
    "\n",
    "        shuffled_PFcov_all = Array{Any}(undef,length(specificity_population_z_1))\n",
    "        original_PFcor_all = fill(NaN32,length(specificity_population_z_1))\n",
    "        original_PFcov_all = fill(NaN32,length(specificity_population_z_1))\n",
    "        PFoverlap_all = zeros(length(specificity_population_z_1))\n",
    "        \n",
    "        @showprogress for which_neuron in union_place_cell_index\n",
    "            if experiment_filename_2 in morphing_need_filename\n",
    "                s1_map = place_map_all_1[:,:,which_neuron]\n",
    "                s2_map = mapped_map_all[:,:,which_neuron]\n",
    "            else\n",
    "                s1_map = place_map_all_1[:,:,which_neuron]\n",
    "                s2_map = place_map_all_2[:,:,which_neuron]\n",
    "            end\n",
    "            original_PFcor = corr_2d_original(s1_map,s2_map)\n",
    "            PFoverlap_all[which_neuron] = PF_overlap(s1_map,s2_map)\n",
    "            original_PFcor_all[which_neuron] = original_PFcor\n",
    "            \n",
    "            # computing null distribution for the PF correlation\n",
    "            valid_index = findall((.!isnan.(s1_map)).*(.!isnan.(s2_map)))\n",
    "            if length(valid_index) == 0\n",
    "                continue\n",
    "            end\n",
    "            valid_s1_map = s1_map[valid_index]\n",
    "            valid_s2_map = s2_map[valid_index]\n",
    "            original_PFcov = cov(valid_s1_map,valid_s2_map)\n",
    "            \n",
    "            # manual circular shuffle\n",
    "            max_shift = length(valid_index)\n",
    "            shift_steps = collect(1:max_shift)\n",
    "    \n",
    "            shuffled_PFcov = zeros(max_shift)\n",
    "            for n in 1:max_shift\n",
    "                shuffled_valid_s2_map = numpy.roll(valid_s2_map,n)\n",
    "                shuffled_PFcov[n] = cov(valid_s1_map,shuffled_valid_s2_map)\n",
    "            end\n",
    "            original_PFcov_all[which_neuron] = original_PFcov\n",
    "            shuffled_PFcov_all[which_neuron] = shuffled_PFcov\n",
    "        end\n",
    "        \n",
    "        append!(trials_original_PFcor_tog, [original_PFcor_all])\n",
    "        append!(trials_original_PFcov_tog, [original_PFcov_all])\n",
    "        append!(trials_suffled_PFcov_tog, [shuffled_PFcov_all])\n",
    "        append!(trials_PFoverlap_tog, [PFoverlap_all])\n",
    "\n",
    "        file_folder_1 = joinpath(data_path(ds_save_cy_1), \"place_cell_windows\")\n",
    "        all_files = readdir(file_folder_1)\n",
    "        long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "        spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "        candidate_filename = long_name_files[spatial_info_index]\n",
    "        which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "        save_file_name = candidate_filename[which_file][1]\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1),\"place_cell_windows\", save_file_name)\n",
    "        file = h5open(info_filename, \"r\")\n",
    "        place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "        specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "        specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "        specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "        stability_1_early = HDF5.readmmap(file[\"stability_all\"])\n",
    "        close(file)\n",
    "            \n",
    "        save_file_name = candidate_filename[which_file][2]\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1),\"place_cell_windows\", save_file_name)\n",
    "        file = h5open(info_filename, \"r\")\n",
    "        place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "        specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "        specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "        specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "        stability_1_late = HDF5.readmmap(file[\"stability_all\"])\n",
    "        close(file)\n",
    "\n",
    "        place_cell_index_1 = intersect(findall(specificity_population_z_1.>3), findall(specificity_shuffle_z_1.>5), findall(specificity_1.>0.01), findall(whether_tel));\n",
    "        place_cell_index_2 = intersect(findall(specificity_population_z_2.>3), findall(specificity_shuffle_z_2.>5), findall(specificity_2.>0.01), findall(whether_tel));\n",
    "        union_place_cell_index = union(place_cell_index_1,place_cell_index_2)\n",
    "        \n",
    "        append!(earlylate_place_cell_1_tog, [place_cell_index_1])\n",
    "        append!(earlylate_place_cell_2_tog, [place_cell_index_2])\n",
    "        append!(earlylate_union_place_cell_tog, [union_place_cell_index])\n",
    "\n",
    "        shuffled_PFcov_all = Array{Any}(undef,length(specificity_population_z_1))\n",
    "        original_PFcor_all = fill(NaN32,length(specificity_population_z_1))\n",
    "        original_PFcov_all = fill(NaN32,length(specificity_population_z_1))\n",
    "        PFoverlap_all = zeros(length(specificity_population_z_1))\n",
    "        \n",
    "        @showprogress for which_neuron in union_place_cell_index\n",
    "            s1_map = place_map_all_1[:,:,which_neuron]\n",
    "            s2_map = place_map_all_2[:,:,which_neuron]\n",
    "            \n",
    "            original_PFcor = corr_2d_original(s1_map,s2_map)\n",
    "            PFoverlap_all[which_neuron] = PF_overlap(s1_map,s2_map)\n",
    "            original_PFcor_all[which_neuron] = original_PFcor\n",
    "            \n",
    "            # computing null distribution for the PF correlation\n",
    "            valid_index = findall((.!isnan.(s1_map)).*(.!isnan.(s2_map)))\n",
    "            if length(valid_index) == 0\n",
    "                continue\n",
    "            end\n",
    "            valid_s1_map = s1_map[valid_index]\n",
    "            valid_s2_map = s2_map[valid_index]\n",
    "            original_PFcov = cov(valid_s1_map,valid_s2_map)\n",
    "            \n",
    "            # manual circular shuffle\n",
    "            max_shift = length(valid_index)\n",
    "            shift_steps = collect(1:max_shift)\n",
    "    \n",
    "            shuffled_PFcov = zeros(max_shift)\n",
    "            for n in 1:max_shift\n",
    "                shuffled_valid_s2_map = numpy.roll(valid_s2_map,n)\n",
    "                shuffled_PFcov[n] = cov(valid_s1_map,shuffled_valid_s2_map)\n",
    "            end\n",
    "            original_PFcov_all[which_neuron] = original_PFcov\n",
    "            shuffled_PFcov_all[which_neuron] = shuffled_PFcov\n",
    "        end\n",
    "        \n",
    "        append!(earlylate_original_PFcor_tog, [original_PFcor_all])\n",
    "        append!(earlylate_original_PFcov_tog, [original_PFcov_all])\n",
    "        append!(earlylate_suffled_PFcov_tog, [shuffled_PFcov_all])\n",
    "        append!(earlylate_PFoverlap_tog, [PFoverlap_all])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f959109-015d-47cb-a8f7-b9d774052dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials_two_sided_p_values_tog = []\n",
    "trials_one_sided_p_values_tog = []\n",
    "trials_z_scores_tog = []\n",
    "\n",
    "earlylate_two_sided_p_values_tog = []\n",
    "earlylate_one_sided_p_values_tog = []\n",
    "earlylate_z_scores_tog = []\n",
    "\n",
    "@showprogress for exp_idx in 1:length(trials_original_PFcor_tog)\n",
    "    trials_original_PFcor_all = trials_original_PFcor_tog[exp_idx]\n",
    "    trials_original_PFcov_all = trials_original_PFcov_tog[exp_idx]\n",
    "    trials_shuffled_PFcov_all = trials_suffled_PFcov_tog[exp_idx]\n",
    "    \n",
    "    trials_two_sided_p_values = fill(NaN32, length(trials_place_cell_1_tog[exp_idx]))\n",
    "    trials_one_sided_p_values = fill(NaN32, length(trials_place_cell_1_tog[exp_idx]))\n",
    "    trials_z_scores = fill(NaN32, length(trials_place_cell_1_tog[exp_idx]))\n",
    "    for (i,which_neuron) in enumerate(trials_place_cell_1_tog[exp_idx])\n",
    "        test_PFcov = trials_original_PFcov_all[which_neuron]\n",
    "        null_PFcov_dist = []\n",
    "        try null_PFcov_dist = trials_shuffled_PFcov_all[which_neuron]\n",
    "        catch\n",
    "            continue\n",
    "        end\n",
    "    \n",
    "        null_mean = nanmean(null_PFcov_dist)\n",
    "        null_std = nanstd(null_PFcov_dist)\n",
    "        if isfinite(test_PFcov)\n",
    "            # P(null_PFcov >= test_PFcov)\n",
    "            prob_1 = length(findall(null_PFcov_dist .>= test_PFcov)) / length(null_PFcov_dist)\n",
    "            # P(null_PFcov <= test_PFcov)\n",
    "            prob_2 = length(findall(null_PFcov_dist .<= test_PFcov)) / length(null_PFcov_dist)\n",
    "            # p_values\n",
    "            # two-tailed p-value\n",
    "            trials_two_sided_p_values[i] = 2*min(prob_1,prob_2)\n",
    "            # one-tailed p-value\n",
    "            trials_one_sided_p_values[i] = prob_1\n",
    "            # z-score\n",
    "            trials_z_scores[i] = (test_PFcov - null_mean) / null_std\n",
    "        end\n",
    "    end\n",
    "\n",
    "    append!(trials_two_sided_p_values_tog, [trials_two_sided_p_values])\n",
    "    append!(trials_one_sided_p_values_tog, [trials_one_sided_p_values])\n",
    "    append!(trials_z_scores_tog, [trials_z_scores])\n",
    "end\n",
    "\n",
    "@showprogress for exp_idx in 1:length(earlylate_original_PFcor_tog)\n",
    "    earlylate_original_PFcor_all = earlylate_original_PFcor_tog[exp_idx]\n",
    "    earlylate_original_PFcov_all = earlylate_original_PFcov_tog[exp_idx]\n",
    "    earlylate_shuffled_PFcov_all = earlylate_suffled_PFcov_tog[exp_idx]\n",
    "    \n",
    "    earlylate_two_sided_p_values = fill(NaN32, length(earlylate_place_cell_1_tog[exp_idx]))\n",
    "    earlylate_one_sided_p_values = fill(NaN32, length(earlylate_place_cell_1_tog[exp_idx]))\n",
    "    earlylate_z_scores = fill(NaN32, length(earlylate_place_cell_1_tog[exp_idx]))\n",
    "    for (i,which_neuron) in enumerate(earlylate_place_cell_1_tog[exp_idx])\n",
    "        test_PFcov = earlylate_original_PFcov_all[which_neuron]\n",
    "        null_PFcov_dist = []\n",
    "        try null_PFcov_dist = earlylate_shuffled_PFcov_all[which_neuron]\n",
    "        catch\n",
    "            continue\n",
    "        end\n",
    "        null_mean = nanmean(null_PFcov_dist)\n",
    "        null_std = nanstd(null_PFcov_dist)\n",
    "        if isfinite(test_PFcov)\n",
    "            # P(null_PFcov >= test_PFcov)\n",
    "            prob_1 = length(findall(null_PFcov_dist .>= test_PFcov)) / length(null_PFcov_dist)\n",
    "            # P(null_PFcov <= test_PFcov)\n",
    "            prob_2 = length(findall(null_PFcov_dist .<= test_PFcov)) / length(null_PFcov_dist)\n",
    "            # p_values\n",
    "            # two-tailed p-value\n",
    "            earlylate_two_sided_p_values[i] = 2*min(prob_1,prob_2)\n",
    "            # one-tailed p-value\n",
    "            earlylate_one_sided_p_values[i] = prob_1\n",
    "            # z-score\n",
    "            earlylate_z_scores[i] = (test_PFcov - null_mean) / null_std\n",
    "        end\n",
    "    end\n",
    "\n",
    "    append!(earlylate_two_sided_p_values_tog, [earlylate_two_sided_p_values])\n",
    "    append!(earlylate_one_sided_p_values_tog, [earlylate_one_sided_p_values])\n",
    "    append!(earlylate_z_scores_tog, [earlylate_z_scores])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3bfa44-d771-4d7e-9d47-fbafb1696b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "jldopen(joinpath(filepath, \"place_cell_dropout.jld\"), \"w\") do file\n",
    "    write(file, \"earlylate_PFoverlap_tog\", earlylate_PFoverlap_tog)\n",
    "    write(file, \"trials_PFoverlap_tog\", trials_PFoverlap_tog)\n",
    "\n",
    "    write(file, \"earlylate_one_sided_p_values_tog\", earlylate_one_sided_p_values_tog)\n",
    "    write(file, \"trials_one_sided_p_values_tog\", trials_one_sided_p_values_tog)\n",
    "\n",
    "    write(file, \"earlylate_original_PFcor_tog\", earlylate_original_PFcor_tog)\n",
    "    write(file, \"trials_original_PFcor_tog\", trials_original_PFcor_tog)\n",
    "\n",
    "    write(file, \"earlylate_place_cell_1_tog\", earlylate_place_cell_1_tog)\n",
    "    write(file, \"earlylate_place_cell_2_tog\", earlylate_place_cell_2_tog)\n",
    "    write(file, \"earlylate_union_place_cell_tog\", earlylate_union_place_cell_tog)\n",
    "    \n",
    "    write(file, \"trials_place_cell_1_tog\", trials_place_cell_1_tog)\n",
    "    write(file, \"trials_place_cell_2_tog\", trials_place_cell_2_tog)\n",
    "    write(file, \"trials_union_place_cell_tog\", trials_union_place_cell_tog)\n",
    "\n",
    "    write(file, \"job_names_ordered\", job_names_ordered)\n",
    "    write(file, \"data_info_dict\", data_info_dict)\n",
    "    write(file, \"job_names_figure\", job_names_figure)\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83421623-ed69-44c6-87e4-7693b24e3620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
