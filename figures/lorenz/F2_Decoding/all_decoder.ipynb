{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce18186-4433-4c9a-bcf0-be85014f4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter, PyCall, PyPlot, Cairo, Images, HDF5, MultivariateStats, Interpolations, Lasso, Distributions, ImageFiltering\n",
    "using _Data\n",
    "using  NaNStatistics, Statistics\n",
    "\n",
    "include(\"../project_place_cell/functions/func_map.jl\")\n",
    "include(\"./Decoder_Functions.jl\")\n",
    "include(\"./Decoder_Pipeline.jl\")\n",
    "np = pyimport(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15480ff0-5821-4830-84e5-8997c4919545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_corner_cue = \n",
    "[\n",
    "    [\"20220407_152537\", 4, \"jen\"],\n",
    "    [\"20220406_111526\", 9, \"jen\"],\n",
    "    [\"20220407_090156\", 5, \"jen\"],\n",
    "    [\"20220417_165530\", 2, \"jen\"],\n",
    "    [\"20220406_153842\", 9, \"jen\"],\n",
    "    [\"20220405_171444\", 4, \"jen\"],\n",
    "    [\"20220416_160516\", 6, \"jen\"]\n",
    "];\n",
    "\n",
    "\n",
    "datasets_8s = \n",
    "[\n",
    "    [\"20230410_115717\", 9, \"lorenz\"],\n",
    "    [\"20230525_130922\", 8, \"chuyu\"],\n",
    "    [\"20230525_174820\", 8, \"chuyu\"],\n",
    "    [\"20230610_204004\", 8, \"jen\"],  \n",
    "    [\"20230611_141304\", 4, \"drew\"],\n",
    "    [\"20230610_142825\", 8, \"chuyu\"]\n",
    "];\n",
    "\n",
    "lengths = [90, 90, 90, 89, 90, 90, 90, 90, 90];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba125450-2aa3-4c1c-8c10-90fadc428347",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_bins = 7\n",
    "activity_shift = 4\n",
    "n_pos = 60 #number of bins in long side\n",
    "long_axis_in_mm = 47 #47 for rectangular, 33 for others\n",
    "use_amount = 1000\n",
    "file_name = \"_decoding_revision_new.h5\"\n",
    "\n",
    "\n",
    "i=1\n",
    "\n",
    "experiment_filename = datasets_corner_cue[i][1]\n",
    "server = datasets_corner_cue[i][2]\n",
    "experimenter = datasets_corner_cue[i][3]\n",
    "\n",
    "ds_Lorenz = Dataset(experiment_filename, \"lorenz\", gethostname() == \"roli-$(server)\" ? \"/data\" : \"/nfs/data$(server)\")\n",
    "ds_Chuyu = Dataset(experiment_filename, \"chuyu\", gethostname() == \"roli-$(server)\" ? \"/data\" : \"/nfs/data$(server)\")\n",
    "\n",
    "ds = Dataset(experiment_filename, experimenter, gethostname() == \"roli-$(server)\" ? \"/data\" : \"/nfs/data$(server)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf91aab-d629-4570-ba94-3b23ae0a001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rm(joinpath(data_path(ds_Lorenz), \"20220406_153842_fig4_data_2000.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d4e5df-3ab1-4008-bb99-6fb1123d639f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0da91-107f-4b4d-96aa-d8c992aafb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "readdir(path(ds_Chuyu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806b5fb-eaf7-40dc-b2c8-580cfd080975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "C, heading, img_bg, y_fish, x_offset, x_fish, y_offset = h5open(ds, \"behavior.h5\"; raw = true) do file\n",
    "    read(file, \"C\"),\n",
    "    read(file, \"heading\"),\n",
    "    read(file, \"img_bg\"),\n",
    "    read(file, \"fish_yolk_y\"),\n",
    "    read(file, \"offset_x\"),\n",
    "    read(file, \"fish_yolk_x\"),\n",
    "    read(file, \"offset_y\")\n",
    "end;\n",
    "\n",
    "img_bg_end = img_bg[:,:,end]\n",
    "\n",
    "# orientation-corrected fish location (time binned)\n",
    "position_file = h5open(joinpath(data_path(ds_Chuyu), \"for_place_calculation_chamber_geometry_$(experiment_filename)_n60.h5\"))\n",
    "    chamber_roi = read(position_file,\"chamber_roi\")\n",
    "    x_fish_sweep_mean = read(position_file,\"x_fish_sweep_mean\")\n",
    "    y_fish_sweep_mean = read(position_file,\"y_fish_sweep_mean\")\n",
    "    speed_mm_s = read(position_file, \"speed_mm_s\")\n",
    "    loc_digital = read(position_file, \"loc_digital\")\n",
    "    x_digital = read(position_file, \"x_digital\")\n",
    "    y_digital = read(position_file, \"y_digital\")\n",
    "    x_bins = read(position_file, \"x_bins\")\n",
    "    y_bins = read(position_file, \"y_bins\")\n",
    "close(position_file)\n",
    "\n",
    "moving_valid = speed_mm_s .> 0.1;\n",
    "long_axis_in_bins = (maximum(x_digital)-minimum(x_digital)+1)\n",
    "\n",
    "\n",
    "file = h5open(joinpath(data_path(ds_Chuyu), \"neuron_spatial_info_15_$(lengths[i])_chamber_geometry_$(experiment_filename)_sigma1_n60_A_dF.h5\"), \"r\") #_whole #spatial_info_4 done on merged cells\n",
    "    valid_neurons = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    specificity_shuffle_z = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    specificity_population_z = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity = HDF5.readmmap(file[\"specificity\"])\n",
    "    bool_index = HDF5.readmmap(file[\"bool_index\"])\n",
    "close(file)\n",
    "\n",
    "bool_index = BitArray(bool_index)\n",
    "\n",
    "\n",
    "\n",
    "file = h5open(joinpath(data_path(ds_Chuyu), \"NMF_merge.h5\"), \"r\")\n",
    "    A_dFF = HDF5.readmmap(file[\"A_dF\"])\n",
    "    #A_dFF = HDF5.readmmap(file[\"A_dFF\"])\n",
    "\n",
    "    z_all = HDF5.readmmap(file[\"Z_all\"])\n",
    "    centroid_x_all = HDF5.readmmap(file[\"X_all\"])\n",
    "    centroid_y_all = HDF5.readmmap(file[\"Y_all\"])\n",
    "\n",
    "    neuron_label = read(file, \"neuron_label\");\n",
    "close(file)\n",
    "\n",
    "n_neurons = size(A_dFF, 2)\n",
    "n_sweeps = size(A_dFF, 1)\n",
    "\n",
    "\n",
    "# import an process OT and OB\n",
    "file = h5open(joinpath(data_path(ds_Chuyu), \"region_roi_bool.h5\"))\n",
    "    region_names = read(file, \"region_names\")\n",
    "    region_roi_bool = read(file, \"region_roi_bool\")\n",
    "close(file)\n",
    "\n",
    "\n",
    "tel_index = findall(region_names .== \"Telencephalon -\")[1];\n",
    "mes_index = findall(region_names .== \"Mesencephalon -\")[1];\n",
    "rhomb_index = findall(region_names .== \"Rhombencephalon -\")[1];\n",
    "\n",
    "tectum_index = findall(region_names .== \"Mesencephalon - Tectum Stratum Periventriculare\")[1];\n",
    "olfactory_index = findall(region_names .== \"Telencephalon - Olfactory Bulb\")[1];\n",
    "olfactory_index_2 = findall(region_names .== \"Telencephalon - Olfactory bulb dopaminergic neuron areas\")[1];\n",
    "\n",
    "mask_tel = falses(n_neurons)\n",
    "mask_mes = falses(n_neurons)\n",
    "mask_rhomb = falses(n_neurons)\n",
    "\n",
    "optic_tectum = falses(n_neurons)\n",
    "olfactory_bulb = falses(n_neurons)\n",
    "olfactory_bulb_2 = falses(n_neurons)\n",
    "\n",
    "\n",
    "@showprogress for which_neuron in 1:n_neurons\n",
    "    mask_tel[which_neuron] = maximum(region_roi_bool[neuron_label.==which_neuron, tel_index])\n",
    "    mask_mes[which_neuron] = maximum(region_roi_bool[neuron_label.==which_neuron, mes_index])\n",
    "    mask_rhomb[which_neuron] = maximum(region_roi_bool[neuron_label.==which_neuron, rhomb_index])\n",
    "    \n",
    "    optic_tectum[which_neuron] = maximum(region_roi_bool[neuron_label.==which_neuron, tectum_index])\n",
    "    olfactory_bulb[which_neuron] = maximum(region_roi_bool[neuron_label.==which_neuron, olfactory_index])\n",
    "    olfactory_bulb_2[which_neuron] = maximum(region_roi_bool[neuron_label.==which_neuron, olfactory_index_2])\n",
    "end\n",
    "\n",
    "mask_tel = findall(mask_tel)\n",
    "mask_mes = findall(mask_mes)\n",
    "mask_rhomb = findall(mask_rhomb)\n",
    "optic_tectum = findall(optic_tectum)\n",
    "olfactory_bulb = findall(olfactory_bulb)\n",
    "olfactory_bulb_2 = findall(olfactory_bulb_2)\n",
    "\n",
    "\n",
    "subplot(2,1,1)\n",
    "scatter(centroid_x_all, centroid_y_all, s=2)\n",
    "scatter(centroid_x_all[mask_tel], centroid_y_all[mask_tel], s=2)\n",
    "scatter(centroid_x_all[mask_mes], centroid_y_all[mask_mes], s=2)\n",
    "scatter(centroid_x_all[mask_rhomb], centroid_y_all[mask_rhomb], s=2)\n",
    "\n",
    "scatter(centroid_x_all[optic_tectum], centroid_y_all[optic_tectum], s=2)\n",
    "scatter(centroid_x_all[olfactory_bulb], centroid_y_all[olfactory_bulb], s=2)\n",
    "scatter(centroid_x_all[olfactory_bulb_2], centroid_y_all[olfactory_bulb_2], s=2)\n",
    "\n",
    "subplot(2,1,2)\n",
    "scatter(centroid_x_all, z_all, s=2)\n",
    "scatter(centroid_x_all[mask_tel], z_all[mask_tel], s=2)\n",
    "scatter(centroid_x_all[mask_mes], z_all[mask_mes], s=2)\n",
    "scatter(centroid_x_all[mask_rhomb], z_all[mask_rhomb], s=2)\n",
    "\n",
    "scatter(centroid_x_all[optic_tectum], z_all[optic_tectum], s=2)\n",
    "scatter(centroid_x_all[olfactory_bulb], z_all[olfactory_bulb], s=2)\n",
    "scatter(centroid_x_all[olfactory_bulb_2], z_all[olfactory_bulb_2], s=2)\n",
    "\n",
    "\n",
    "w = size(img_bg, 1)\n",
    "l = size(img_bg, 2);\n",
    "\n",
    "# Define bins\n",
    "min_x = 0\n",
    "min_y = 0\n",
    "max_x = w\n",
    "max_y = l\n",
    "\n",
    "bin_interval = maximum([(max_y-min_y+2)/n_pos,(max_x-min_x+2)/n_pos])\n",
    "\n",
    "x_bins = collect(min_x-1:bin_interval:min_x+bin_interval*(n_pos)+1);\n",
    "y_bins = collect(min_y-1:bin_interval:min_y+bin_interval*(n_pos)+1);\n",
    "\n",
    "x_bins_mid = (x_bins[1:end-1]+x_bins[2:end])/2\n",
    "y_bins_mid = (y_bins[1:end-1]+y_bins[2:end])/2;\n",
    "\n",
    "# Digitize data, then we just count the number\n",
    "x_digital2 = numpy.digitize(x_fish_sweep_mean, x_bins)\n",
    "y_digital2 = numpy.digitize(y_fish_sweep_mean, y_bins);\n",
    "loc_digital2 = (y_digital2.-1).*n_pos.+x_digital2;\n",
    "\n",
    "\n",
    "function bin_to_px(x, y, offset=true)\n",
    "    if offset\n",
    "        return (x .- 0.5) .* bin_interval .+ (min_x-1), (y .- 0.5) .* bin_interval .+ (min_y-1)\n",
    "    else\n",
    "        return (x .- 0.5) .* bin_interval, (y .- 0.5) .* bin_interval\n",
    "    end\n",
    "end\n",
    "\n",
    "function px_to_bin(x, y)\n",
    "    return 0.5 .+ ((x .- (min_x-1)) ./ bin_interval), 0.5 .+ ((y .- (min_y-1)) ./ bin_interval)\n",
    "end\n",
    "\n",
    "x_in_bins, y_in_bins = px_to_bin(x_fish_sweep_mean, y_fish_sweep_mean);\n",
    "\n",
    "\n",
    "try\n",
    "mkdir(data_path(ds_Lorenz))    \n",
    "catch\n",
    "    println(\"save path exists\")\n",
    "end\n",
    "\n",
    "temp = Decoder.get_top_neurons(use_amount, specificity_population_z[mask_tel], specificity_shuffle_z[mask_tel]);\n",
    "place_candidates_unique = mask_tel[temp];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16599ce-3067-40ff-a983-0587db6fcd87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c45bcc-f927-43a9-bf97-afe56924d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"./Decoder_Functions.jl\")\n",
    "include(\"./Decoder_Pipeline.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dce436-5f81-4937-aa71-1c6cad9a4d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all datasets fast test\n",
    "activity_bins = 7\n",
    "activity_shift = 4\n",
    "n_pos = 90 #number of bins in long side\n",
    "long_axis_in_mm = 47 #47 for rectangular, 33 for others\n",
    "use_amount = 1000\n",
    "\n",
    "include(\"./Decoder_Functions.jl\")\n",
    "include(\"./Decoder_Pipeline.jl\")\n",
    "\n",
    "lengths = [68, 72, 62, 48, 47, 62];\n",
    "\n",
    "errors_all = []\n",
    "\n",
    "for i in 1:length(datasets_8s)\n",
    "    \n",
    "\n",
    "    experiment_filename = datasets_8s[i][1]\n",
    "    server = datasets_8s[i][2]\n",
    "    experimenter = datasets_8s[i][3]\n",
    "\n",
    "    ds_Lorenz = Dataset(experiment_filename, \"lorenz\", gethostname() == \"roli-$(server)\" ? \"/data\" : \"/nfs/data$(server)\")\n",
    "    ds_Chuyu = Dataset(experiment_filename, \"chuyu\", gethostname() == \"roli-$(server)\" ? \"/data\" : \"/nfs/data$(server)\")\n",
    "\n",
    "    ds = Dataset(experiment_filename, experimenter, gethostname() == \"roli-$(server)\" ? \"/data\" : \"/nfs/data$(server)\")\n",
    "\n",
    "    \n",
    "    C, heading, img_bg = h5open(ds, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"C\"),\n",
    "        read(file, \"heading\"),\n",
    "        read(file, \"img_bg\")\n",
    "    end;\n",
    "\n",
    "    img_bg_end = img_bg[:,:,end]\n",
    "\n",
    "    # orientation-corrected fish location (time binned)\n",
    "    position_file = h5open(joinpath(data_path(ds_Chuyu), \"for_place_calculation_chamber_geometry_$(experiment_filename)_n90.h5\"))\n",
    "        chamber_roi = read(position_file,\"chamber_roi\")\n",
    "        x_fish_sweep_mean = read(position_file,\"x_fish_sweep_mean\")\n",
    "        y_fish_sweep_mean = read(position_file,\"y_fish_sweep_mean\")\n",
    "        speed_mm_s = read(position_file, \"speed_mm_s\")\n",
    "        loc_digital = read(position_file, \"loc_digital\")\n",
    "        x_digital = read(position_file, \"x_digital\")\n",
    "        y_digital = read(position_file, \"y_digital\")\n",
    "        x_bins = read(position_file, \"x_bins\")\n",
    "        y_bins = read(position_file, \"y_bins\")\n",
    "    close(position_file)\n",
    "\n",
    "    moving_valid = speed_mm_s .> 0.1;\n",
    "    long_axis_in_bins = (maximum(x_digital)-minimum(x_digital)+1)\n",
    "\n",
    "\n",
    "    file = h5open(joinpath(data_path(ds_Chuyu), \"neuron_spatial_info_0_$(lengths[i])_chamber_geometry_$(experiment_filename)_sigma1_n90.h5\"), \"r\") #_whole #spatial_info_4 done on merged cells\n",
    "        valid_neurons = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "        place_cell_index = read(file, \"place_cell_index\")\n",
    "        specificity_shuffle_z = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "        specificity_population_z = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "        specificity = HDF5.readmmap(file[\"specificity\"])\n",
    "        bool_index = HDF5.readmmap(file[\"bool_index\"])\n",
    "    close(file)\n",
    "\n",
    "    bool_index = BitArray(bool_index)\n",
    "\n",
    "    bool_index[1:30*120] .= 0\n",
    "\n",
    "\n",
    "    file = h5open(joinpath(data_path(ds_Chuyu), \"NMF_merge.h5\"), \"r\")\n",
    "        A_dFF = HDF5.readmmap(file[\"A_dFF\"])\n",
    "\n",
    "        z_all = HDF5.readmmap(file[\"Z_all\"])\n",
    "        centroid_x_all = HDF5.readmmap(file[\"X_all\"])\n",
    "        centroid_y_all = HDF5.readmmap(file[\"Y_all\"])\n",
    "\n",
    "        neuron_label = read(file, \"neuron_label\");\n",
    "    close(file)\n",
    "\n",
    "    n_neurons = size(A_dFF, 2)\n",
    "    n_sweeps = size(A_dFF, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # import an process OT and OB\n",
    "    file = h5open(joinpath(data_path(ds_Chuyu), \"region_roi_bool.h5\"))\n",
    "        region_names = read(file, \"region_names\")\n",
    "        region_roi_bool = read(file, \"region_roi_bool\")\n",
    "    close(file)\n",
    "\n",
    "\n",
    "    tel_index = findall(region_names .== \"Telencephalon -\")[1];\n",
    "    mask_tel = falses(n_neurons)\n",
    "\n",
    "    for which_neuron in 1:n_neurons\n",
    "        mask_tel[which_neuron] = maximum(region_roi_bool[neuron_label.==which_neuron, tel_index])\n",
    "    end\n",
    "\n",
    "    mask_tel = findall(mask_tel)\n",
    "\n",
    "\n",
    "\n",
    "    w = size(img_bg, 1)\n",
    "    l = size(img_bg, 2);\n",
    "\n",
    "    # Define bins\n",
    "    min_x = 0\n",
    "    min_y = 0\n",
    "    max_x = w\n",
    "    max_y = l\n",
    "\n",
    "    bin_interval = maximum([(max_y-min_y+2)/n_pos,(max_x-min_x+2)/n_pos])\n",
    "\n",
    "    x_bins = collect(min_x-1:bin_interval:min_x+bin_interval*(n_pos)+1);\n",
    "    y_bins = collect(min_y-1:bin_interval:min_y+bin_interval*(n_pos)+1);\n",
    "\n",
    "    x_bins_mid = (x_bins[1:end-1]+x_bins[2:end])/2\n",
    "    y_bins_mid = (y_bins[1:end-1]+y_bins[2:end])/2;\n",
    "\n",
    "    # Digitize data, then we just count the number\n",
    "    x_digital2 = numpy.digitize(x_fish_sweep_mean, x_bins)\n",
    "    y_digital2 = numpy.digitize(y_fish_sweep_mean, y_bins);\n",
    "    loc_digital2 = (y_digital2.-1).*n_pos.+x_digital2;\n",
    "\n",
    "\n",
    "    function bin_to_px(x, y, offset=true)\n",
    "        if offset\n",
    "            return (x .- 0.5) .* bin_interval .+ (min_x-1), (y .- 0.5) .* bin_interval .+ (min_y-1)\n",
    "        else\n",
    "            return (x .- 0.5) .* bin_interval, (y .- 0.5) .* bin_interval\n",
    "        end\n",
    "    end\n",
    "\n",
    "    function px_to_bin(x, y)\n",
    "        return 0.5 .+ ((x .- (min_x-1)) ./ bin_interval), 0.5 .+ ((y .- (min_y-1)) ./ bin_interval)\n",
    "    end\n",
    "\n",
    "    x_in_bins2, y_in_bins2 = px_to_bin(x_fish_sweep_mean, y_fish_sweep_mean);\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    amount = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 30]#, 50, 60, 80, 100, 300, 500, 600, 700, 800, 900, 1000]\n",
    "    long_shift_errors_mm = fill(NaN, length(amount))\n",
    "    \n",
    "    @showprogress for i in 1:length(amount)\n",
    "        shift = amount[i]\n",
    "        \n",
    "        predicted, rolling_var, rolling_valid = Decoder.quick_decoder(bool_index, A_dFF[:, place_cell_index], loc_digital2, activity_bins, shift, n_pos) #rolling_decoder\n",
    "        \n",
    "        errors = Decoder.get_distance(predicted[:, 1] , x_in_bins2, predicted[:, 2], y_in_bins2)\n",
    "        \n",
    "        long_shift_errors_mm[i] = nanmedian(errors)*long_axis_in_mm/long_axis_in_bins\n",
    "    end\n",
    "    \n",
    "    append!(errors_all, [long_shift_errors_mm])\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2e654-91df-40e2-b8bb-510f4099313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb534e-d1a1-4426-bc8e-857fa5b8f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in errors_all \n",
    "plt.plot([0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 30], i)\n",
    "plt.axhline(20, alpha=0.5)\n",
    "plt.xlabel(\"shift\")\n",
    "plt.ylabel(\"error [mm]\")\n",
    "#plt.xscale(\"log\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fa4e0-bcbd-44d0-9ad8-0d1ea4309586",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1624f4f-ee00-41e2-8ea9-81c5273f5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "x = hcat(errors_all...)\n",
    "\n",
    "m = nanmean(x, dim=2)\n",
    "s = nanstd(x, dim=2)\n",
    "\n",
    "ax.plot([0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 30], m, color=\"black\", linewidth=1)\n",
    "\n",
    "plt.fill_between([0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 30], m-s, m+s, color=\"lightgrey\", alpha=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fcbc3-b187-4c24-b222-a611714122d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7abfa4-fcf1-46ae-b868-6915e2dd3bd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### test all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1b0d2-c93b-4ac3-889c-de74c375e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all datasets fast test\n",
    "activity_bins = 1\n",
    "activity_shift = 4\n",
    "n_pos = 60 #number of bins in long side\n",
    "long_axis_in_mm = 47 #47 for rectangular, 33 for others\n",
    "use_amount = 1000\n",
    "\n",
    "include(\"./Decoder_Functions.jl\")\n",
    "include(\"./Decoder_Pipeline.jl\")\n",
    "\n",
    "lengths = [90, 90, 90, 89, 90, 90, 90, 90, 90];\n",
    "\n",
    "errors_all = []\n",
    "\n",
    "for i in 1:length(datasets_corner_cue)\n",
    "    \n",
    "\n",
    "experiment_filename = datasets_corner_cue[i][1]\n",
    "server = datasets_corner_cue[i][2]\n",
    "experimenter = datasets_corner_cue[i][3]\n",
    "\n",
    "ds_Lorenz = Dataset(experiment_filename, \"lorenz\", gethostname() == \"roli-$(server)\" ? \"/data\" : \"/nfs/data$(server)\")\n",
    "ds_Chuyu = Dataset(experiment_filename, \"chuyu\", gethostname() == \"roli-$(server)\" ? \"/data\" : \"/nfs/data$(server)\")\n",
    "\n",
    "ds = Dataset(experiment_filename, experimenter, gethostname() == \"roli-$(server)\" ? \"/data\" : \"/nfs/data$(server)\")\n",
    "    \n",
    "    \n",
    "    C, heading, img_bg, y_fish, x_offset, x_fish, y_offset = h5open(ds, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"C\"),\n",
    "        read(file, \"heading\"),\n",
    "        read(file, \"img_bg\"),\n",
    "        read(file, \"fish_yolk_y\"),\n",
    "        read(file, \"offset_x\"),\n",
    "        read(file, \"fish_yolk_x\"),\n",
    "        read(file, \"offset_y\")\n",
    "    end;\n",
    "    \n",
    "    img_bg_end = img_bg[:,:,end]\n",
    "    \n",
    "    # orientation-corrected fish location (time binned)\n",
    "    position_file = h5open(joinpath(data_path(ds_Chuyu), \"for_place_calculation_chamber_geometry_$(experiment_filename)_n60.h5\"))\n",
    "        chamber_roi = read(position_file,\"chamber_roi\")\n",
    "        x_fish_sweep_mean = read(position_file,\"x_fish_sweep_mean\")\n",
    "        y_fish_sweep_mean = read(position_file,\"y_fish_sweep_mean\")\n",
    "        speed_mm_s = read(position_file, \"speed_mm_s\")\n",
    "        loc_digital = read(position_file, \"loc_digital\")\n",
    "        x_digital = read(position_file, \"x_digital\")\n",
    "        y_digital = read(position_file, \"y_digital\")\n",
    "        x_bins = read(position_file, \"x_bins\")\n",
    "        y_bins = read(position_file, \"y_bins\")\n",
    "    close(position_file)\n",
    "\n",
    "    moving_valid = speed_mm_s .> 0.1;\n",
    "    long_axis_in_bins = (maximum(x_digital)-minimum(x_digital)+1)\n",
    "\n",
    "\n",
    "    file = h5open(joinpath(data_path(ds_Chuyu), \"neuron_spatial_info_15_$(lengths[i])_chamber_geometry_$(experiment_filename)_sigma1_n60_A_dF.h5\"), \"r\") #_whole #spatial_info_4 done on merged cells\n",
    "        valid_neurons = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "        specificity_shuffle_z = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "        specificity_population_z = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "        specificity = HDF5.readmmap(file[\"specificity\"])\n",
    "        bool_index = HDF5.readmmap(file[\"bool_index\"])\n",
    "    close(file)\n",
    "\n",
    "    bool_index = BitArray(bool_index)\n",
    "\n",
    "    #bool_index[1:30*120] .= 0\n",
    "\n",
    "\n",
    "    file = h5open(joinpath(data_path(ds_Chuyu), \"NMF_merge.h5\"), \"r\")\n",
    "        #A_dF = HDF5.readmmap(file[\"A_dF\"])\n",
    "        A_dFF = HDF5.readmmap(file[\"A_dF\"])\n",
    "\n",
    "        z_all = HDF5.readmmap(file[\"Z_all\"])\n",
    "        centroid_x_all = HDF5.readmmap(file[\"X_all\"])\n",
    "        centroid_y_all = HDF5.readmmap(file[\"Y_all\"])\n",
    "\n",
    "        neuron_label = read(file, \"neuron_label\");\n",
    "    close(file)\n",
    "\n",
    "    n_neurons = size(A_dFF, 2)\n",
    "    n_sweeps = size(A_dFF, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # import an process OT and OB\n",
    "    file = h5open(joinpath(data_path(ds_Chuyu), \"region_roi_bool.h5\"))\n",
    "        region_names = read(file, \"region_names\")\n",
    "        region_roi_bool = read(file, \"region_roi_bool\")\n",
    "    close(file)\n",
    "\n",
    "\n",
    "    tel_index = findall(region_names .== \"Telencephalon -\")[1];\n",
    "    mask_tel = falses(n_neurons)\n",
    "\n",
    "    @showprogress for which_neuron in 1:n_neurons\n",
    "        mask_tel[which_neuron] = maximum(region_roi_bool[neuron_label.==which_neuron, tel_index])\n",
    "    end\n",
    "\n",
    "    mask_tel = findall(mask_tel)\n",
    "\n",
    "\n",
    "\n",
    "    w = size(img_bg, 1)\n",
    "    l = size(img_bg, 2);\n",
    "\n",
    "    # Define bins\n",
    "    # min_x = 0\n",
    "    # min_y = 0\n",
    "    # max_x = w\n",
    "    # max_y = l\n",
    "    \n",
    "    min_x = minimum(x_fish_sweep_mean)\n",
    "    min_y = minimum(y_fish_sweep_mean)\n",
    "    max_x = maximum(x_fish_sweep_mean)\n",
    "    max_y = maximum(y_fish_sweep_mean)\n",
    "\n",
    "    bin_interval = maximum([(max_y-min_y+2)/n_pos,(max_x-min_x+2)/n_pos])\n",
    "\n",
    "    x_bins = collect(min_x-1:bin_interval:min_x+bin_interval*(n_pos)+1);\n",
    "    y_bins = collect(min_y-1:bin_interval:min_y+bin_interval*(n_pos)+1);\n",
    "\n",
    "    x_bins_mid = (x_bins[1:end-1]+x_bins[2:end])/2\n",
    "    y_bins_mid = (y_bins[1:end-1]+y_bins[2:end])/2;\n",
    "\n",
    "    # Digitize data, then we just count the number\n",
    "    x_digital2 = numpy.digitize(x_fish_sweep_mean, x_bins)\n",
    "    y_digital2 = numpy.digitize(y_fish_sweep_mean, y_bins);\n",
    "    loc_digital2 = (y_digital2.-1).*n_pos.+x_digital2;\n",
    "\n",
    "\n",
    "    function bin_to_px(x, y, offset=true)\n",
    "        if offset\n",
    "            return (x .- 0.5) .* bin_interval .+ (min_x-1), (y .- 0.5) .* bin_interval .+ (min_y-1)\n",
    "        else\n",
    "            return (x .- 0.5) .* bin_interval, (y .- 0.5) .* bin_interval\n",
    "        end\n",
    "    end\n",
    "\n",
    "    function px_to_bin(x, y)\n",
    "        return 0.5 .+ ((x .- (min_x-1)) ./ bin_interval), 0.5 .+ ((y .- (min_y-1)) ./ bin_interval)\n",
    "    end\n",
    "\n",
    "    x_in_bins2, y_in_bins2 = px_to_bin(x_fish_sweep_mean, y_fish_sweep_mean);\n",
    "    \n",
    "    temp = Decoder.get_top_neurons(use_amount, specificity_population_z[mask_tel], specificity_shuffle_z[mask_tel]);\n",
    "    place_candidates_unique = mask_tel[temp];\n",
    "\n",
    "\n",
    "baseline_mean, baseline_std = Decoder.baseline_error(x_in_bins[1:n_sweeps], x_in_bins[1:n_sweeps], bool_index; sample=10)\n",
    "\n",
    "append!(errors_all, [baseline_mean * long_axis_in_mm/40])\n",
    "    \n",
    "    \n",
    "#     A_dF_place_cells = A_dFF[:, place_candidates_unique]\n",
    "\n",
    "#     pred, var, valid = Decoder.rolling_decoder(bool_index, A_dF_place_cells, loc_digital2, activity_bins, activity_shift, n_pos; decoding_window=120, space=120);\n",
    "#     errors = Decoder.get_distance(pred[:, 1], x_in_bins2, pred[:, 2], y_in_bins2);\n",
    "\n",
    "#     append!(errors_all, [nanmedian(errors[bool_index]) * long_axis_in_mm/41])\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19115e-45f4-42f7-9d5b-67e66733ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(errors_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90806cb1-1432-4d98-90aa-afbe99e58425",
   "metadata": {
    "tags": []
   },
   "source": [
    "### test one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e3bab-8284-4c71-8be5-68cf3a720630",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x = minimum(x_fish_sweep_mean)\n",
    "min_y = minimum(y_fish_sweep_mean)\n",
    "max_x = maximum(x_fish_sweep_mean)\n",
    "max_y = maximum(y_fish_sweep_mean)\n",
    "\n",
    "\n",
    "bin_interval = maximum([(max_y-min_y+2)/n_pos,(max_x-min_x+2)/n_pos])\n",
    "\n",
    "x_bins = collect(min_x-1:bin_interval:min_x+bin_interval*(n_pos)+1);\n",
    "y_bins = collect(min_y-1:bin_interval:min_y+bin_interval*(n_pos)+1);\n",
    "\n",
    "x_bins_mid = (x_bins[1:end-1]+x_bins[2:end])/2\n",
    "y_bins_mid = (y_bins[1:end-1]+y_bins[2:end])/2;\n",
    "\n",
    "# Digitize data, then we just count the number\n",
    "x_digital2 = numpy.digitize(x_fish_sweep_mean, x_bins)\n",
    "y_digital2 = numpy.digitize(y_fish_sweep_mean, y_bins);\n",
    "loc_digital2 = (y_digital2.-1).*n_pos.+x_digital2;\n",
    "\n",
    "\n",
    "function bin_to_px(x, y, offset=true)\n",
    "    if offset\n",
    "        return (x .- 0.5) .* bin_interval .+ (min_x-1), (y .- 0.5) .* bin_interval .+ (min_y-1)\n",
    "    else\n",
    "        return (x .- 0.5) .* bin_interval, (y .- 0.5) .* bin_interval\n",
    "    end\n",
    "end\n",
    "\n",
    "function px_to_bin(x, y)\n",
    "    return 0.5 .+ ((x .- (min_x-1)) ./ bin_interval), 0.5 .+ ((y .- (min_y-1)) ./ bin_interval)\n",
    "end\n",
    "\n",
    "x_in_bins2, y_in_bins2 = px_to_bin(x_fish_sweep_mean, y_fish_sweep_mean);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8212262-068f-4d9b-8175-ec9436862719",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"./Decoder_Functions.jl\")\n",
    "include(\"./Decoder_Pipeline.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d6024-8d3e-4774-b59d-fefbdbf73605",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_dF_place_cells = A_dFF[:, place_candidates_unique]\n",
    "\n",
    "pred, var, valid = Decoder.rolling_decoder(bool_index, A_dF_place_cells, loc_digital, activity_bins, activity_shift, n_pos; decoding_window=120);\n",
    "errors = Decoder.get_distance(pred[:, 1], x_in_bins, pred[:, 2], y_in_bins);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7086a0d-b359-4ca8-b55a-8ccda2f428ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = Decoder.get_distance(pred[:, 1], x_in_bins, pred[:, 2], y_in_bins);\n",
    "\n",
    "print(nanmedian(errors[bool_index]) * long_axis_in_mm/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc75f1-8252-4c9f-a074-47201ce4ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,4))\n",
    "plot(x_in_bins)\n",
    "plot(pred[:, 1])\n",
    "xlim(1000, 10000)\n",
    "figure(figsize=(20,4))\n",
    "plot(y_in_bins)\n",
    "plot(pred[:, 2])\n",
    "xlim(1000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f99732-2594-4efd-976d-6ef6e151b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_pc_maps = Decoder.make_basis_maps(A_dF_place_cells, loc_digital, bool_index, n_pos, true)\n",
    "\n",
    "density_map = Float32.(sum([all_pc_maps[:,:,i] .> nanpctile(all_pc_maps[:,:,i], 95) for i in 1:size(all_pc_maps, 3)]))\n",
    "density_map[density_map .== 0] .= 1\n",
    "\n",
    "imshow(density_map', origin=\"lower\"); colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab01d15-2939-4a18-a24c-98956e4a44fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### independend maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf615735-032f-48d1-880f-096c1166dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Decoder.get_top_neurons(1000, population_z[mask_tel], specifity_z[mask_tel])\n",
    "place_candidates_10000 = mask_tel[temp];\n",
    "\n",
    "A_dF_place_cells_10000 = A_dF[:, place_candidates_10000]\n",
    "\n",
    "\n",
    "all_pc_maps = Decoder.make_basis_maps(A_dF_place_cells_10000, loc_digital, bool_index, n_pos, true)\n",
    "\n",
    "indep_matrix = ones(size(all_pc_maps, 3), size(all_pc_maps, 3))\n",
    "@showprogress for i in 1:size(all_pc_maps, 3)\n",
    "    for j in 1:i\n",
    "        indep_matrix[i,j] = nansum(all_pc_maps[:,:,i] .* all_pc_maps[:,:,j]) ./ (sqrt(nansum(all_pc_maps[:,:,i].^2) .* nansum(all_pc_maps[:,:,j].^2)))\n",
    "        indep_matrix[j,i] = indep_matrix[i,j]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef760e6-09e5-497b-aa1b-0c3d7e06a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_indep_sorted = [argmin(sum(indep_matrix, dims=2))[1]] #set the one that is most indep to all others\n",
    "\n",
    "for i in 1:size(all_pc_maps, 3)-1\n",
    "    indep = sum(abs.(indep_matrix[neuron_indep_sorted, :]), dims=1)[1, :]\n",
    "    sort_indep = sortperm(indep)\n",
    "    sort_indep = sort_indep[[!(i in neuron_indep_sorted) for i in sort_indep]]\n",
    "    append!(neuron_indep_sorted, [sort_indep[1]])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035da249-0f9a-450c-9c4a-65ba0cac0e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_sorting = Decoder.get_top_neurons(9000, neuron_indep_sorted, temp)\n",
    "\n",
    "\n",
    "figure(figsize=(20,5))\n",
    "for i in 1:30\n",
    "    \n",
    "    subplot(3, 10, i)\n",
    "    imshow(all_pc_maps[:,1:30,neuron_indep_sorted[i]]', origin=\"lower\", interpolation=\"nearest\")\n",
    "    axis(\"off\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892e6e6-a147-4181-8eeb-99bdf1cffcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_chosen = [place_candidates_unique[1]]\n",
    "\n",
    "left_neurons = copy(place_candidates_unique)\n",
    "\n",
    "\n",
    "A_dF_candidate_cells = @view A_dF[:, place_candidates_unique[1]]\n",
    "\n",
    "pred2, var2, valid2 = Decoder.rolling_decoder(bool_index, A_dF_candidate_cells, loc_digital, activity_bins, activity_shift, n_pos; decoding_window=120);\n",
    "errors2 = Decoder.get_distance(pred2[:, 1], x_in_bins, pred2[:, 2], y_in_bins);\n",
    "\n",
    "errors = [median(errors2[bool_index])]\n",
    "\n",
    "@showprogress for i in 1:10 # include more neurons\n",
    "    \n",
    "    current_min = Inf\n",
    "    current_argmin = NaN\n",
    "    \n",
    "    @showprogress for n in left_neurons\n",
    "        A_dF_candidate_cells = @view A_dF[:, cat(neurons_chosen, [n], dims=1)]\n",
    "        \n",
    "        pred2, var2, valid2 = Decoder.rolling_decoder(bool_index, A_dF_candidate_cells, loc_digital, activity_bins, activity_shift, n_pos; decoding_window=120);\n",
    "        errors2 = Decoder.get_distance(pred2[:, 1], x_in_bins, pred2[:, 2], y_in_bins);\n",
    "        \n",
    "        if nanmedian(errors2[bool_index]) < current_min\n",
    "            current_argmin = copy(n)\n",
    "            current_min = copy(nanmedian(errors2[bool_index]))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    append!(errors, [current_min])\n",
    "    append!(neurons_chosen, [current_argmin])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df199da5-9ddf-498e-9e6e-9f6cf336f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(1:length(neurons_chosen), errors.*(long_axis_in_mm/n_pos))\n",
    "plt.xlabel(\"cells included\")\n",
    "plt.ylabel(\"error [mm]\")\n",
    "plt.xscale(\"log\"); title(\"greedy chosing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d78783-0afb-41b9-8f53-8f8b82c9a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount = [1,2,3,5,7,10,15,20,30,50,100,200, 500, 1000]\n",
    "\n",
    "combined_sorting = Decoder.get_top_neurons(9000, neuron_indep_sorted, temp)\n",
    "\n",
    "place_cells = [place_candidates_unique[combined_sorting[1:x]] for x in amount]\n",
    "\n",
    "\n",
    "error_by_amount_place_cells = DecoderPlots.prepare_subplot4_5(A_dF[:, valid_neurons], place_cells, bool_index, loc_digital, x_in_bins, y_in_bins, n_pos, activity_bins, activity_shift);\n",
    "\n",
    "plt.plot(amount, error_by_amount_place_cells.*(long_axis_in_mm/n_pos))\n",
    "plt.xlabel(\"cells included\")\n",
    "plt.ylabel(\"error [mm]\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc72df6-80f8-406c-848a-1156e0b2d4f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## example_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce033b1-886c-4a07-ac5f-8ab9635eb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_stuff();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed2713-8d77-4e47-a61a-5077b6f4b145",
   "metadata": {
    "tags": []
   },
   "source": [
    "## error by populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bfe7dc-68ba-4d90-aa66-5d9391754c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cells = 1000\n",
    "\n",
    "populations = Dict()\n",
    "\n",
    "n_neurons = size(A_dFF, 2)\n",
    "\n",
    "populations[\"random_cells\"] = Distributions.sample(intersect(valid_neurons, findall(specificity_population_z .< 1)), use_cells, replace=false)\n",
    "\n",
    "labels = [\n",
    "        [\"place_cells\", valid_neurons],\n",
    "        [\"place_cells_tel\", mask_tel],\n",
    "        [\"place_cells_rhomb\", mask_rhomb],\n",
    "        [\"place_cells_mes\", mask_mes],\n",
    "        [\"place_cells_rhomb_mes\", union(mask_mes, mask_rhomb)],\n",
    "        [\"place_cells_optic_tectum\", optic_tectum]\n",
    "]\n",
    "\n",
    "for l in labels\n",
    "    place_cells = Decoder.get_top_neurons(use_cells, specificity_population_z[l[2]], specificity_shuffle_z[l[2]])\n",
    "    populations[l[1]] = l[2][place_cells]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90444eb3-4c35-4fb4-8cca-b64a19228ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(isnan.(specificity_shuffle_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa1722-ad6b-49c2-9e3b-b53aab018112",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(centroid_x_all, centroid_y_all)\n",
    "scatter(centroid_x_all[populations[\"place_cells_rhomb_mes\"]], centroid_y_all[populations[\"place_cells_rhomb_mes\"]])\n",
    "scatter(centroid_x_all[populations[\"place_cells_tel\"]], centroid_y_all[populations[\"place_cells_tel\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdccae4a-71de-44ab-911d-da18e0c2f93e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_by_populations(use_amount, populations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd57bb60-f360-4097-8ce2-adc732557a41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## error by number figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0e35a9-7e27-4590-a1ff-ba6fd9a9bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_amount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029d75d-78c9-454c-a530-4bba11797938",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_amount(space_n=240)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd9e6f-036b-40c2-af46-cbfe0cf9687b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## error by number figure greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67bb57-5a5f-41e2-b125-3dc0fe93b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_amount_greedy(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1645622-b4f8-4809-a5de-79e9ba996f5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## error by long shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8967ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_long_shift()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a15306-5837-4e9d-aa81-ad0a96c6463c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## decoding animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e71bdd-8532-4eec-8ec1-dc810f8112dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoding_animation(activity_bins, activity_shift);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af493d-793b-4b94-af98-0d6366de38ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## heatmap figure\n",
    "\n",
    "mean error of different shifts and bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d37965-931d-494f-85eb-c4b766a456af",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_bin_shift()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
