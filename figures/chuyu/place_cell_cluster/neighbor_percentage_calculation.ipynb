{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12ee01-5172-434d-b3fd-b90c398c00b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!(@isdefined cleanup_hook) && IJulia.push_postexecute_hook(() -> (empty!(In); empty!(Out); GC.gc(true))); cleanup_hook = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b912c67-bb5e-4f76-8d1f-2c06cebd37ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ProgressMeter, PyCall, PyPlot, Images, HDF5,NaNStatistics, Statistics, DSP, Lasso, JLD2\n",
    "using _Data, _Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6153f-aad5-47c8-8f70-4072fb770f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pyimport numpy\n",
    "@pyimport sklearn.decomposition as decomposition\n",
    "@pyimport scipy.stats as stats\n",
    "@pyimport matplotlib.colors as mpl_colors\n",
    "@pyimport matplotlib.cm as cm \n",
    "@pyimport sklearn.cluster as cluster\n",
    "@pyimport sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18096c99-67ec-4ae1-9435-7c0d7b076da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_params = PyDict(pyimport(\"matplotlib\")[\"rcParams\"]);\n",
    "rc_params[\"font.sans-serif\"] = [\"Arial\"];\n",
    "rc_params[\"font.size\"] = 7;\n",
    "rc_params[\"lines.linewidth\"] = 1;\n",
    "rc_params[\"lines.markersize\"] = 4;\n",
    "rc_params[\"xtick.major.size\"] = 2;\n",
    "rc_params[\"ytick.major.size\"] = 2;\n",
    "rc_params[\"xtick.major.pad\"] = 2;\n",
    "rc_params[\"ytick.major.pad\"] = 2;\n",
    "# rc_params[\"axes.labelpad\"] = 2;\n",
    "rc_params[\"axes.spines.right\"] = false\n",
    "rc_params[\"axes.spines.top\"] = false\n",
    "\n",
    "cim(img::Matrix{UInt32}) = CairoImageSurface(img, Cairo.FORMAT_RGB24; flipxy = false) \n",
    "cim(img::Matrix{ARGB32}) = cim(reinterpret(UInt32, img))\n",
    "cim(img::Matrix{RGB24}) = cim(reinterpret(UInt32, img))\n",
    "cim(img::Matrix{UInt8}) = cim(Gray.(reinterpret(N0f8, img)))\n",
    "cim(img::Array{UInt8,3}) = cim(RGB24.(reinterpret(N0f8, img[:,:,1]), reinterpret(N0f8, img[:,:,2]), reinterpret(N0f8, img[:,:,3])));downsample(img,n=4) = +([img[i:n:n*div(size(img,1)-1,n), j:n:n*div(size(img,2)-1,n)] for i = 1:n, j = 1:n]...)/(n*n);\n",
    "downsample(img,n=4) = +([img[i:n:n*div(size(img,1)-1,n), j:n:n*div(size(img,2)-1,n)] for i = 1:n, j = 1:n]...)/(n*n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e4cae-f0f6-4022-8ece-b654084e500c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(\"../../../functions/func_map.jl\")\n",
    "include(\"../../../functions/func_stat.jl\")\n",
    "include(\"../../../functions/func_data.jl\")\n",
    "include(\"../../../functions/func_plot.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96978e6d-377c-4d25-8a0f-c769dd66f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_dict = load(\"/home/chuyu/Notebooks/project_place_cell/figures/chuyu/figure_data_info.jld2\")\n",
    "\n",
    "data_info_all = []\n",
    "for key in keys(data_info_dict)\n",
    "    append!(data_info_all, data_info_dict[key])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5b847-6a6d-4074-a0bb-f1e09d17a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca914f3-7034-49c4-8526-9d4540745251",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = \"chuyu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c794154-9f27-422c-b92c-97ed9850df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "function neighbor_percent(corr_map_pairwise_all_1, corr_map_pairwise_all_2, neighbor_percent_list)\n",
    "    \n",
    "    percent_stay_all_n = fill(NaN32, length(neighbor_percent_list), size(corr_map_pairwise_all_1, 1))\n",
    "    for which_neuron = 1:size(corr_map_pairwise_all_1, 1)\n",
    "        neighbor_rank_1 = reverse(sortperm(corr_map_pairwise_all_1[which_neuron,:]))\n",
    "        neighbor_rank_2 = reverse(sortperm(corr_map_pairwise_all_2[which_neuron,:]))\n",
    "        \n",
    "        valid_neighbors_1 = findall(corr_map_pairwise_all_1[which_neuron,:].>=-1)\n",
    "        valid_neighbors_2 = findall(corr_map_pairwise_all_2[which_neuron,:].>=-1)\n",
    "        \n",
    "        n_neighbors_list = floor.(Int32, neighbor_percent_list.*length(valid_neighbors_1))\n",
    "        \n",
    "        for (i_neighbor, n_neighbors) in enumerate(n_neighbors_list)\n",
    "            top_neighbors_1 = intersect(neighbor_rank_1[1:n_neighbors], valid_neighbors_1)\n",
    "            top_neighbors_2 = intersect(neighbor_rank_2[1:n_neighbors], valid_neighbors_2)\n",
    "            \n",
    "\n",
    "            percent_stay = sum(whether_in(top_neighbors_2,  top_neighbors_1))/length(top_neighbors_1)\n",
    "            percent_stay_all_n[i_neighbor,which_neuron] = percent_stay\n",
    "        end\n",
    "    end \n",
    "    return percent_stay_all_n\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7189e2f0-ea7c-450e-809b-5076d4989349",
   "metadata": {},
   "source": [
    "# Process all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28342c-0412-4380-8d31-b2ad2c5f9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = \"/home/chuyu/Notebooks/project_place_cell/figures/output/sfigure10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12de798-70aa-41db-bda4-0bcd69e1672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"corner_cue_circle\"\n",
    "\n",
    "data_info_all = data_info_dict[key]\n",
    "for which_data = 1:length(data_info_all)\n",
    "data_info = data_info_all[which_data]\n",
    "\n",
    "experiment_filename_1 = data_info[1]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "experiment_filename_2 = data_info[3]\n",
    "server_2 = data_info[4]\n",
    "\n",
    "experimenter = data_info[5]\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "    \n",
    "file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "all_files = readdir(file_folder_1)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(file_folder_1, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "valid_neuron_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "all_files = readdir(file_folder_2)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "println(candidate_filename[which_file])\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "info_filename = joinpath(file_folder_2, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "valid_neuron_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "\n",
    "save_file_name = \"compare_map_results_original.h5\"\n",
    "compare_filename = joinpath(data_path(ds_save_cy_1), save_file_name)\n",
    "file = h5open(compare_filename, \"r\")\n",
    "tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "correct_index = whether_in(tel_place_cell_index, intersect(valid_neuron_1, valid_neuron_2))\n",
    "\n",
    "# orientation-corrected background image and chamber roi image\n",
    "cluster_file = h5open(joinpath(data_path(ds_save_cy_1), \"cluster_analysis.h5\"))\n",
    "corr_map_pairwise_all_1_early = read(cluster_file,\"corr_map_pairwise_all_1_early\")[correct_index, correct_index]\n",
    "corr_map_pairwise_all_1_late = read(cluster_file,\"corr_map_pairwise_all_1_late\")[correct_index, correct_index]\n",
    "corr_map_pairwise_all_1 = read(cluster_file,\"corr_map_pairwise_all_1\")[correct_index, correct_index]\n",
    "corr_map_pairwise_all_2 = read(cluster_file,\"corr_map_pairwise_all_2\")[correct_index, correct_index]\n",
    "anatomy_pairwise_distance = read(cluster_file, \"anatomy_pairwise_distance\")[correct_index, correct_index]\n",
    "close(cluster_file)\n",
    "    \n",
    "\n",
    "\n",
    "corr_map_pairwise_all_1[anatomy_pairwise_distance.<=20] .= -2\n",
    "corr_map_pairwise_all_2[anatomy_pairwise_distance.<=20] .= -2\n",
    "\n",
    "\n",
    "corr_map_pairwise_all_1_early[anatomy_pairwise_distance.<=20] .= -2\n",
    "corr_map_pairwise_all_1_late[anatomy_pairwise_distance.<=20] .= -2;\n",
    "\n",
    "neighbor_percent_list = numpy.linspace(0.02, 1, 50) \n",
    "percent_stay_all_n = neighbor_percent(corr_map_pairwise_all_1, corr_map_pairwise_all_2, neighbor_percent_list)\n",
    "percent_stay_all_n_mean = numpy.mean(percent_stay_all_n, axis = 1);\n",
    "\n",
    "\n",
    "percent_stay_all_n_earlylate = neighbor_percent(corr_map_pairwise_all_1_early, corr_map_pairwise_all_1_late, neighbor_percent_list)\n",
    "percent_stay_all_n_mean_earlylate = numpy.mean(percent_stay_all_n_earlylate, axis = 1);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "figure()\n",
    "plot(neighbor_percent_list, percent_stay_all_n_mean, label= \"s1 vs s2\")\n",
    "plot(neighbor_percent_list, percent_stay_all_n_mean_earlylate, label= \"early vs late\")\n",
    "legend()\n",
    "\n",
    "xlabel(\"k\")\n",
    "ylabel(\"Staying neighbors %\")\n",
    "    \n",
    "title(key)\n",
    "    \n",
    "    \n",
    "h5open(joinpath(data_path(ds_save_analyzer_1), \"cluster_analysis_neighbors.h5\"), \"w\") do file\n",
    "    file[\"neighbor_percent_list\"] = neighbor_percent_list\n",
    "    file[\"percent_stay_all_n_mean_earlylate_percent\"] = percent_stay_all_n_mean_earlylate\n",
    "    file[\"percent_stay_all_n_mean_percent\"] = percent_stay_all_n_mean;  \n",
    "end;\n",
    "        \n",
    "        \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6106780-e204-40b1-a118-81fa0651f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_neuron_nr = []\n",
    "center_neuron_nr = []\n",
    "\n",
    "key = \"corner_cue_circle\"\n",
    "\n",
    "data_info_all = data_info_dict[key]\n",
    "for which_data = 1:length(data_info_all)\n",
    "data_info = data_info_all[which_data]\n",
    "\n",
    "experiment_filename_1 = data_info[1]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "experiment_filename_2 = data_info[3]\n",
    "server_2 = data_info[4]\n",
    "\n",
    "experimenter = data_info[5]\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "save_file_name = \"compare_map_results.h5\"\n",
    "compare_filename = joinpath(data_path(ds_save_cy_1), save_file_name)\n",
    "file = h5open(compare_filename, \"r\")\n",
    "tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "confined_place_cell_index_1 = HDF5.readmmap(file[\"confined_place_cell_index_1\"])\n",
    "confined_place_cell_index_2 = HDF5.readmmap(file[\"confined_place_cell_index_2\"])\n",
    "peak_loc_map_1 = HDF5.readmmap(file[\"peak_all_1\"])\n",
    "peak_loc_map_2 = HDF5.readmmap(file[\"peak_all_2\"])\n",
    "peak_distance_edge_1_mm = HDF5.readmmap(file[\"peak_distance_edge_1_mm\"])\n",
    "close(file)\n",
    "\n",
    "println(extrema(peak_distance_edge_1_mm))\n",
    "\n",
    "median_distance_edge = 3\n",
    "edge_neuron = confined_place_cell_index_1[peak_distance_edge_1_mm.<median_distance_edge]\n",
    "center_neuron = confined_place_cell_index_1[peak_distance_edge_1_mm.>median_distance_edge]\n",
    "\n",
    "edge_neuron_index = whether_in(tel_place_cell_index, edge_neuron)\n",
    "center_neuron_index = whether_in(tel_place_cell_index, center_neuron)\n",
    "\n",
    "    \n",
    "println(length(edge_neuron))\n",
    "  println(length(center_neuron))  \n",
    "    \n",
    "    \n",
    "append!(edge_neuron_nr, length(edge_neuron))\n",
    "append!(center_neuron_nr, length(center_neuron))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b7414-da9a-41f2-bb99-7e721f828ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(edge_neuron_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a3be8-9402-45ef-8b92-b4ed2fe65b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(edge_neuron_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fab348-54f0-40f2-ace5-8ba6a5fab10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(center_neuron_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3312e1-3c78-42ec-bbe8-ea380769c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(center_neuron_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35ea82-2fed-47b6-88b7-122183ec9345",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"corner_cue_circle\"\n",
    "\n",
    "data_info_all = data_info_dict[key]\n",
    "for which_data = 1:length(data_info_all)\n",
    "data_info = data_info_all[which_data]\n",
    "\n",
    "experiment_filename_1 = data_info[1]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "experiment_filename_2 = data_info[3]\n",
    "server_2 = data_info[4]\n",
    "\n",
    "experimenter = data_info[5]\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "all_files = readdir(file_folder_1)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(file_folder_1, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "valid_neuron_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "all_files = readdir(file_folder_2)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "println(candidate_filename[which_file])\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "info_filename = joinpath(file_folder_2, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "valid_neuron_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "\n",
    "save_file_name = \"compare_map_results_original.h5\"\n",
    "compare_filename = joinpath(data_path(ds_save_cy_1), save_file_name)\n",
    "file = h5open(compare_filename, \"r\")\n",
    "tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "correct_index = whether_in(tel_place_cell_index, intersect(valid_neuron_1, valid_neuron_2))\n",
    "    \n",
    "tel_place_cell_index = tel_place_cell_index[correct_index]\n",
    "\n",
    "# orientation-corrected background image and chamber roi image\n",
    "cluster_file = h5open(joinpath(data_path(ds_save_cy_1), \"cluster_analysis.h5\"))\n",
    "corr_map_pairwise_all_1_early = read(cluster_file,\"corr_map_pairwise_all_1_early\")[correct_index, correct_index]\n",
    "corr_map_pairwise_all_1_late = read(cluster_file,\"corr_map_pairwise_all_1_late\")[correct_index, correct_index]\n",
    "corr_map_pairwise_all_1 = read(cluster_file,\"corr_map_pairwise_all_1\")[correct_index, correct_index]\n",
    "corr_map_pairwise_all_2 = read(cluster_file,\"corr_map_pairwise_all_2\")[correct_index, correct_index]\n",
    "anatomy_pairwise_distance = read(cluster_file, \"anatomy_pairwise_distance\")[correct_index, correct_index]\n",
    "close(cluster_file)\n",
    "\n",
    "\n",
    "save_file_name = \"compare_map_results_original.h5\"\n",
    "compare_filename = joinpath(data_path(ds_save_cy_1), save_file_name)\n",
    "file = h5open(compare_filename, \"r\")\n",
    "peak_distance_edge_1_mm = HDF5.readmmap(file[\"peak_distance_edge_1_mm\"])\n",
    "confined_place_cell_index_1 = HDF5.readmmap(file[\"confined_place_cell_index_1\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "median_distance_edge = median(peak_distance_edge_1_mm)\n",
    "edge_neuron = confined_place_cell_index_1[peak_distance_edge_1_mm.<median_distance_edge]\n",
    "center_neuron = confined_place_cell_index_1[peak_distance_edge_1_mm.>median_distance_edge]\n",
    "\n",
    "edge_neuron_index = whether_in(tel_place_cell_index, edge_neuron)\n",
    "center_neuron_index = whether_in(tel_place_cell_index, center_neuron)\n",
    "\n",
    "\n",
    "corr_map_pairwise_all_1[anatomy_pairwise_distance.<=20] .= -2\n",
    "corr_map_pairwise_all_2[anatomy_pairwise_distance.<=20] .= -2\n",
    "\n",
    "corr_map_pairwise_all_1_early[anatomy_pairwise_distance.<=20] .= -2\n",
    "corr_map_pairwise_all_1_late[anatomy_pairwise_distance.<=20] .= -2;\n",
    "\n",
    "\n",
    "corr_map_pairwise_all_1_chosen = corr_map_pairwise_all_1[edge_neuron_index, edge_neuron_index]\n",
    "corr_map_pairwise_all_2_chosen = corr_map_pairwise_all_2[edge_neuron_index, edge_neuron_index]\n",
    "corr_map_pairwise_all_1_early_chosen = corr_map_pairwise_all_1_early[edge_neuron_index, edge_neuron_index]\n",
    "corr_map_pairwise_all_1_late_chosen = corr_map_pairwise_all_1_late[edge_neuron_index, edge_neuron_index]\n",
    "\n",
    "neighbor_percent_list = numpy.linspace(0.02, 1, 50) \n",
    "\n",
    "    \n",
    "percent_stay_all_n = neighbor_percent(corr_map_pairwise_all_1_chosen, corr_map_pairwise_all_2_chosen, neighbor_percent_list)\n",
    "percent_stay_all_n_mean_edge = numpy.mean(percent_stay_all_n, axis = 1);\n",
    "\n",
    "\n",
    "percent_stay_all_n_earlylate = neighbor_percent(corr_map_pairwise_all_1_early_chosen, corr_map_pairwise_all_1_late_chosen, neighbor_percent_list)\n",
    "percent_stay_all_n_mean_earlylate_edge = numpy.mean(percent_stay_all_n_earlylate, axis = 1);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "corr_map_pairwise_all_1_chosen = corr_map_pairwise_all_1[center_neuron_index, center_neuron_index]\n",
    "corr_map_pairwise_all_2_chosen = corr_map_pairwise_all_2[center_neuron_index, center_neuron_index]\n",
    "corr_map_pairwise_all_1_early_chosen = corr_map_pairwise_all_1_early[center_neuron_index, center_neuron_index]\n",
    "corr_map_pairwise_all_1_late_chosen = corr_map_pairwise_all_1_late[center_neuron_index, center_neuron_index]\n",
    "\n",
    "\n",
    "percent_stay_all_n = neighbor_percent(corr_map_pairwise_all_1_chosen, corr_map_pairwise_all_2_chosen, neighbor_percent_list)\n",
    "percent_stay_all_n_mean_center = numpy.mean(percent_stay_all_n, axis = 1);\n",
    "\n",
    "\n",
    "percent_stay_all_n_earlylate = neighbor_percent(corr_map_pairwise_all_1_early_chosen, corr_map_pairwise_all_1_late_chosen, neighbor_percent_list)\n",
    "percent_stay_all_n_mean_earlylate_center = numpy.mean(percent_stay_all_n_earlylate, axis = 1);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "figure()\n",
    "plot(100 .*numpy.linspace(0.02, 1, 50), percent_stay_all_n_mean_edge, label= \"s1 vs s2 edge\", color = \"r\", linestyle=\"dashed\")\n",
    "plot(100 .*numpy.linspace(0.02, 1, 50), percent_stay_all_n_mean_earlylate_edge, label= \"early vs late edge\", color = \"gray\", linestyle=\"dashed\")\n",
    "\n",
    "\n",
    "\n",
    "plot(100 .*numpy.linspace(0.02, 1, 50), percent_stay_all_n_mean_center, label= \"s1 vs s2 center\", color = \"r\")\n",
    "plot(100 .*numpy.linspace(0.02, 1, 50), percent_stay_all_n_mean_earlylate_center, label= \"early vs late center\", color = \"gray\")\n",
    "\n",
    "\n",
    "legend()\n",
    "\n",
    "xlabel(\"Neighbors %\")\n",
    "ylabel(\"Staying neighbors %\")\n",
    "    \n",
    "title(key)\n",
    "    \n",
    "    \n",
    "h5open(joinpath(data_path(ds_save_analyzer_1), \"cluster_analysis_neighbors.h5\"), \"r+\") do file\n",
    "    file[\"edge_neuron_index\"] = collect(edge_neuron_index)\n",
    "    file[\"center_neuron_index\"] = collect(center_neuron_index)\n",
    "    file[\"percent_stay_all_n_mean_edge\"] = percent_stay_all_n_mean_edge;\n",
    "    file[\"percent_stay_all_n_mean_earlylate_edge\"] = percent_stay_all_n_mean_earlylate_edge\n",
    "        \n",
    "    file[\"percent_stay_all_n_mean_center\"] = percent_stay_all_n_mean_center;\n",
    "    file[\"percent_stay_all_n_mean_earlylate_center\"] = percent_stay_all_n_mean_earlylate_center\n",
    "        \n",
    "        \n",
    "end;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff4ddb-ba2d-4c4d-8202-2b2aff2fdb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_all = data_info_dict[key]\n",
    "for which_data = 1:length(data_info_all)\n",
    "data_info = data_info_all[which_data]\n",
    "\n",
    "experiment_filename_1 = data_info[1]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "experiment_filename_2 = data_info[3]\n",
    "server_2 = data_info[4]\n",
    "\n",
    "experimenter = data_info[5]\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "all_files = readdir(file_folder_1)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(file_folder_1, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "valid_neuron_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "all_files = readdir(file_folder_2)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "println(candidate_filename[which_file])\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "info_filename = joinpath(file_folder_2, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "valid_neuron_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "\n",
    "save_file_name = \"compare_map_results_original.h5\"\n",
    "compare_filename = joinpath(data_path(ds_save_cy_1), save_file_name)\n",
    "file = h5open(compare_filename, \"r\")\n",
    "tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "correct_index = whether_in(tel_place_cell_index, intersect(valid_neuron_1, valid_neuron_2))\n",
    "    \n",
    "tel_place_cell_index = tel_place_cell_index[correct_index]\n",
    "\n",
    "\n",
    "# orientation-corrected background image and chamber roi image\n",
    "cluster_file = h5open(joinpath(data_path(ds_save_cy_1), \"cluster_analysis.h5\"))\n",
    "corr_map_pairwise_all_1_early = read(cluster_file,\"corr_map_pairwise_all_1_early\")[correct_index, correct_index]\n",
    "corr_map_pairwise_all_1_late = read(cluster_file,\"corr_map_pairwise_all_1_late\")[correct_index, correct_index]\n",
    "corr_map_pairwise_all_1 = read(cluster_file,\"corr_map_pairwise_all_1\")[correct_index, correct_index]\n",
    "corr_map_pairwise_all_2 = read(cluster_file,\"corr_map_pairwise_all_2\")[correct_index, correct_index]\n",
    "anatomy_pairwise_distance = read(cluster_file, \"anatomy_pairwise_distance\")[correct_index, correct_index]\n",
    "close(cluster_file)\n",
    "\n",
    "\n",
    "corr_map_pairwise_all_1[anatomy_pairwise_distance.<=20] .= -2\n",
    "corr_map_pairwise_all_2[anatomy_pairwise_distance.<=20] .= -2\n",
    "\n",
    "\n",
    "corr_map_pairwise_all_1_early[anatomy_pairwise_distance.<=20] .= -2\n",
    "corr_map_pairwise_all_1_late[anatomy_pairwise_distance.<=20] .= -2;\n",
    "\n",
    "neighbor_percent_list = numpy.linspace(0.02, 1, 50) \n",
    "percent_stay_all_n = neighbor_percent(corr_map_pairwise_all_1, corr_map_pairwise_all_2, neighbor_percent_list)\n",
    "percent_stay_all_n_mean = numpy.mean(percent_stay_all_n, axis = 1);\n",
    "\n",
    "\n",
    "percent_stay_all_n_earlylate = neighbor_percent(corr_map_pairwise_all_1_early, corr_map_pairwise_all_1_late, neighbor_percent_list)\n",
    "percent_stay_all_n_mean_earlylate = numpy.mean(percent_stay_all_n_earlylate, axis = 1);\n",
    "\n",
    "\n",
    "\n",
    "println(stats.wilcoxon(percent_stay_all_n[5,:], percent_stay_all_n_earlylate[5,:],alternative=\"less\"))\n",
    "\n",
    "percent_stay_all_n_mean_random_all = []\n",
    "@showprogress for i_random in 1:1000\n",
    "    random_idx = collect(1:size(corr_map_pairwise_all_1, 1))\n",
    "    random_idx = numpy.random.permutation(random_idx)\n",
    "    percent_stay_all_n_random = neighbor_percent(corr_map_pairwise_all_1, corr_map_pairwise_all_2[random_idx, random_idx], [neighbor_percent_list[5]])\n",
    "    percent_stay_all_n_mean_random = numpy.mean(percent_stay_all_n_random, axis = 1);\n",
    "    append!(percent_stay_all_n_mean_random_all, [percent_stay_all_n_mean_random])\n",
    "end\n",
    "println(neighbor_percent_list[5])\n",
    "println(sum(mean(percent_stay_all_n[5,:]) .< [percent_stay_all_n_mean_random_all[i][1] for i in 1:length(percent_stay_all_n_mean_random_all)])/1000)\n",
    "println(mean(percent_stay_all_n_mean_random_all)) \n",
    "    println(std(percent_stay_all_n_mean_random_all)) \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be932caa-d464-4a93-89aa-8b66810e05c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.4",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
