{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ad3c1-3ab5-433a-80da-73f8b784734c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!(@isdefined cleanup_hook) && IJulia.push_postexecute_hook(() -> (empty!(In); empty!(Out); GC.gc(true))); cleanup_hook = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901f7e5-414f-4b20-99c4-c45c1cfa5905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ProgressMeter, PyCall, PyPlot, Images, HDF5,NaNStatistics, Statistics, DSP, Lasso, JLD2\n",
    "using _Data, _Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c776b95a-c3d1-43d3-b094-9fc486c65680",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter, PyCall, PyPlot, Images, HDF5,NaNStatistics, Statistics, DSP\n",
    "@pyimport numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586aef89-ed96-4bbc-8589-b9910fd49da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pyimport sklearn.metrics as metrics\n",
    "@pyimport scipy.stats as stats\n",
    "@pyimport matplotlib.colors as mpl_colors\n",
    "@pyimport matplotlib.cm as cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e92b9-d26a-41e9-969a-44dad07cb47f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(\"../../../functions/func_map.jl\")\n",
    "include(\"../../../functions/func_stat.jl\")\n",
    "include(\"../../../functions/func_data.jl\")\n",
    "include(\"../../../functions/func_plot.jl\")\n",
    "include(\"../../../functions/utils.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf76ca-49ce-4731-9c44-9c8c8516aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = \"chuyu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d2d12-9b3e-47ef-8a82-3f954e156feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_all = \n",
    "[\n",
    "    [\"20220407_152537\", 4, \"jen\"],\n",
    "    [\"20220406_111526\", 9, \"jen\"],\n",
    "    [\"20220407_090156\", 5, \"jen\"],\n",
    "    [\"20220417_165530\", 2, \"jen\"],\n",
    "    [\"20220406_153842\", 9, \"jen\"],\n",
    "    [\"20220405_171444\", 25, \"jen\"],\n",
    "    [\"20220416_160516\", 6, \"jen\"]\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea0bfd6-bd38-4814-b352-3d4bc37b3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_NMF_mask(cell_index, img_width, img_height, roi_x_idx_all, roi_y_idx_all, roi_centroid_x_all, roi_centroid_y_all, S_all, z_all, M_full, threshold = 0.1)\n",
    "\n",
    "    W = 32\n",
    "    H = 32\n",
    "    for i = cell_index\n",
    "        which_z = z_all[i]\n",
    "        \n",
    "        roi_x1 = roi_x_idx_all[i]\n",
    "        roi_x2 = min(img_width, roi_x1+W-1)\n",
    "        roi_x2 == img_width ? roi_x1 = img_width-W+1 : roi_x1 = roi_x1 \n",
    "        roi_y1 = roi_y_idx_all[i]\n",
    "        roi_y2 = min(img_height, roi_y1+H-1)\n",
    "        roi_y2 == img_height ? roi_y1 = img_height-H+1 : roi_y1 = roi_y1 \n",
    "    \n",
    "    \n",
    "        cur_img_x = round(Int64, roi_centroid_x_all[i] + roi_x1 -1)\n",
    "        cur_img_y = round(Int64,roi_centroid_y_all[i] + roi_y1 -1)\n",
    "        footprint = S_all[:, i]\n",
    "        footprint ./= maximum(footprint)\n",
    "        mask = footprint .>= threshold\n",
    "    \n",
    "        # M.= 0\n",
    "        # M[mask] .= 1\n",
    "        \n",
    "        M = reshape(footprint, (32, 32))\n",
    "        \n",
    "        M_full[roi_x1:roi_x2, roi_y1:roi_y2, which_z] .= M; \n",
    "    end\n",
    "\n",
    "    return M_full\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f69f45-8818-49f0-b90e-f4d062d40a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_data = 2\n",
    "data_info = data_info_all[which_data]\n",
    "\n",
    "experiment_filename_1 = data_info[1]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "\n",
    "experimenter = data_info[end]\n",
    "\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe88337-8f0d-4d30-a249-09ff269dc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMF_filename = joinpath(data_path(ds_save_cy_1), \"NMF_merge.h5\")\n",
    "NMF_file = h5open(NMF_filename, \"r\")\n",
    "neuron_label = HDF5.readmmap(NMF_file[\"neuron_label\"])\n",
    "X_all = HDF5.readmmap(NMF_file[\"X_all\"])\n",
    "Y_all = HDF5.readmmap(NMF_file[\"Y_all\"])\n",
    "Z_all = HDF5.readmmap(NMF_file[\"Z_all\"])\n",
    "close(NMF_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b829a-6577-4536-bb75-6e7438877678",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "all_files = readdir(file_folder_1)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(file_folder_1, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_cell_index = HDF5.readmmap(file[\"place_cell_index\"])\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "close(file)\n",
    "\n",
    "n_neuron = size(place_map_all_1, 3)\n",
    "\n",
    "# whether individual roi belongs to a certain region\n",
    "region_bool_filename = joinpath(data_path(ds_save_cy_1), \"region_roi_bool.h5\")\n",
    "region_bool_file = h5open(region_bool_filename, \"r\")\n",
    "global region_names = read(region_bool_file, \"region_names\")\n",
    "global region_roi_bool = read(region_bool_file, \"region_roi_bool\")\n",
    "close(region_bool_file)\n",
    "\n",
    "\n",
    "# for one merged cell, it belongs to telecephalon if at least one of its roi belongs to telencephalon\n",
    "region_roi_bool_tel = region_roi_bool[:,findall(region_names .== \"Telencephalon -\")][:,1]\n",
    "whether_tel = falses(n_neuron)\n",
    "for which_neuron in Int32.(numpy.unique(neuron_label)[1:end-1])\n",
    "    if sum(region_roi_bool_tel[neuron_label.==which_neuron]) >0\n",
    "        whether_tel[which_neuron] = true\n",
    "    end\n",
    "end\n",
    "\n",
    "tel_place_cell_index = intersect(place_cell_index, findall(whether_tel));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c6aaa-95f7-4639-b060-963152b219f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb9e8c-a0f4-41dc-9292-636425f4f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether individual roi belongs to a certain region\n",
    "anatomy_PF_correlation_filename = joinpath(data_path(ds_save_cy_1), \"anatomy_PF_correlation_2d.h5\")\n",
    "anatomy_PF_correlation_file = h5open(anatomy_PF_correlation_filename, \"r\")\n",
    "corr_map_pairwise_all_1 = read(anatomy_PF_correlation_file, \"corr_map_pairwise_all_1\")\n",
    "anatomy_pairwise_distance = read(anatomy_PF_correlation_file, \"anatomy_pairwise_distance\")\n",
    "anatomy_pairwise_distance_z = read(anatomy_PF_correlation_file, \"anatomy_pairwise_distance_z\")\n",
    "close(anatomy_PF_correlation_file)\n",
    "\n",
    "anatomy_pairwise_distance_copy = copy(anatomy_pairwise_distance)\n",
    "for i in 1:size(anatomy_pairwise_distance_copy, 1)\n",
    "    anatomy_pairwise_distance_copy[i,i] = NaN\n",
    "end\n",
    "\n",
    "corr_map_pairwise_all_1_copy = copy(corr_map_pairwise_all_1)\n",
    "for i in 1:size(corr_map_pairwise_all_1_copy, 1)\n",
    "    corr_map_pairwise_all_1_copy[i,i] = NaN\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c6d0b-a630-423b-bc4b-c54f3706ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMF_filename = joinpath(data_path(ds_save_1), \"NMF.h5\")\n",
    "file = h5open(NMF_filename, \"r\")\n",
    "ds_stack_mean = HDF5.readmmap(file[\"stack_mean\"]) # reference images\n",
    "S_all = HDF5.readmmap(file[\"S_all\"]) # roi mask\n",
    "A_all = HDF5.readmmap(file[\"A_all\"]) # roi activity\n",
    "roi_centroid_x_all = HDF5.readmmap(file[\"roi_centroid_x_all\"]) # centroid x in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "roi_centroid_y_all = HDF5.readmmap(file[\"roi_centroid_y_all\"]) # centroid y in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "roi_x_idx_all = HDF5.readmmap(file[\"roi_x_idx_all\"]) # roi x (for the square, the centroid is located by the mask)\n",
    "roi_y_idx_all = HDF5.readmmap(file[\"roi_y_idx_all\"]) # roi y (for the square, the centroid is located by the mask)\n",
    "z_all = HDF5.readmmap(file[\"z_all\"]) # z for all rois\n",
    "centroid_x_all = HDF5.readmmap(file[\"centroid_x_all\"]) # centroid x\n",
    "centroid_y_all = HDF5.readmmap(file[\"centroid_y_all\"]) # centroid y\n",
    "close(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b98c1-ae28-4adf-8a59-38f90363a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = size(ds_stack_mean, 1)\n",
    "img_height = size(ds_stack_mean, 2)\n",
    "n_z = size(ds_stack_mean, 3)\n",
    "n_sweeps = size(A_all, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821ab21-60d9-47a5-8e83-3ab51c45d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_list = intersect(findall(anatomy_pairwise_distance_copy.<5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6df556-2158-45ac-bfce-095e64c71aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which_pair = numpy.random.choice(1:length(pair_list))\n",
    "which_pair = 23\n",
    "parent_cell_index = tel_place_cell_index[pair_list[which_pair][1]]\n",
    "child_cell_index = tel_place_cell_index[pair_list[which_pair][2]]\n",
    "\n",
    "parent_roi_index = findall(neuron_label.==parent_cell_index)\n",
    "M_full_parent = zeros(Float32, img_width, img_height, n_z)\n",
    "get_NMF_mask(parent_roi_index, img_width, img_height, roi_x_idx_all, roi_y_idx_all, roi_centroid_x_all, roi_centroid_y_all, S_all, z_all, M_full_parent, 0);\n",
    "\n",
    "\n",
    "child_roi_index = findall(neuron_label.==child_cell_index)\n",
    "M_full_child = zeros(Float32, img_width, img_height, n_z)\n",
    "get_NMF_mask(child_roi_index, img_width, img_height, roi_x_idx_all, roi_y_idx_all, roi_centroid_x_all, roi_centroid_y_all, S_all, z_all, M_full_child, 0);\n",
    "\n",
    "sum(M_full_parent.*M_full_child).>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da90a79-244e-45f1-9631-16f5ab356b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_all_parent = z_all[parent_roi_index]\n",
    "z_all_child = z_all[child_roi_index];\n",
    "\n",
    "z_all_union = union(z_all_parent, z_all_child);\n",
    "z_mid = floor(Int32, mean(z_all_union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b54b43-7c1b-4989-becc-6cfa6e3d389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_all_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96fcdf-626a-4eb2-bae9-b91b17c02601",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(dpi=250)\n",
    "\n",
    "subplot(1,2,1)\n",
    "imshow(ds_stack_mean[:,:,z_mid]')\n",
    "xlim(600, size(ds_stack_mean, 1))\n",
    "ylim(100, 400)\n",
    "\n",
    "\n",
    "subplot(1,2,2)\n",
    "# imshow(nanmaximum(ds_stack_mean, dims=3)[:,:,1]')\n",
    "imshow(ds_stack_mean[:,:,z_mid]')\n",
    "imshow(nanmaximum(M_full_parent[:,:,z_all_union], dims=3)[:,:,1]', alpha = 0.3, cmap=\"Greens\")\n",
    "imshow(nanmaximum(M_full_child[:,:,z_all_union], dims=3)[:,:,1]', alpha = 0.3, cmap=\"Reds\")\n",
    "xlim(600, size(ds_stack_mean, 1))\n",
    "ylim(100, 400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b3f047-8019-435e-ba29-7325f1aea159",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_list = intersect(findall(anatomy_pairwise_distance_copy.>10),findall(anatomy_pairwise_distance_copy.<12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e81d20-2d9b-4abe-8661-d89e3d8af046",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_overlap = fill(false, size(anatomy_pairwise_distance))\n",
    "@showprogress for which_pair in 1:length(pair_list)\n",
    "        parent_cell_index = tel_place_cell_index[pair_list[which_pair][1]]\n",
    "        child_cell_index = tel_place_cell_index[pair_list[which_pair][2]]\n",
    "        \n",
    "        parent_roi_index = findall(neuron_label.==parent_cell_index)\n",
    "        M_full_parent = zeros(Float32, img_width, img_height, n_z)\n",
    "        get_NMF_mask(parent_roi_index, img_width, img_height, roi_x_idx_all, roi_y_idx_all, roi_centroid_x_all, roi_centroid_y_all, S_all, z_all, M_full_parent, 0);\n",
    "        \n",
    "        \n",
    "        child_roi_index = findall(neuron_label.==child_cell_index)\n",
    "        M_full_child = zeros(Float32, img_width, img_height, n_z)\n",
    "        get_NMF_mask(child_roi_index, img_width, img_height, roi_x_idx_all, roi_y_idx_all, roi_centroid_x_all, roi_centroid_y_all, S_all, z_all, M_full_child, 0);\n",
    "\n",
    "        mask_overlap[pair_list[which_pair]] = sum(M_full_parent.*M_full_child).>0\n",
    "\n",
    "\n",
    "        # if sum(M_full_parent.*M_full_child).==0\n",
    "        #     println(pair_list[which_pair])\n",
    "        #     println(which_pair)\n",
    "        # end\n",
    "\n",
    "        GC.gc()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceabc62b-f6de-4c16-9474-952c3c8d491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(mask_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9b54f-33f7-43ef-b668-b4efdedd2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which_pair = numpy.random.choice(1:length(pair_list))\n",
    "which_pair = 23\n",
    "parent_cell_index = tel_place_cell_index[pair_list[which_pair][1]]\n",
    "child_cell_index = tel_place_cell_index[pair_list[which_pair][2]]\n",
    "\n",
    "parent_roi_index = findall(neuron_label.==parent_cell_index)[3]\n",
    "M_full_parent = zeros(Float32, img_width, img_height, n_z)\n",
    "get_NMF_mask(parent_roi_index, img_width, img_height, roi_x_idx_all, roi_y_idx_all, roi_centroid_x_all, roi_centroid_y_all, S_all, z_all, M_full_parent, 0);\n",
    "\n",
    "\n",
    "child_roi_index = findall(neuron_label.==child_cell_index)[1]\n",
    "M_full_child = zeros(Float32, img_width, img_height, n_z)\n",
    "get_NMF_mask(child_roi_index, img_width, img_height, roi_x_idx_all, roi_y_idx_all, roi_centroid_x_all, roi_centroid_y_all, S_all, z_all, M_full_child, 0);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91723f-eda6-42b9-9ce0-3503ff09969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_all_parent = z_all[parent_roi_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b485198f-8a73-401f-b650-573fbb63b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_all_child = z_all[child_roi_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a840b9a-a777-4fe3-9fba-89790fa1d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_all_union = union(z_all_parent, z_all_child);\n",
    "z_mid = floor(Int32, mean(z_all_union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0aa28-88ed-492f-904f-1b2cf26e88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(dpi=250)\n",
    "\n",
    "subplot(1,2,1)\n",
    "imshow(ds_stack_mean[:,:,z_mid]')\n",
    "xlim(600, size(ds_stack_mean, 1))\n",
    "ylim(100, 400)\n",
    "\n",
    "\n",
    "subplot(1,2,2)\n",
    "# imshow(nanmaximum(ds_stack_mean, dims=3)[:,:,1]')\n",
    "imshow(ds_stack_mean[:,:,z_mid]')\n",
    "imshow(nanmaximum(M_full_parent[:,:,z_all_union], dims=3)[:,:,1]', alpha = 0.3, cmap=\"Greens\")\n",
    "imshow(nanmaximum(M_full_child[:,:,z_all_union], dims=3)[:,:,1]', alpha = 0.3, cmap=\"Reds\")\n",
    "xlim(600, size(ds_stack_mean, 1))\n",
    "ylim(100, 400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85653655-1b14-4fe9-b5dc-e67d9c3dd5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for which_data = 1:length(data_info_all)\n",
    "data_info = data_info_all[which_data]\n",
    "\n",
    "experiment_filename_1 = data_info[1]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "\n",
    "experimenter = data_info[end]\n",
    "\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "server_alternative = 25\n",
    "ds_save_1_alternative = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_alternative)\" ? \"/data\" : \"/nfs/data$(server_alternative)\")\n",
    "\n",
    "\n",
    "NMF_filename = joinpath(data_path(ds_save_cy_1), \"NMF_merge.h5\")\n",
    "NMF_file = h5open(NMF_filename, \"r\")\n",
    "neuron_label = HDF5.readmmap(NMF_file[\"neuron_label\"])\n",
    "X_all = HDF5.readmmap(NMF_file[\"X_all\"])\n",
    "Y_all = HDF5.readmmap(NMF_file[\"Y_all\"])\n",
    "Z_all = HDF5.readmmap(NMF_file[\"Z_all\"])\n",
    "close(NMF_file)\n",
    "\n",
    "\n",
    "file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "all_files = readdir(file_folder_1)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(file_folder_1, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_cell_index = HDF5.readmmap(file[\"place_cell_index\"])\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "close(file)\n",
    "\n",
    "n_neuron = size(place_map_all_1, 3)\n",
    "\n",
    "# whether individual roi belongs to a certain region\n",
    "region_bool_filename = joinpath(data_path(ds_save_cy_1), \"region_roi_bool.h5\")\n",
    "region_bool_file = h5open(region_bool_filename, \"r\")\n",
    "global region_names = read(region_bool_file, \"region_names\")\n",
    "global region_roi_bool = read(region_bool_file, \"region_roi_bool\")\n",
    "close(region_bool_file)\n",
    "\n",
    "\n",
    "# for one merged cell, it belongs to telecephalon if at least one of its roi belongs to telencephalon\n",
    "region_roi_bool_tel = region_roi_bool[:,findall(region_names .== \"Telencephalon -\")][:,1]\n",
    "whether_tel = falses(n_neuron)\n",
    "for which_neuron in Int32.(numpy.unique(neuron_label)[1:end-1])\n",
    "    if sum(region_roi_bool_tel[neuron_label.==which_neuron]) >0\n",
    "        whether_tel[which_neuron] = true\n",
    "    end\n",
    "end\n",
    "\n",
    "tel_place_cell_index = intersect(place_cell_index, findall(whether_tel));\n",
    "\n",
    "@pyimport sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "# whether individual roi belongs to a certain region\n",
    "anatomy_PF_correlation_filename = joinpath(data_path(ds_save_cy_1), \"anatomy_PF_correlation_2d.h5\")\n",
    "anatomy_PF_correlation_file = h5open(anatomy_PF_correlation_filename, \"r\")\n",
    "corr_map_pairwise_all_1 = read(anatomy_PF_correlation_file, \"corr_map_pairwise_all_1\")\n",
    "anatomy_pairwise_distance = read(anatomy_PF_correlation_file, \"anatomy_pairwise_distance\")\n",
    "anatomy_pairwise_distance_z = read(anatomy_PF_correlation_file, \"anatomy_pairwise_distance_z\")\n",
    "close(anatomy_PF_correlation_file)\n",
    "\n",
    "anatomy_pairwise_distance_copy = copy(anatomy_pairwise_distance)\n",
    "for i in 1:size(anatomy_pairwise_distance_copy, 1)\n",
    "    anatomy_pairwise_distance_copy[i,i] = NaN\n",
    "end\n",
    "\n",
    "corr_map_pairwise_all_1_copy = copy(corr_map_pairwise_all_1)\n",
    "for i in 1:size(corr_map_pairwise_all_1_copy, 1)\n",
    "    corr_map_pairwise_all_1_copy[i,i] = NaN\n",
    "end\n",
    "\n",
    "try\n",
    "    NMF_filename = joinpath(data_path(ds_save_1), \"NMF.h5\")\n",
    "    file = h5open(NMF_filename, \"r\")\n",
    "    global ds_stack_mean = HDF5.readmmap(file[\"stack_mean\"]) # reference images\n",
    "    global S_all = HDF5.readmmap(file[\"S_all\"]) # roi mask\n",
    "    global A_all = HDF5.readmmap(file[\"A_all\"]) # roi activity\n",
    "    global roi_centroid_x_all = HDF5.readmmap(file[\"roi_centroid_x_all\"]) # centroid x in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_centroid_y_all = HDF5.readmmap(file[\"roi_centroid_y_all\"]) # centroid y in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_x_idx_all = HDF5.readmmap(file[\"roi_x_idx_all\"]) # roi x (for the square, the centroid is located by the mask)\n",
    "    global roi_y_idx_all = HDF5.readmmap(file[\"roi_y_idx_all\"]) # roi y (for the square, the centroid is located by the mask)\n",
    "    global z_all = HDF5.readmmap(file[\"z_all\"]) # z for all rois\n",
    "    global centroid_x_all = HDF5.readmmap(file[\"centroid_x_all\"]) # centroid x\n",
    "    global centroid_y_all = HDF5.readmmap(file[\"centroid_y_all\"]) # centroid y\n",
    "    close(file)\n",
    "catch end\n",
    "try\n",
    "    NMF_filename = joinpath(data_path(ds_save_1), \"NMF_no_kappa.h5\")\n",
    "    file = h5open(NMF_filename, \"r\")\n",
    "    global ds_stack_mean = HDF5.readmmap(file[\"stack_mean\"]) # reference images\n",
    "    global S_all = HDF5.readmmap(file[\"S_all\"]) # roi mask\n",
    "    global A_all = HDF5.readmmap(file[\"A_all\"]) # roi activity\n",
    "    global roi_centroid_x_all = HDF5.readmmap(file[\"roi_centroid_x_all\"]) # centroid x in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_centroid_y_all = HDF5.readmmap(file[\"roi_centroid_y_all\"]) # centroid y in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_x_idx_all = HDF5.readmmap(file[\"roi_x_idx_all\"]) # roi x (for the square, the centroid is located by the mask)\n",
    "    global roi_y_idx_all = HDF5.readmmap(file[\"roi_y_idx_all\"]) # roi y (for the square, the centroid is located by the mask)\n",
    "    global z_all = HDF5.readmmap(file[\"z_all\"]) # z for all rois\n",
    "    global centroid_x_all = HDF5.readmmap(file[\"centroid_x_all\"]) # centroid x\n",
    "    global centroid_y_all = HDF5.readmmap(file[\"centroid_y_all\"]) # centroid y\n",
    "    close(file)\n",
    "catch end\n",
    "\n",
    "try\n",
    "    NMF_filename = joinpath(data_path(ds_save_1_alternative), \"NMF.h5\")\n",
    "    file = h5open(NMF_filename, \"r\")\n",
    "    global ds_stack_mean = HDF5.readmmap(file[\"stack_mean\"]) # reference images\n",
    "    global S_all = HDF5.readmmap(file[\"S_all\"]) # roi mask\n",
    "    global A_all = HDF5.readmmap(file[\"A_all\"]) # roi activity\n",
    "    global roi_centroid_x_all = HDF5.readmmap(file[\"roi_centroid_x_all\"]) # centroid x in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_centroid_y_all = HDF5.readmmap(file[\"roi_centroid_y_all\"]) # centroid y in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_x_idx_all = HDF5.readmmap(file[\"roi_x_idx_all\"]) # roi x (for the square, the centroid is located by the mask)\n",
    "    global roi_y_idx_all = HDF5.readmmap(file[\"roi_y_idx_all\"]) # roi y (for the square, the centroid is located by the mask)\n",
    "    global z_all = HDF5.readmmap(file[\"z_all\"]) # z for all rois\n",
    "    global centroid_x_all = HDF5.readmmap(file[\"centroid_x_all\"]) # centroid x\n",
    "    global centroid_y_all = HDF5.readmmap(file[\"centroid_y_all\"]) # centroid y\n",
    "    close(file)\n",
    "catch end\n",
    "try\n",
    "    NMF_filename = joinpath(data_path(ds_save_1_alternative), \"NMF_no_kappa.h5\")\n",
    "    file = h5open(NMF_filename, \"r\")\n",
    "    global ds_stack_mean = HDF5.readmmap(file[\"stack_mean\"]) # reference images\n",
    "    global S_all = HDF5.readmmap(file[\"S_all\"]) # roi mask\n",
    "    global A_all = HDF5.readmmap(file[\"A_all\"]) # roi activity\n",
    "    global roi_centroid_x_all = HDF5.readmmap(file[\"roi_centroid_x_all\"]) # centroid x in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_centroid_y_all = HDF5.readmmap(file[\"roi_centroid_y_all\"]) # centroid y in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_x_idx_all = HDF5.readmmap(file[\"roi_x_idx_all\"]) # roi x (for the square, the centroid is located by the mask)\n",
    "    global roi_y_idx_all = HDF5.readmmap(file[\"roi_y_idx_all\"]) # roi y (for the square, the centroid is located by the mask)\n",
    "    global z_all = HDF5.readmmap(file[\"z_all\"]) # z for all rois\n",
    "    global centroid_x_all = HDF5.readmmap(file[\"centroid_x_all\"]) # centroid x\n",
    "    global centroid_y_all = HDF5.readmmap(file[\"centroid_y_all\"]) # centroid y\n",
    "    close(file)\n",
    "catch end\n",
    "    \n",
    "\n",
    "\n",
    "img_width = size(ds_stack_mean, 1)\n",
    "img_height = size(ds_stack_mean, 2)\n",
    "n_z = size(ds_stack_mean, 3)\n",
    "n_sweeps = size(A_all, 1)\n",
    "\n",
    "\n",
    "pair_list = intersect(findall(anatomy_pairwise_distance_copy.<10))\n",
    "\n",
    "\n",
    "mask_overlap = fill(false, size(anatomy_pairwise_distance))\n",
    "@showprogress for which_pair in 1:length(pair_list)\n",
    "        parent_cell_index = tel_place_cell_index[pair_list[which_pair][1]]\n",
    "        child_cell_index = tel_place_cell_index[pair_list[which_pair][2]]\n",
    "        \n",
    "        parent_roi_index = findall(neuron_label.==parent_cell_index)\n",
    "        M_full_parent = zeros(Float32, img_width, img_height, n_z)\n",
    "        get_NMF_mask(parent_roi_index, img_width, img_height, roi_x_idx_all, roi_y_idx_all, roi_centroid_x_all, roi_centroid_y_all, S_all, z_all, M_full_parent, 0);\n",
    "        \n",
    "        \n",
    "        child_roi_index = findall(neuron_label.==child_cell_index)\n",
    "        M_full_child = zeros(Float32, img_width, img_height, n_z)\n",
    "        get_NMF_mask(child_roi_index, img_width, img_height, roi_x_idx_all, roi_y_idx_all, roi_centroid_x_all, roi_centroid_y_all, S_all, z_all, M_full_child, 0);\n",
    "\n",
    "        mask_overlap[pair_list[which_pair]] = sum(M_full_parent.*M_full_child).>0\n",
    "\n",
    "        GC.gc()\n",
    "end\n",
    "\n",
    "\n",
    "h5open(joinpath(data_path(ds_save_analyzer_1), \"anatomy_PF_correlation_2d.h5\"), \"r+\") do file\n",
    "    if haskey(file, \"mask_overlap\")\n",
    "        delete_object(file, \"mask_overlap\")\n",
    "    end\n",
    "\n",
    "    file[\"mask_overlap\"] = mask_overlap\n",
    "end;\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e817764-61ba-4086-9a75-b79518790cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for which_data = 1:length(data_info_all)\n",
    "\n",
    "data_info = data_info_all[which_data]\n",
    "    println(data_info)\n",
    "experiment_filename_1 = data_info[1]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "\n",
    "experimenter = data_info[end]\n",
    "\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "server_alternative = 25\n",
    "ds_save_1_alternative = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_alternative)\" ? \"/data\" : \"/nfs/data$(server_alternative)\")\n",
    "\n",
    "\n",
    "NMF_filename = joinpath(data_path(ds_save_cy_1), \"NMF_merge.h5\")\n",
    "NMF_file = h5open(NMF_filename, \"r\")\n",
    "neuron_label = HDF5.readmmap(NMF_file[\"neuron_label\"])\n",
    "X_all = HDF5.readmmap(NMF_file[\"X_all\"])\n",
    "Y_all = HDF5.readmmap(NMF_file[\"Y_all\"])\n",
    "Z_all = HDF5.readmmap(NMF_file[\"Z_all\"])\n",
    "close(NMF_file)\n",
    "\n",
    "\n",
    "file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "all_files = readdir(file_folder_1)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(file_folder_1, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_cell_index = HDF5.readmmap(file[\"place_cell_index\"])\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "close(file)\n",
    "\n",
    "n_neuron = size(place_map_all_1, 3)\n",
    "\n",
    "# whether individual roi belongs to a certain region\n",
    "region_bool_filename = joinpath(data_path(ds_save_cy_1), \"region_roi_bool.h5\")\n",
    "region_bool_file = h5open(region_bool_filename, \"r\")\n",
    "global region_names = read(region_bool_file, \"region_names\")\n",
    "global region_roi_bool = read(region_bool_file, \"region_roi_bool\")\n",
    "close(region_bool_file)\n",
    "\n",
    "\n",
    "# for one merged cell, it belongs to telecephalon if at least one of its roi belongs to telencephalon\n",
    "region_roi_bool_tel = region_roi_bool[:,findall(region_names .== \"Telencephalon -\")][:,1]\n",
    "whether_tel = falses(n_neuron)\n",
    "for which_neuron in Int32.(numpy.unique(neuron_label)[1:end-1])\n",
    "    if sum(region_roi_bool_tel[neuron_label.==which_neuron]) >0\n",
    "        whether_tel[which_neuron] = true\n",
    "    end\n",
    "end\n",
    "\n",
    "tel_place_cell_index = intersect(place_cell_index, findall(whether_tel));\n",
    "\n",
    "@pyimport sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "# whether individual roi belongs to a certain region\n",
    "anatomy_PF_correlation_filename = joinpath(data_path(ds_save_cy_1), \"anatomy_PF_correlation_2d.h5\")\n",
    "anatomy_PF_correlation_file = h5open(anatomy_PF_correlation_filename, \"r\")\n",
    "corr_map_pairwise_all_1 = read(anatomy_PF_correlation_file, \"corr_map_pairwise_all_1\")\n",
    "anatomy_pairwise_distance = read(anatomy_PF_correlation_file, \"anatomy_pairwise_distance\")\n",
    "anatomy_pairwise_distance_z = read(anatomy_PF_correlation_file, \"anatomy_pairwise_distance_z\")\n",
    "close(anatomy_PF_correlation_file)\n",
    "\n",
    "anatomy_pairwise_distance_copy = copy(anatomy_pairwise_distance)\n",
    "for i in 1:size(anatomy_pairwise_distance_copy, 1)\n",
    "    anatomy_pairwise_distance_copy[i,i] = NaN\n",
    "end\n",
    "\n",
    "corr_map_pairwise_all_1_copy = copy(corr_map_pairwise_all_1)\n",
    "for i in 1:size(corr_map_pairwise_all_1_copy, 1)\n",
    "    corr_map_pairwise_all_1_copy[i,i] = NaN\n",
    "end\n",
    "\n",
    "try\n",
    "    NMF_filename = joinpath(data_path(ds_save_1), \"NMF.h5\")\n",
    "    file = h5open(NMF_filename, \"r\")\n",
    "    global ds_stack_mean = HDF5.readmmap(file[\"stack_mean\"]) # reference images\n",
    "    global S_all = HDF5.readmmap(file[\"S_all\"]) # roi mask\n",
    "    global A_all = HDF5.readmmap(file[\"A_all\"]) # roi activity\n",
    "    global roi_centroid_x_all = HDF5.readmmap(file[\"roi_centroid_x_all\"]) # centroid x in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_centroid_y_all = HDF5.readmmap(file[\"roi_centroid_y_all\"]) # centroid y in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_x_idx_all = HDF5.readmmap(file[\"roi_x_idx_all\"]) # roi x (for the square, the centroid is located by the mask)\n",
    "    global roi_y_idx_all = HDF5.readmmap(file[\"roi_y_idx_all\"]) # roi y (for the square, the centroid is located by the mask)\n",
    "    global z_all = HDF5.readmmap(file[\"z_all\"]) # z for all rois\n",
    "    global centroid_x_all = HDF5.readmmap(file[\"centroid_x_all\"]) # centroid x\n",
    "    global centroid_y_all = HDF5.readmmap(file[\"centroid_y_all\"]) # centroid y\n",
    "    close(file)\n",
    "catch end\n",
    "try\n",
    "    NMF_filename = joinpath(data_path(ds_save_1), \"NMF_no_kappa.h5\")\n",
    "    file = h5open(NMF_filename, \"r\")\n",
    "    global ds_stack_mean = HDF5.readmmap(file[\"stack_mean\"]) # reference images\n",
    "    global S_all = HDF5.readmmap(file[\"S_all\"]) # roi mask\n",
    "    global A_all = HDF5.readmmap(file[\"A_all\"]) # roi activity\n",
    "    global roi_centroid_x_all = HDF5.readmmap(file[\"roi_centroid_x_all\"]) # centroid x in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_centroid_y_all = HDF5.readmmap(file[\"roi_centroid_y_all\"]) # centroid y in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_x_idx_all = HDF5.readmmap(file[\"roi_x_idx_all\"]) # roi x (for the square, the centroid is located by the mask)\n",
    "    global roi_y_idx_all = HDF5.readmmap(file[\"roi_y_idx_all\"]) # roi y (for the square, the centroid is located by the mask)\n",
    "    global z_all = HDF5.readmmap(file[\"z_all\"]) # z for all rois\n",
    "    global centroid_x_all = HDF5.readmmap(file[\"centroid_x_all\"]) # centroid x\n",
    "    global centroid_y_all = HDF5.readmmap(file[\"centroid_y_all\"]) # centroid y\n",
    "    close(file)\n",
    "catch end\n",
    "\n",
    "try\n",
    "    NMF_filename = joinpath(data_path(ds_save_1_alternative), \"NMF.h5\")\n",
    "    file = h5open(NMF_filename, \"r\")\n",
    "    global ds_stack_mean = HDF5.readmmap(file[\"stack_mean\"]) # reference images\n",
    "    global S_all = HDF5.readmmap(file[\"S_all\"]) # roi mask\n",
    "    global A_all = HDF5.readmmap(file[\"A_all\"]) # roi activity\n",
    "    global roi_centroid_x_all = HDF5.readmmap(file[\"roi_centroid_x_all\"]) # centroid x in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_centroid_y_all = HDF5.readmmap(file[\"roi_centroid_y_all\"]) # centroid y in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_x_idx_all = HDF5.readmmap(file[\"roi_x_idx_all\"]) # roi x (for the square, the centroid is located by the mask)\n",
    "    global roi_y_idx_all = HDF5.readmmap(file[\"roi_y_idx_all\"]) # roi y (for the square, the centroid is located by the mask)\n",
    "    global z_all = HDF5.readmmap(file[\"z_all\"]) # z for all rois\n",
    "    global centroid_x_all = HDF5.readmmap(file[\"centroid_x_all\"]) # centroid x\n",
    "    global centroid_y_all = HDF5.readmmap(file[\"centroid_y_all\"]) # centroid y\n",
    "    close(file)\n",
    "catch end\n",
    "try\n",
    "    NMF_filename = joinpath(data_path(ds_save_1_alternative), \"NMF_no_kappa.h5\")\n",
    "    file = h5open(NMF_filename, \"r\")\n",
    "    global ds_stack_mean = HDF5.readmmap(file[\"stack_mean\"]) # reference images\n",
    "    global S_all = HDF5.readmmap(file[\"S_all\"]) # roi mask\n",
    "    global A_all = HDF5.readmmap(file[\"A_all\"]) # roi activity\n",
    "    global roi_centroid_x_all = HDF5.readmmap(file[\"roi_centroid_x_all\"]) # centroid x in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_centroid_y_all = HDF5.readmmap(file[\"roi_centroid_y_all\"]) # centroid y in the 32*32 image (for the square, the centroid is located by the mask)\n",
    "    global roi_x_idx_all = HDF5.readmmap(file[\"roi_x_idx_all\"]) # roi x (for the square, the centroid is located by the mask)\n",
    "    global roi_y_idx_all = HDF5.readmmap(file[\"roi_y_idx_all\"]) # roi y (for the square, the centroid is located by the mask)\n",
    "    global z_all = HDF5.readmmap(file[\"z_all\"]) # z for all rois\n",
    "    global centroid_x_all = HDF5.readmmap(file[\"centroid_x_all\"]) # centroid x\n",
    "    global centroid_y_all = HDF5.readmmap(file[\"centroid_y_all\"]) # centroid y\n",
    "    close(file)\n",
    "catch end\n",
    "    \n",
    "\n",
    "\n",
    "img_width = size(ds_stack_mean, 1)\n",
    "img_height = size(ds_stack_mean, 2)\n",
    "n_z = size(ds_stack_mean, 3)\n",
    "n_sweeps = size(A_all, 1)\n",
    "\n",
    "\n",
    "pair_list = intersect(findall(anatomy_pairwise_distance_copy.<5))\n",
    "\n",
    "\n",
    "mask_overlap = fill(false, size(anatomy_pairwise_distance))\n",
    "@showprogress for which_pair in 1:length(pair_list)\n",
    "        parent_cell_index = tel_place_cell_index[pair_list[which_pair][1]]\n",
    "        child_cell_index = tel_place_cell_index[pair_list[which_pair][2]]\n",
    "        \n",
    "        parent_roi_index = findall(neuron_label.==parent_cell_index)\n",
    "        M_full_parent = zeros(Float32, img_width, img_height, n_z)\n",
    "        get_NMF_mask(parent_roi_index, img_width, img_height, roi_x_idx_all, roi_y_idx_all, roi_centroid_x_all, roi_centroid_y_all, S_all, z_all, M_full_parent, 0);\n",
    "        \n",
    "        \n",
    "        child_roi_index = findall(neuron_label.==child_cell_index)\n",
    "        M_full_child = zeros(Float32, img_width, img_height, n_z)\n",
    "        get_NMF_mask(child_roi_index, img_width, img_height, roi_x_idx_all, roi_y_idx_all, roi_centroid_x_all, roi_centroid_y_all, S_all, z_all, M_full_child, 0);\n",
    "\n",
    "        mask_overlap[pair_list[which_pair]] = sum(M_full_parent.*M_full_child).>0\n",
    "        if sum(M_full_parent.*M_full_child).==0\n",
    "            println(pair_list[which_pair])\n",
    "            println(which_pair)\n",
    "        end\n",
    "        GC.gc()\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb1c81-3fc8-4007-9bc6-b917a0c2c7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
