{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a216e-930e-444a-986c-1a90ed436404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ProgressMeter, PyCall, PyPlot, Images, HDF5,NaNStatistics, Statistics, DSP, Lasso, JLD2\n",
    "using _Data, _Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff048e54-570b-4236-be33-f5a27cb5d6a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pyimport numpy\n",
    "@pyimport sklearn.decomposition as decomposition\n",
    "@pyimport scipy.stats as stats\n",
    "@pyimport matplotlib.colors as mpl_colors\n",
    "@pyimport matplotlib.cm as cm \n",
    "@pyimport sklearn.cluster as cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31453a66-b46a-4d17-8283-06067d83eabe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rc_params = PyDict(pyimport(\"matplotlib\")[\"rcParams\"]);\n",
    "rc_params[\"font.sans-serif\"] = [\"Arial\"];\n",
    "rc_params[\"font.size\"] = 5;\n",
    "rc_params[\"lines.linewidth\"] = 1;\n",
    "rc_params[\"lines.markersize\"] = 4;\n",
    "rc_params[\"xtick.major.size\"] = 2;\n",
    "rc_params[\"ytick.major.size\"] = 2;\n",
    "rc_params[\"xtick.major.pad\"] = 2;\n",
    "rc_params[\"ytick.major.pad\"] = 2;\n",
    "# rc_params[\"axes.labelpad\"] = 2;\n",
    "rc_params[\"axes.spines.right\"] = false\n",
    "rc_params[\"axes.spines.top\"] = false\n",
    "\n",
    "cim(img::Matrix{UInt32}) = CairoImageSurface(img, Cairo.FORMAT_RGB24; flipxy = false) \n",
    "cim(img::Matrix{ARGB32}) = cim(reinterpret(UInt32, img))\n",
    "cim(img::Matrix{RGB24}) = cim(reinterpret(UInt32, img))\n",
    "cim(img::Matrix{UInt8}) = cim(Gray.(reinterpret(N0f8, img)))\n",
    "cim(img::Array{UInt8,3}) = cim(RGB24.(reinterpret(N0f8, img[:,:,1]), reinterpret(N0f8, img[:,:,2]), reinterpret(N0f8, img[:,:,3])));downsample(img,n=4) = +([img[i:n:n*div(size(img,1)-1,n), j:n:n*div(size(img,2)-1,n)] for i = 1:n, j = 1:n]...)/(n*n);\n",
    "downsample(img,n=4) = +([img[i:n:n*div(size(img,1)-1,n), j:n:n*div(size(img,2)-1,n)] for i = 1:n, j = 1:n]...)/(n*n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df0dbe-45d9-45d7-86ff-ea885476d004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(\"../../../functions/func_map.jl\")\n",
    "include(\"../../../functions/func_stat.jl\")\n",
    "include(\"../../../functions/func_data.jl\")\n",
    "include(\"../../../functions/func_plot.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d22e8-905d-4d13-8279-a031ae54119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_dict = load(\"../figure_data_info.jld2\")\n",
    "\n",
    "data_info_all = []\n",
    "data_info_tog = []\n",
    "job_names = []\n",
    "for key in keys(data_info_dict)\n",
    "    append!(data_info_all, data_info_dict[key])\n",
    "    append!(data_info_tog, [data_info_dict[key]])\n",
    "    append!(job_names, [String(key)])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2c555-dcec-493d-98b7-35eb5b0a8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = \"chuyu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f2af4-3570-42d6-a77e-8cfd622e20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf\n",
    "function plot_mean_density(bins, y_tog; plot_color=\"k\", shade_color=\"gray\", line_color=\"k\", plot_median = true)\n",
    "    \n",
    "    n_bins = length(bins)\n",
    "    x = (bins[1:end-1] + bins[2:end])/2\n",
    "    y = mean(y_tog)\n",
    "    ymax = y + std(y_tog)\n",
    "    ymin = y - std(y_tog);\n",
    "    \n",
    "    cumsum_y_mean = cumsum(mean(y_tog)*(maximum(bins) - minimum(bins))/(n_bins-1))\n",
    "\n",
    "    x_median = numpy.round(numpy.interp(0.5, cumsum_y_mean, x), 2)\n",
    "    x_14 = numpy.round(numpy.interp(0.25, cumsum_y_mean, x), 2)\n",
    "    x_34 = numpy.round(numpy.interp(0.75, cumsum_y_mean, x), 2)\n",
    "    \n",
    "    \n",
    "    plot(x, y, color= plot_color)\n",
    "    fill_between(x, ymax, ymin, color=shade_color, alpha=0.3)\n",
    "    if plot_median\n",
    "        axvline(x_median, color=line_color, label= @sprintf(\"%.2f\",x_median), linestyle=\"dashed\")\n",
    "        # axvline(x_median, color=line_color, label= \"$x_median ($x_14 - $x_34)\")\n",
    "    end\n",
    "    \n",
    "    \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0866b5-92bf-456f-ab82-eaf47bc65b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c314488-8526-46b9-a77c-98c68e974898",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_names_ordered = [\n",
    " \"corner_cue_rotation_whole\"\n",
    " \"landmark_removal\"\n",
    " \"boundary_morphing\"\n",
    " \"job_retangular_half_circle_rotation\"\n",
    "\n",
    "    \n",
    " \"hedgehog_rotation_bottom_out\"\n",
    " \"hedgehog_landmark_removal\"\n",
    " \"hedgehog_circle\"\n",
    " \"corner_cue_circle\"\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c2677-608c-45d2-8f96-2037232cacf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_names_figure = [\n",
    " \"Chamber rotation\"\n",
    " \"Landmark removal\"\n",
    " \"Wall morphing\"\n",
    "    \n",
    " \"Wall rotation\"\n",
    "    \n",
    " \"No change\"\n",
    " \"Landmark removal\"\n",
    " \"Wall morphing\"\n",
    " \"Wall morphing + \\n Landmark removal\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1137352-1240-4b00-bb17-3e5565be3e5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compared with control, original maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a94b50-6e0b-434e-82e4-b6e78de30786",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = \"/home/chuyu/Notebooks/project_place_cell/figures/output/sfigure6/summary/original\"\n",
    "mkpath(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042dda47-8ac0-44ba-9258-7ab8b339ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(5,1.5))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "for (i_job, job_name) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []    \n",
    "    \n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "\n",
    "    close(file)\n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    corr_pv_earlylate_all = HDF5.readmmap(file[\"corr_pv_earlylate_all\"])\n",
    "    corr_pv_earlylate_all_normalized = HDF5.readmmap(file[\"corr_pv_earlylate_all_normalized\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    close(file)\n",
    "        \n",
    "    if job_name != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    corr_pv_all = HDF5.readmmap(file[\"corr_pv_all\"])\n",
    "    corr_pv_all_normalized = HDF5.readmmap(file[\"corr_pv_all_normalized\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "    \n",
    "    \n",
    "    append!(trials_median_tog, nanmedian(corr_trials_all[tel_place_cell_index]))\n",
    "    append!(earlylate_median_tog, nanmedian(corr_earlylate_all[tel_place_cell_index]))\n",
    "        \n",
    "        \n",
    "    append!(trials_all_exp, [corr_trials_all[tel_place_cell_index]])\n",
    "    append!(earlylate_all_exp, [corr_earlylate_all[tel_place_cell_index]])\n",
    "end\n",
    "    \n",
    "\n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"less\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    println(p_value)\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_job*2-1,i_job*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_job*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_job*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "    append!(plot_y_all, trials_median_tog[i] - 0.04)\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 0.03\n",
    "            plot_y_all_sort[i:end] .= plot_y_all_sort[i:end] .- 0.03\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_job*2 + 0.1, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "    \n",
    "\n",
    "    \n",
    "    append!(tick_locs, [i_job*2-0.5])\n",
    "    append!(tick_labels, [])\n",
    "\n",
    "end\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=90)\n",
    "ylabel(\"median PF correlation\")\n",
    "\n",
    "fig.savefig(joinpath(fig_path, \"PF_correlation_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d824f3-a3d2-4f03-9e7b-adedeb63e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(7,2))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "for (i_job, job_name) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []   \n",
    "    \n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    close(file)\n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    pv_map_normalized_early_late = HDF5.readmmap(file[\"pv_map_dFF\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    close(file)\n",
    "        \n",
    "    if job_name != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_dFF\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    valid_index = isfinite.(pv_map_normalized_early_late) .* isfinite.(pv_map_normalized)\n",
    "    append!(trials_median_tog, nanmedian(pv_map_normalized[valid_index]))\n",
    "    append!(earlylate_median_tog, nanmedian(pv_map_normalized_early_late[valid_index]))\n",
    "    \n",
    "\n",
    "    append!(trials_all_exp, [pv_map_normalized[valid_index]])\n",
    "    append!(earlylate_all_exp, [pv_map_normalized_early_late[valid_index]])   \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"less\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    println(p_value)\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_job*2-1,i_job*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_job*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_job*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "    append!(plot_y_all, trials_median_tog[i] - 0.02)\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 0.02\n",
    "            plot_y_all_sort[i:end] .= plot_y_all_sort[i:end] .- 0.02\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_job*2 + 0.1, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    append!(tick_locs, [i_job*2-0.5])\n",
    "    append!(tick_labels, [])\n",
    "\n",
    "end\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=90)\n",
    "ylabel(\"median PV correlation\")\n",
    "fig.savefig(joinpath(fig_path, \"PV_correlation_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726ab26b-238d-4b7b-8cdd-0c601e2b5bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(7,2))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "for (i_job, job_name) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []  \n",
    "    \n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    if job_name != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    corr_pv_all = HDF5.readmmap(file[\"corr_pv_all\"])\n",
    "    corr_pv_all_normalized = HDF5.readmmap(file[\"corr_pv_all_normalized\"])\n",
    "    pv_map = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    corr_pv_earlylate_all = HDF5.readmmap(file[\"corr_pv_earlylate_all\"])\n",
    "    corr_pv_earlylate_all_normalized = HDF5.readmmap(file[\"corr_pv_earlylate_all_normalized\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    pv_map_earlylate = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized_earlylate = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    confined_place_cell_index_early_late = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    append!(trials_median_tog, nanmedian(peak_shift_mm[whether_in(confined_place_cell_index,confined_place_cell_index_early_late)]))\n",
    "    append!(earlylate_median_tog, nanmedian(peak_shift_early_late_mm[whether_in(confined_place_cell_index_early_late, confined_place_cell_index)]))\n",
    "    \n",
    "    append!(trials_all_exp, [peak_shift_mm[whether_in(confined_place_cell_index,confined_place_cell_index_early_late)]])\n",
    "    append!(earlylate_all_exp, [peak_shift_early_late_mm[whether_in(confined_place_cell_index_early_late, confined_place_cell_index)]])   \n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"greater\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    println(p_value)\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_job*2-1,i_job*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_job*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_job*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "    append!(plot_y_all, trials_median_tog[i] - 0.04)\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 2\n",
    "            plot_y_all_sort[i:end] .= plot_y_all_sort[i:end] .- 2\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_job*2 + 0.1, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    append!(tick_locs, [i_job*2-0.5])\n",
    "    append!(tick_labels, [])\n",
    "\n",
    "end\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=45)\n",
    "ylabel(\"median Peak shift (mm)\")\n",
    "\n",
    "ylim(0,45)\n",
    "fig.savefig(joinpath(fig_path, \"peak_shift_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a3e018-30b2-4efd-95ce-19b4aa8af066",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Match angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de64ec8-c20d-4d62-89ce-a1544e8305a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = \"/home/chuyu/Notebooks/project_place_cell/figures/output/sfigure6/summary/match_angle\"\n",
    "mkpath(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4457f-6496-4dfc-b585-f74421ecf761",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(7,1.5))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "for (i_job, job_name) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "\n",
    "    close(file)\n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    corr_pv_earlylate_all = HDF5.readmmap(file[\"corr_pv_earlylate_all\"])\n",
    "    corr_pv_earlylate_all_normalized = HDF5.readmmap(file[\"corr_pv_earlylate_all_normalized\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    close(file)\n",
    "        \n",
    "    if job_name != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchboundary.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    corr_pv_all = HDF5.readmmap(file[\"corr_pv_all\"])\n",
    "    corr_pv_all_normalized = HDF5.readmmap(file[\"corr_pv_all_normalized\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "    \n",
    "    \n",
    "    append!(trials_median_tog, nanmedian(corr_trials_all[tel_place_cell_index]))\n",
    "    append!(earlylate_median_tog, nanmedian(corr_earlylate_all[tel_place_cell_index]))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    plot([i_job*2-1,i_job*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_job*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_job*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "\n",
    "end\n",
    "\n",
    "    \n",
    "    append!(tick_locs, [i_job*2-0.5])\n",
    "    append!(tick_labels, [])\n",
    "\n",
    "end\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=90)\n",
    "ylabel(\"median PF correlation\")\n",
    "\n",
    "fig.savefig(joinpath(fig_path, \"PF_correlation_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18decf48-d5b3-4c61-a3a5-ba46f6fa1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(7,1.5))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "for (i_job, job_name) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    close(file)\n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    pv_map_normalized_early_late = HDF5.readmmap(file[\"pv_map_dFF\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    close(file)\n",
    "        \n",
    "    if job_name != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchboundary.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_dFF\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    valid_index = isfinite.(pv_map_normalized_early_late) .* isfinite.(pv_map_normalized)\n",
    "    append!(trials_median_tog, nanmedian(pv_map_normalized[valid_index]))\n",
    "    append!(earlylate_median_tog, nanmedian(pv_map_normalized_early_late[valid_index]))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    plot([i_job*2-1,i_job*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_job*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_job*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "\n",
    "end\n",
    "\n",
    "    \n",
    "    \n",
    "    append!(tick_locs, [i_job*2-0.5])\n",
    "    append!(tick_labels, [])\n",
    "\n",
    "end\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=90)\n",
    "ylabel(\"median PV correlation\")\n",
    "fig.savefig(joinpath(fig_path, \"PV_correlation_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec37d6-b800-475f-b309-2584ba15441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(7,1))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "for (i_job, job_name) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    if job_name != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchboundary.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    corr_pv_all = HDF5.readmmap(file[\"corr_pv_all\"])\n",
    "    corr_pv_all_normalized = HDF5.readmmap(file[\"corr_pv_all_normalized\"])\n",
    "    pv_map = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    corr_pv_earlylate_all = HDF5.readmmap(file[\"corr_pv_earlylate_all\"])\n",
    "    corr_pv_earlylate_all_normalized = HDF5.readmmap(file[\"corr_pv_earlylate_all_normalized\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    pv_map_earlylate = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized_earlylate = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    confined_place_cell_index_early_late = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    append!(trials_median_tog, nanmedian(peak_shift_mm[whether_in(confined_place_cell_index,confined_place_cell_index_early_late)]))\n",
    "    append!(earlylate_median_tog, nanmedian(peak_shift_early_late_mm[whether_in(confined_place_cell_index_early_late, confined_place_cell_index)]))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    plot([i_job*2-1,i_job*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_job*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_job*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "\n",
    "end\n",
    "\n",
    "    \n",
    "    \n",
    "    append!(tick_locs, [i_job*2-0.5])\n",
    "    append!(tick_labels, [job_name])\n",
    "\n",
    "end\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=45)\n",
    "ylabel(\"median Peak shift (mm)\")\n",
    "\n",
    "ylim(0,45)\n",
    "fig.savefig(joinpath(fig_path, \"peak_shift_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b7a129-cc19-41b6-98ba-6da708fe5022",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Best morphed maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afe9a4-0e0e-4e76-aa8b-32965f11dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = \"/home/chuyu/Notebooks/project_place_cell/figures/output/sfigure6/summary/best\"\n",
    "mkpath(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2254fbb-d058-45b5-91f4-e2424564a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(4.5,0.6))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "for (i_job, job_name) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []\n",
    "    \n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index_1 = HDF5.readmmap(file[\"confined_place_cell_index_1\"])\n",
    "    confined_place_cell_index_2 = HDF5.readmmap(file[\"confined_place_cell_index_2\"])\n",
    "    confined_place_cell_index = intersect(confined_place_cell_index_1, confined_place_cell_index_2)\n",
    "\n",
    "    close(file)\n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late_best.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    corr_pv_earlylate_all = HDF5.readmmap(file[\"corr_pv_earlylate_all\"])\n",
    "    corr_pv_earlylate_all_normalized = HDF5.readmmap(file[\"corr_pv_earlylate_all_normalized\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    close(file)\n",
    "        \n",
    "    if job_name != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    corr_pv_all = HDF5.readmmap(file[\"corr_pv_all\"])\n",
    "    corr_pv_all_normalized = HDF5.readmmap(file[\"corr_pv_all_normalized\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "    \n",
    "    \n",
    "    append!(trials_median_tog, nanmedian(corr_trials_all[tel_place_cell_index]))\n",
    "    append!(earlylate_median_tog, nanmedian(corr_earlylate_all[tel_place_cell_index]))\n",
    "    \n",
    "    append!(trials_all_exp, [corr_trials_all[tel_place_cell_index]])\n",
    "    append!(earlylate_all_exp, [corr_earlylate_all[tel_place_cell_index]])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "i_plot = i_job\n",
    "if i_job>4\n",
    "        i_plot = i_job+1\n",
    "    end\n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"less\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    println(p_value)\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_plot*2-1,i_plot*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_plot*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7, s = 5)\n",
    "    scatter([i_plot*2], [trials_median_tog[i]], color=\"r\", alpha=0.7, s = 5)\n",
    "    append!(plot_y_all, trials_median_tog[i])\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 0.07\n",
    "            plot_y_all_sort[i] = plot_y_all_sort[i-1] -  0.07\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_plot*2 + 0.15, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "\n",
    "    \n",
    "    append!(tick_locs, [i_plot*2-0.5])\n",
    "    append!(tick_labels, [])\n",
    "\n",
    "end\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=90)\n",
    "ylabel(\"PF correlation\")\n",
    "ylim(-0,0.8)\n",
    "fig.savefig(joinpath(fig_path, \"PF_correlation_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276ffa11-7ca9-4cfe-9046-f52545ea86e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(4.5,0.6))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "for (i_job, job_name) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []\n",
    "    \n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index_1 = HDF5.readmmap(file[\"confined_place_cell_index_1\"])\n",
    "    confined_place_cell_index_2 = HDF5.readmmap(file[\"confined_place_cell_index_2\"])\n",
    "    confined_place_cell_index = intersect(confined_place_cell_index_1, confined_place_cell_index_2)\n",
    "    close(file)\n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late_best.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    pv_map_normalized_early_late = HDF5.readmmap(file[\"pv_map_dFF\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    close(file)\n",
    "        \n",
    "    if job_name != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_dFF\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    valid_index = isfinite.(pv_map_normalized_early_late) .* isfinite.(pv_map_normalized)\n",
    "    append!(trials_median_tog, nanmedian(pv_map_normalized[valid_index]))\n",
    "    append!(earlylate_median_tog, nanmedian(pv_map_normalized_early_late[valid_index]))\n",
    "    \n",
    "\n",
    "    append!(trials_all_exp, [pv_map_normalized[valid_index]])\n",
    "    append!(earlylate_all_exp, [pv_map_normalized_early_late[valid_index]])   \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "i_plot = i_job\n",
    "if i_job>4\n",
    "        i_plot = i_job+1\n",
    "    end\n",
    "\n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"less\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    println(p_value)\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_plot*2-1,i_plot*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_plot*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7, s = 5)\n",
    "    scatter([i_plot*2], [trials_median_tog[i]], color=\"r\", alpha=0.7, s = 5)\n",
    "    append!(plot_y_all, trials_median_tog[i])\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 0.07\n",
    "            plot_y_all_sort[i] = plot_y_all_sort[i-1] -  0.07\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_plot*2 + 0.15, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "\n",
    "    \n",
    "    \n",
    "    append!(tick_locs, [i_plot*2-0.5])\n",
    "    append!(tick_labels, [])\n",
    "\n",
    "end\n",
    "\n",
    "yticks([0, 0.2, 0.4, 0.6])\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=90)\n",
    "ylabel(\"PV correlation\")\n",
    "fig.savefig(joinpath(fig_path, \"PV_correlation_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d9dd25-228e-41ac-a57f-e7418b55da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(4.5,0.6))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "for (i_job, job_name) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []  \n",
    "    \n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    if job_name != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index_1 = HDF5.readmmap(file[\"confined_place_cell_index_1\"])\n",
    "    confined_place_cell_index_2 = HDF5.readmmap(file[\"confined_place_cell_index_2\"])\n",
    "    confined_place_cell_index = intersect(confined_place_cell_index_1, confined_place_cell_index_2)\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    corr_pv_all = HDF5.readmmap(file[\"corr_pv_all\"])\n",
    "    corr_pv_all_normalized = HDF5.readmmap(file[\"corr_pv_all_normalized\"])\n",
    "    pv_map = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late_best.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    corr_pv_earlylate_all = HDF5.readmmap(file[\"corr_pv_earlylate_all\"])\n",
    "    corr_pv_earlylate_all_normalized = HDF5.readmmap(file[\"corr_pv_earlylate_all_normalized\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    pv_map_earlylate = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized_earlylate = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    confined_place_cell_index_early_late = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    append!(trials_median_tog, nanmedian(peak_shift_mm[whether_in(confined_place_cell_index,confined_place_cell_index_early_late)]))\n",
    "    append!(earlylate_median_tog, nanmedian(peak_shift_early_late_mm[whether_in(confined_place_cell_index_early_late, confined_place_cell_index)]))\n",
    "    \n",
    "    append!(trials_all_exp, [peak_shift_mm[whether_in(confined_place_cell_index,confined_place_cell_index_early_late)]])\n",
    "    append!(earlylate_all_exp, [peak_shift_early_late_mm[whether_in(confined_place_cell_index_early_late, confined_place_cell_index)]])   \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "i_plot = i_job\n",
    "if i_job>4\n",
    "        i_plot = i_job+1\n",
    "    end\n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"greater\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    println(p_value)\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_plot*2-1,i_plot*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_plot*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7, s = 5)\n",
    "    scatter([i_plot*2], [trials_median_tog[i]], color=\"r\", alpha=0.7, s = 5)\n",
    "    append!(plot_y_all, trials_median_tog[i])\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 2\n",
    "            plot_y_all_sort[i] = plot_y_all_sort[i-1] - 2\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_plot*2 + 0.15, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    append!(tick_locs, [i_plot*2-0.5])\n",
    "    append!(tick_labels, [job_name])\n",
    "\n",
    "end\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=45, ha=\"right\" , rotation_mode=\"anchor\")\n",
    "ylabel(\"PF shift (mm)\")\n",
    "\n",
    "ylim(-1,20)\n",
    "fig.savefig(joinpath(fig_path, \"peak_shift_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bfc432-18af-477f-9ebe-36cf22825e40",
   "metadata": {},
   "source": [
    "# Original + match angle (for wall rotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4f92d-6d59-4b9f-aff0-0f453be2e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = \"/home/chuyu/Notebooks/project_place_cell/figures/output/sfigure6/summary/\"\n",
    "mkpath(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9343bc47-234b-4979-ac7c-cbf64cf5cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_names_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1c6d7-8641-49e7-86a0-92364c6a963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(7,1.5))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "i_plot = 1\n",
    "for (i_job, job_name_original) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name_original]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []\n",
    "    \n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    if job_name_original == \"boundary_morphing\" \n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\") \n",
    "    elseif job_name_original == \"corner_cue_rotation_whole\" || job_name_original == \"job_retangular_half_circle_rotation\" \n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\")\n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    corr_pv_all = HDF5.readmmap(file[\"corr_pv_all\"])\n",
    "    corr_pv_all_normalized = HDF5.readmmap(file[\"corr_pv_all_normalized\"])\n",
    "    pv_map = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    if info_filename == joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\")\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late_original.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    end\n",
    "        \n",
    "    file = h5open(info_filename, \"r\")\n",
    "\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    corr_pv_earlylate_all = HDF5.readmmap(file[\"corr_pv_earlylate_all\"])\n",
    "    corr_pv_earlylate_all_normalized = HDF5.readmmap(file[\"corr_pv_earlylate_all_normalized\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    pv_map_earlylate = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized_earlylate = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    confined_place_cell_index_early_late = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    append!(trials_median_tog, nanmedian(corr_trials_all[tel_place_cell_index]))\n",
    "    append!(earlylate_median_tog, nanmedian(corr_earlylate_all[tel_place_cell_index][isfinite.(corr_trials_all[tel_place_cell_index])]))\n",
    "    \n",
    "    append!(trials_all_exp, [corr_trials_all[tel_place_cell_index]])\n",
    "    append!(earlylate_all_exp, [corr_earlylate_all[tel_place_cell_index]])\n",
    "\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"less\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    println(p_value)\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_plot*2-1,i_plot*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_plot*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_plot*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "    append!(plot_y_all, trials_median_tog[i])\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 0.07\n",
    "            plot_y_all_sort[i] = plot_y_all_sort[i-1] -  0.07\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_plot*2 + 0.15, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "\n",
    "\n",
    "    \n",
    "    append!(tick_locs, [i_plot*2-0.5])\n",
    "    append!(tick_labels, [])\n",
    "if job_name == \"Chamber rotation\"\n",
    "    i_plot +=1\n",
    "end\n",
    "    \n",
    "if job_name == \"Wall rotation\"\n",
    "    i_plot +=2\n",
    "end\n",
    "    i_plot+=1\n",
    "    \n",
    "println(i_plot)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "already_plot = 0\n",
    "for (i_job, job_name_original) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name_original]\n",
    "job_name = job_names_figure[i_job]\n",
    "    \n",
    "if job_name != \"Chamber rotation\" && job_name != \"Wall rotation\"\n",
    "    continue\n",
    "end\n",
    "    \n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []  \n",
    "    \n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "        \n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    if job_name_original != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchboundary.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    corr_pv_all = HDF5.readmmap(file[\"corr_pv_all\"])\n",
    "    corr_pv_all_normalized = HDF5.readmmap(file[\"corr_pv_all_normalized\"])\n",
    "    pv_map = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    corr_pv_earlylate_all = HDF5.readmmap(file[\"corr_pv_earlylate_all\"])\n",
    "    corr_pv_earlylate_all_normalized = HDF5.readmmap(file[\"corr_pv_earlylate_all_normalized\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    pv_map_earlylate = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized_earlylate = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    confined_place_cell_index_early_late = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    append!(trials_median_tog, nanmedian(corr_trials_all[tel_place_cell_index]))\n",
    "    append!(earlylate_median_tog, nanmedian(corr_earlylate_all[tel_place_cell_index][isfinite.(corr_trials_all[tel_place_cell_index])]))\n",
    "    \n",
    "   append!(trials_all_exp, [corr_trials_all[tel_place_cell_index]])\n",
    "    append!(earlylate_all_exp, [corr_earlylate_all[tel_place_cell_index]])\n",
    "\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "i_plot = i_job + 1 +already_plot\n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"less\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    println(p_value)\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_plot*2-1,i_plot*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_plot*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_plot*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "    append!(plot_y_all, trials_median_tog[i])\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 0.07\n",
    "            plot_y_all_sort[i] = plot_y_all_sort[i-1] -  0.07\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_plot*2 + 0.15, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "\n",
    "    \n",
    "    \n",
    "    append!(tick_locs, [i_plot*2-0.5])\n",
    "    append!(tick_labels, [])\n",
    "    already_plot+=1\n",
    "\n",
    "end\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=90)\n",
    "ylabel(\"PF correlation\", labelpad=-1)\n",
    "yticks([-0.3,0, 0.3,0.6])\n",
    "xlim(0, 23)\n",
    "\n",
    "fig.savefig(joinpath(fig_path, \"PF_correlation_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe71160-ae02-4b58-bb7c-db652fbca672",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(7,1.5))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "i_plot = 1\n",
    "for (i_job, job_name_original) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name_original]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []\n",
    "    \n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    if job_name_original == \"boundary_morphing\" \n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\") \n",
    "    elseif job_name_original == \"corner_cue_rotation_whole\" || job_name_original == \"job_retangular_half_circle_rotation\" \n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\")\n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    pv_map = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "        \n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_dFF\"])\n",
    "        \n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    if info_filename == joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\")\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late_original.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    pv_map_normalized_early_late = HDF5.readmmap(file[\"pv_map_dFF\"])\n",
    "\n",
    "    confined_place_cell_index_early_late = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    valid_index = isfinite.(pv_map_normalized_early_late) .* isfinite.(pv_map_normalized)\n",
    "    append!(trials_median_tog, nanmedian(pv_map_normalized[valid_index]))\n",
    "    append!(earlylate_median_tog, nanmedian(pv_map_normalized_early_late[valid_index]))\n",
    "    \n",
    "\n",
    "    append!(trials_all_exp, [pv_map_normalized[valid_index]])\n",
    "    append!(earlylate_all_exp, [pv_map_normalized_early_late[valid_index]])   \n",
    "\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"less\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    println(p_value)\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_plot*2-1,i_plot*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_plot*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_plot*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "    append!(plot_y_all, trials_median_tog[i])\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 0.07\n",
    "            plot_y_all_sort[i] = plot_y_all_sort[i-1] -  0.07\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_plot*2 + 0.15, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "\n",
    "\n",
    "    \n",
    "    append!(tick_locs, [i_plot*2-0.5])\n",
    "    append!(tick_labels, [])\n",
    "if job_name == \"Chamber rotation\"\n",
    "    i_plot +=1\n",
    "end\n",
    "    \n",
    "if job_name == \"Wall rotation\"\n",
    "    i_plot +=2\n",
    "end\n",
    "    i_plot+=1\n",
    "    \n",
    "println(i_plot)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "already_plot = 0\n",
    "for (i_job, job_name_original) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name_original]\n",
    "job_name = job_names_figure[i_job]\n",
    "    \n",
    "if job_name != \"Chamber rotation\" && job_name != \"Wall rotation\"\n",
    "    continue\n",
    "end\n",
    "    \n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []  \n",
    "    \n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "        \n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    if job_name_original != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchboundary.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_dFF\"])\n",
    "\n",
    "\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    corr_pv_earlylate_all = HDF5.readmmap(file[\"corr_pv_earlylate_all\"])\n",
    "    corr_pv_earlylate_all_normalized = HDF5.readmmap(file[\"corr_pv_earlylate_all_normalized\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    pv_map_normalized_early_late = HDF5.readmmap(file[\"pv_map_dFF\"])\n",
    "    confined_place_cell_index_early_late = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "        \n",
    "    valid_index = isfinite.(pv_map_normalized_early_late) .* isfinite.(pv_map_normalized)\n",
    "    append!(trials_median_tog, nanmedian(pv_map_normalized[valid_index]))\n",
    "    append!(earlylate_median_tog, nanmedian(pv_map_normalized_early_late[valid_index]))\n",
    "    \n",
    "\n",
    "    append!(trials_all_exp, [pv_map_normalized[valid_index]])\n",
    "    append!(earlylate_all_exp, [pv_map_normalized_early_late[valid_index]])   \n",
    "\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "i_plot = i_job + 1 +already_plot\n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"less\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    println(p_value)\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_plot*2-1,i_plot*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_plot*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_plot*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "    append!(plot_y_all, trials_median_tog[i])\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 0.07\n",
    "            plot_y_all_sort[i] = plot_y_all_sort[i-1] -  0.07\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_plot*2 + 0.15, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "\n",
    "    \n",
    "    \n",
    "    append!(tick_locs, [i_plot*2-0.5])\n",
    "    append!(tick_labels, [])\n",
    "    already_plot+=1\n",
    "\n",
    "end\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=90)\n",
    "ylabel(\"PV correlation\", labelpad=3)\n",
    "\n",
    "yticks([0, 0.3,0.6])\n",
    "\n",
    "ylim(-0.1,0.75)\n",
    "\n",
    "fig.savefig(joinpath(fig_path, \"PV_correlation_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81de2a-7ba9-4044-8f00-8cd6bd5da5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_names_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bebcba4-b50e-498a-8734-68694e712016",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(7,1.5))\n",
    "tick_locs = []\n",
    "tick_labels = []\n",
    "i_plot = 1\n",
    "for (i_job, job_name_original) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name_original]\n",
    "job_name = job_names_figure[i_job]\n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []  \n",
    "    \n",
    "\n",
    "    \n",
    "for which_data in 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    if job_name_original == \"boundary_morphing\" \n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\") \n",
    "    elseif job_name_original == \"corner_cue_rotation_whole\" || job_name_original == \"job_retangular_half_circle_rotation\" \n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\")\n",
    "    end\n",
    "        \n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    corr_pv_all = HDF5.readmmap(file[\"corr_pv_all\"])\n",
    "    corr_pv_all_normalized = HDF5.readmmap(file[\"corr_pv_all_normalized\"])\n",
    "    pv_map = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    if info_filename == joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\")\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late_original.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    corr_pv_earlylate_all = HDF5.readmmap(file[\"corr_pv_earlylate_all\"])\n",
    "    corr_pv_earlylate_all_normalized = HDF5.readmmap(file[\"corr_pv_earlylate_all_normalized\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    pv_map_earlylate = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized_earlylate = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    confined_place_cell_index_early_late = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    append!(trials_median_tog, nanmedian(peak_shift_mm[whether_in(confined_place_cell_index,confined_place_cell_index_early_late)]))\n",
    "    append!(earlylate_median_tog, nanmedian(peak_shift_early_late_mm[whether_in(confined_place_cell_index_early_late, confined_place_cell_index)]))\n",
    "    \n",
    "    append!(trials_all_exp, [peak_shift_mm[whether_in(confined_place_cell_index,confined_place_cell_index_early_late)]])\n",
    "    append!(earlylate_all_exp, [peak_shift_early_late_mm[whether_in(confined_place_cell_index_early_late, confined_place_cell_index)]])   \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "    \n",
    "println(trials_median_tog)\n",
    "println(earlylate_median_tog)\n",
    "\n",
    "        \n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"greater\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_plot*2-1,i_plot*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_plot*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_plot*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "    append!(plot_y_all, trials_median_tog[i])\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 3\n",
    "            plot_y_all_sort[i] = plot_y_all_sort[i-1] - 3\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_plot*2 + 0.15, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "\n",
    "    \n",
    "    append!(tick_locs, [i_plot*2-0.5])\n",
    "    append!(tick_labels, [job_name])\n",
    "if job_name == \"Chamber rotation\"\n",
    "    i_plot +=1\n",
    "end\n",
    "    \n",
    "if job_name == \"Wall rotation\"\n",
    "    i_plot +=2\n",
    "end\n",
    "    i_plot+=1\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "already_plot = 0\n",
    "for (i_job, job_name_original) in enumerate(job_names_ordered)\n",
    "data_info_all = data_info_dict[job_name_original]\n",
    "job_name = job_names_figure[i_job]\n",
    "    \n",
    "if job_name != \"Chamber rotation\" && job_name != \"Wall rotation\"\n",
    "    continue\n",
    "end\n",
    "    \n",
    "\n",
    "n_bins = 31\n",
    "\n",
    "trials_median_tog = []\n",
    "earlylate_median_tog = []\n",
    "    \n",
    "trials_all_exp = []    \n",
    "earlylate_all_exp = []  \n",
    "    \n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "        \n",
    "    data_info = data_info_all[which_data]\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "     experimenter = data_info[3]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    \n",
    "    \n",
    "    if job_name_original != \"boundary_morphing\"\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchangle.h5\")\n",
    "    else\n",
    "        info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_matchboundary.h5\") \n",
    "    end\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    tel_place_cell_index_1 = HDF5.readmmap(file[\"tel_place_cell_index_1\"])\n",
    "    tel_place_cell_index_2 = HDF5.readmmap(file[\"tel_place_cell_index_2\"])\n",
    "    tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    confined_place_cell_index = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    corr_trials_all = HDF5.readmmap(file[\"corr_trials_all\"])\n",
    "    corr_pv_all = HDF5.readmmap(file[\"corr_pv_all\"])\n",
    "    corr_pv_all_normalized = HDF5.readmmap(file[\"corr_pv_all_normalized\"])\n",
    "    pv_map = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    peak_shift_mm = HDF5.readmmap(file[\"peak_shift_mm\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity_1\"])\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity_2\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1), \"compare_map_results_early_late.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "\n",
    "    corr_earlylate_all = HDF5.readmmap(file[\"corr_earlylate_all\"])\n",
    "    corr_pv_earlylate_all = HDF5.readmmap(file[\"corr_pv_earlylate_all\"])\n",
    "    corr_pv_earlylate_all_normalized = HDF5.readmmap(file[\"corr_pv_earlylate_all_normalized\"])\n",
    "    peak_shift_early_late_mm = HDF5.readmmap(file[\"peak_shift_early_late_mm\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity_1_early\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity_1_late\"])\n",
    "    pv_map_earlylate = HDF5.readmmap(file[\"pv_map\"])\n",
    "    pv_map_normalized_earlylate = HDF5.readmmap(file[\"pv_map_normalized\"])\n",
    "    confined_place_cell_index_early_late = HDF5.readmmap(file[\"confined_place_cell_index\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "    append!(trials_median_tog, nanmedian(peak_shift_mm[whether_in(confined_place_cell_index,confined_place_cell_index_early_late)]))\n",
    "    append!(earlylate_median_tog, nanmedian(peak_shift_early_late_mm[whether_in(confined_place_cell_index_early_late, confined_place_cell_index)]))\n",
    "    \n",
    "        \n",
    "    append!(trials_all_exp, [peak_shift_mm[whether_in(confined_place_cell_index,confined_place_cell_index_early_late)]])\n",
    "    append!(earlylate_all_exp, [peak_shift_early_late_mm[whether_in(confined_place_cell_index_early_late, confined_place_cell_index)]])   \n",
    "    \n",
    "    \n",
    "    \n",
    "end\n",
    "    \n",
    "\n",
    "    \n",
    "i_plot = i_job + 1 +already_plot\n",
    "\n",
    "siginficance_all = []\n",
    "plot_y_all = []\n",
    "for i in 1:length(earlylate_median_tog)\n",
    "    x = reduce(vcat, trials_all_exp[i])\n",
    "    y = reduce(vcat, earlylate_all_exp[i])\n",
    "\n",
    "    valid_neuron = isfinite.(x) .* isfinite.(y)\n",
    "    _,p_value = stats.wilcoxon(x[valid_neuron], y[valid_neuron], alternative = \"greater\")\n",
    "    siginficance = \"n.s.\"\n",
    "    if p_value < 0.01\n",
    "        siginficance = \"*\"\n",
    "    end\n",
    "    if p_value < 1e-3\n",
    "        siginficance = \"**\"\n",
    "    end\n",
    "    if p_value < 1e-5\n",
    "        siginficance = \"***\"\n",
    "    end\n",
    "    append!(siginficance_all, [siginficance])\n",
    "        \n",
    "    \n",
    "    plot([i_plot*2-1,i_plot*2], [earlylate_median_tog[i], trials_median_tog[i]], color=\"gray\")\n",
    "    scatter([i_plot*2-1], [earlylate_median_tog[i]], color=\"gray\", alpha=0.7)\n",
    "    scatter([i_plot*2], [trials_median_tog[i]], color=\"r\", alpha=0.7)\n",
    "    append!(plot_y_all, trials_median_tog[i])\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "end\n",
    "plot_y_all_sort = plot_y_all[sortperm(-plot_y_all)]\n",
    "siginficance_all_sort = siginficance_all[sortperm(-plot_y_all)] \n",
    "\n",
    "for i in 2:length(plot_y_all_sort)\n",
    "    if plot_y_all_sort[i-1] - plot_y_all_sort[i]  < 3\n",
    "            plot_y_all_sort[i] = plot_y_all_sort[i-1] - 3\n",
    "        end\n",
    "    end\n",
    "    \n",
    "for i in 1:length(earlylate_median_tog) \n",
    "    text(i_plot*2 + 0.15, plot_y_all_sort[i], siginficance_all_sort[i])\n",
    "end\n",
    "    \n",
    "    \n",
    "    append!(tick_locs, [i_plot*2-0.5])\n",
    "    append!(tick_labels, [job_name * \"\\n (rotation corrected)\"])\n",
    "    already_plot+=1\n",
    "\n",
    "end\n",
    "\n",
    "xticks(tick_locs, tick_labels, rotation=45, ha=\"right\" , rotation_mode=\"anchor\")\n",
    "ylabel(\"PF shift (mm)\", labelpad=5)\n",
    "xlim(0, 23)\n",
    "\n",
    "ylim(-3,45)\n",
    "fig.savefig(joinpath(fig_path, \"peak_shift_compare_control.pdf\"), bbox_inches=\"tight\",transparent = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694cf34-39ce-492b-8948-c321353a08bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
