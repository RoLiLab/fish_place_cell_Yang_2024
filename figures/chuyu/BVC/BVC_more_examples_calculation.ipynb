{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3919c-59f7-4560-ad32-c30c4a9c289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!(@isdefined cleanup_hook) && IJulia.push_postexecute_hook(() -> (empty!(In); empty!(Out); GC.gc(true))); cleanup_hook = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477e270-6afb-4ff2-970b-ba8f2c58928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter, PyCall, PyPlot, Images, HDF5,NaNStatistics, Statistics, DSP, Lasso, JLD2\n",
    "using _Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2737e493-c7d0-46df-bc16-9a1fbf4db368",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyimport numpy\n",
    "@pyimport sklearn.decomposition as decomposition\n",
    "@pyimport scipy.stats as stats\n",
    "@pyimport sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8a8cf-87d1-4203-a66b-ecfa9226c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_params = PyDict(pyimport(\"matplotlib\")[\"rcParams\"]);\n",
    "rc_params[\"font.sans-serif\"] = [\"Arial\"];\n",
    "rc_params[\"font.size\"] = 7;\n",
    "rc_params[\"lines.linewidth\"] = 1;\n",
    "rc_params[\"lines.markersize\"] = 4;\n",
    "rc_params[\"xtick.major.size\"] = 2;\n",
    "rc_params[\"ytick.major.size\"] = 2;\n",
    "rc_params[\"xtick.major.pad\"] = 2;\n",
    "rc_params[\"ytick.major.pad\"] = 2;\n",
    "# rc_params[\"axes.labelpad\"] = 2;\n",
    "rc_params[\"axes.spines.right\"] = false\n",
    "rc_params[\"axes.spines.top\"] = false\n",
    "\n",
    "cim(img::Matrix{UInt32}) = CairoImageSurface(img, Cairo.FORMAT_RGB24; flipxy = false) \n",
    "cim(img::Matrix{ARGB32}) = cim(reinterpret(UInt32, img))\n",
    "cim(img::Matrix{RGB24}) = cim(reinterpret(UInt32, img))\n",
    "cim(img::Matrix{UInt8}) = cim(Gray.(reinterpret(N0f8, img)))\n",
    "cim(img::Array{UInt8,3}) = cim(RGB24.(reinterpret(N0f8, img[:,:,1]), reinterpret(N0f8, img[:,:,2]), reinterpret(N0f8, img[:,:,3])));downsample(img,n=4) = +([img[i:n:n*div(size(img,1)-1,n), j:n:n*div(size(img,2)-1,n)] for i = 1:n, j = 1:n]...)/(n*n);\n",
    "downsample(img,n=4) = +([img[i:n:n*div(size(img,1)-1,n), j:n:n*div(size(img,2)-1,n)] for i = 1:n, j = 1:n]...)/(n*n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f62acd-adc6-4de4-bf6e-ca0c2bb2971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"/home/chuyu/fish_place_cell_paper/functions/func_map.jl\")\n",
    "include(\"/home/chuyu/fish_place_cell_paper/functions/func_stat.jl\")\n",
    "include(\"/home/chuyu/fish_place_cell_paper/functions/func_data.jl\")\n",
    "include(\"/home/chuyu/fish_place_cell_paper/functions/func_plot.jl\")\n",
    "include(\"/home/chuyu/fish_place_cell_paper/functions/utils.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f4f52-6837-455d-8476-fff6f00e3573",
   "metadata": {},
   "source": [
    "# Example fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b645e1-c1a2-4a0d-b108-1ea4788450f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_filename_1 = \"20230227_155813\"\n",
    "server_1 = 1\n",
    "\n",
    "experiment_filename_2 = \"20230227_165253\"\n",
    "server_2 = 1\n",
    "\n",
    "experiment_filename_3 = \"20230227_175948\"\n",
    "server_3 = 1\n",
    "\n",
    "experimenter = \"chuyu\"\n",
    "analyzer = \"chuyu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b3a07-867b-4477-8678-a2f866eb656e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "ds_save_3 = Dataset(experiment_filename_3, experimenter, gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_3 = Dataset(experiment_filename_3, \"chuyu\", gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\")\n",
    "ds_save_analyzer_3 = Dataset(experiment_filename_3, analyzer, gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b4c8c-8348-41fa-9ebf-35b49ec71f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NMF_filename = joinpath(data_path(ds_save_cy_1), \"NMF_merge.h5\")\n",
    "NMF_file = h5open(NMF_filename, \"r\")\n",
    "global Z_all = HDF5.readmmap(NMF_file[\"Z_all\"])\n",
    "global X_all = HDF5.readmmap(NMF_file[\"X_all\"])\n",
    "global Y_all = HDF5.readmmap(NMF_file[\"Y_all\"])\n",
    "global neuron_label = HDF5.readmmap(NMF_file[\"neuron_label\"])\n",
    "A_dF_1 = HDF5.readmmap(NMF_file[\"A_dF\"])\n",
    "close(NMF_file)\n",
    "\n",
    "NMF_filename = joinpath(data_path(ds_save_cy_2), \"NMF_merge.h5\")\n",
    "NMF_file = h5open(NMF_filename, \"r\")\n",
    "A_dF_2 = HDF5.readmmap(NMF_file[\"A_dF\"])\n",
    "close(NMF_file)\n",
    "\n",
    "NMF_filename = joinpath(data_path(ds_save_cy_3), \"NMF_merge.h5\")\n",
    "NMF_file = h5open(NMF_filename, \"r\")\n",
    "A_dF_3 = HDF5.readmmap(NMF_file[\"A_dF\"])\n",
    "close(NMF_file)\n",
    "\n",
    "n_neuron = length(X_all);\n",
    "\n",
    "# whether individual roi belongs to a certain region\n",
    "region_bool_filename = joinpath(data_path(ds_save_cy_1), \"region_roi_bool.h5\")\n",
    "region_bool_file = h5open(region_bool_filename, \"r\")\n",
    "global region_names = read(region_bool_file, \"region_names\")\n",
    "global region_roi_bool = read(region_bool_file, \"region_roi_bool\")\n",
    "close(region_bool_file)\n",
    "\n",
    "\n",
    "# for one merged cell, it belongs to telecephalon if at least one of its roi belongs to telencephalon\n",
    "region_roi_bool_tel = region_roi_bool[:,findall(region_names .== \"Telencephalon -\")][:,1]\n",
    "whether_tel = falses(n_neuron)\n",
    "for which_neuron in Int32.(numpy.unique(neuron_label)[1:end-1])\n",
    "    if sum(region_roi_bool_tel[neuron_label.==which_neuron]) >0\n",
    "        whether_tel[which_neuron] = true\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "img_bg_1 = h5open(ds_save_1, \"behavior.h5\"; raw = true) do file\n",
    "    read(file, \"img_bg\")\n",
    "end;\n",
    "\n",
    "    \n",
    "global img_bg_end_1 = img_bg_1[:,:,end]\n",
    "\n",
    "\n",
    "global w = size(img_bg_end_1, 1)\n",
    "global l = size(img_bg_end_1, 2)\n",
    "    \n",
    "\n",
    "for_place_calculation_file = h5open(joinpath(data_path(ds_save_cy_1), \"for_place_calculation_chamber_geometry_$(experiment_filename_1)_n100.h5\"))\n",
    "x_bins = read(for_place_calculation_file,\"x_bins\")\n",
    "y_bins = read(for_place_calculation_file,\"y_bins\")\n",
    "close(for_place_calculation_file)\n",
    "\n",
    "\n",
    "# orientation-corrected background image and chamber roi image\n",
    "orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_1), \"chamber_geometry_$(experiment_filename_1).h5\"))\n",
    "chamber_roi_1 = read(orientation_correction_file,\"chamber_roi\")\n",
    "countour_array_1 = read(orientation_correction_file,\"countour_array\")\n",
    "close(orientation_correction_file)\n",
    "\n",
    "\n",
    "# orientation-corrected background image and chamber roi image\n",
    "orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_2), \"chamber_geometry_$(experiment_filename_2).h5\"))\n",
    "chamber_roi_2 = read(orientation_correction_file,\"chamber_roi\")\n",
    "global countour_array_2 = read(orientation_correction_file,\"countour_array\")\n",
    "close(orientation_correction_file)\n",
    "\n",
    "\n",
    "# orientation-corrected background image and chamber roi image\n",
    "orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_3), \"chamber_geometry_$(experiment_filename_3).h5\"))\n",
    "chamber_roi_3 = read(orientation_correction_file,\"chamber_roi\")\n",
    "global countour_array_3 = read(orientation_correction_file,\"countour_array\")\n",
    "close(orientation_correction_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe377c-9e90-4e4c-9b90-0a59f21457e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = readdir(data_path(ds_save_cy_1))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][2]\n",
    "println(save_file_name)\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(data_path(ds_save_cy_1), save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "place_cell_index_1 = HDF5.readmmap(file[\"place_cell_index\"])\n",
    "close(file)\n",
    "\n",
    "place_cell_index_1 = intersect(place_cell_index_1, findall(whether_tel))\n",
    "    \n",
    "all_files = readdir(data_path(ds_save_cy_2))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_2, candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "println(save_file_name)\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(data_path(ds_save_cy_2), save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "all_files = readdir(data_path(ds_save_cy_3))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_3, candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "println(save_file_name)\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(data_path(ds_save_cy_3), save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_3 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "specificity_3 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_3 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_3 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "valid_roi_3 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f32104-8705-4a55-95f5-f4d0a638503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bvc_filename = joinpath(data_path(ds_save_cy_1), \"BVC_tel_newbound.h5\")\n",
    "bvc_file = h5open(bvc_filename, \"r\")\n",
    "corr_diff = read(bvc_file, \"corr_diff\")\n",
    "popt_all_1 = read(bvc_file, \"popt_all_1\")\n",
    "popt_all_2 = read(bvc_file, \"popt_all_2\")\n",
    "popt_all_3 = read(bvc_file, \"popt_all_3\")\n",
    "candidate_neurons = read(bvc_file, \"candidate_neurons\") .+1\n",
    "predict_map_all_1 = read(bvc_file, \"predict_map_all_1\")\n",
    "predict_map_12_all = read(bvc_file, \"predict_map_12_all\")\n",
    "close(bvc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7955fce-9257-4f01-b07b-0104e9f5baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1 = popt_all_1[1, candidate_neurons]\n",
    "d_2 = popt_all_2[1, candidate_neurons]\n",
    "d_3 = popt_all_3[1, candidate_neurons]\n",
    "\n",
    "Φ_1 = popt_all_1[2, candidate_neurons]\n",
    "Φ_2 = popt_all_2[2, candidate_neurons]\n",
    "Φ_3 = popt_all_3[2, candidate_neurons]\n",
    "\n",
    "\n",
    "\n",
    "Φ_threshold = sqrt(2)/2\n",
    "\n",
    "\n",
    "Φ_pass = (numpy.cos(Φ_1) .< -Φ_threshold).*(numpy.cos(Φ_3) .< -Φ_threshold)\n",
    "pass_neurons_1 = candidate_neurons[Φ_pass]\n",
    "Φ_pass = (numpy.cos(Φ_1) .> Φ_threshold).*(numpy.cos(Φ_3) .> Φ_threshold)\n",
    "pass_neurons_2 = candidate_neurons[Φ_pass]\n",
    "pass_neurons = union(pass_neurons_1, pass_neurons_2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67125d27-548a-4ac6-8fd5-172f49206d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "function map_corr_p_value(which_map_1, which_map_2)\n",
    "    mask = findall(isfinite.(which_map_1) .* isfinite.(which_map_2))\n",
    "    n_shuffle = length(mask) - 1\n",
    "    random_map_cov_distribution = fill(NaN32, n_shuffle)\n",
    "\n",
    "    map_1_values = which_map_1[mask]\n",
    "    map_2_values = which_map_2[mask]\n",
    "    map_cov = cov(map_1_values, map_2_values)\n",
    "    for i in 1:n_shuffle\n",
    "        shift = i\n",
    "        map_1_values_shuffle = numpy.roll(map_1_values, shift)\n",
    "        random_map_cov_distribution[i] = cov(map_1_values_shuffle, map_2_values)\n",
    "    end\n",
    "    p_value = sum(random_map_cov_distribution.>map_cov)./length(random_map_cov_distribution)\n",
    "    return p_value\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7931ab-a08b-4592-a09b-5bca16d46ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_map_1_without_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_all_1[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_1[:,:,which_neuron];\n",
    "    pvalue_map_1_without_wall[which_neuron] = map_corr_p_value(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "pvalue_map_1_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_1[:,:,which_neuron];\n",
    "    pvalue_map_1_with_wall[which_neuron] = map_corr_p_value(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "\n",
    "pvalue_map_2_without_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_all_1[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_2[:,:,which_neuron];\n",
    "    pvalue_map_2_without_wall[which_neuron] = map_corr_p_value(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "pvalue_map_2_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_2[:,:,which_neuron];\n",
    "    pvalue_map_2_with_wall[which_neuron] = map_corr_p_value(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "pvalue_map_3_without_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_all_1[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_3[:,:,which_neuron];\n",
    "    pvalue_map_3_without_wall[which_neuron] = map_corr_p_value(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "pvalue_map_3_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_3[:,:,which_neuron];\n",
    "    pvalue_map_3_with_wall[which_neuron] = map_corr_p_value(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "\n",
    "pvalue_map_2_half1_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron = candidate_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_2[:,:,which_neuron];\n",
    "\n",
    "    shift = 0\n",
    "    map1 = which_map_1[55- shift:93 - shift,:];\n",
    "    map2 = which_map_2[55- shift:93 - shift,:];\n",
    "    \n",
    "    pvalue_map_2_half1_with_wall[which_neuron] = map_corr_p_value(map1, map2)\n",
    "end\n",
    "\n",
    "\n",
    "pvalue_map_2_half2_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron = candidate_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_2[:,:,which_neuron];\n",
    "\n",
    "    shift = 40\n",
    "    map1 = which_map_1[55- shift:93 - shift,:];\n",
    "    map2 = which_map_2[55- shift:93 - shift,:];\n",
    "    \n",
    "    pvalue_map_2_half2_with_wall[which_neuron] = map_corr_p_value(map1, map2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45baa2ec-b5fb-4d9f-8f01-aa33347a5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_13 = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron = candidate_neurons\n",
    "    map1 = place_map_all_1[:,:,which_neuron];\n",
    "    map2 = place_map_all_3[:,:,which_neuron];\n",
    "\n",
    "    pvalue_13[which_neuron] = map_corr_p_value(map1, map2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0776b4-8f43-4942-b5f9-d3d34be1e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_map_1_without_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_all_1[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_1[:,:,which_neuron];\n",
    "    prediction_map_1_without_wall[which_neuron] = corr_2d(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "prediction_map_1_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_1[:,:,which_neuron];\n",
    "    prediction_map_1_with_wall[which_neuron] = corr_2d(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "\n",
    "prediction_map_2_without_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_all_1[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_2[:,:,which_neuron];\n",
    "    prediction_map_2_without_wall[which_neuron] = corr_2d(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "prediction_map_2_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_2[:,:,which_neuron];\n",
    "    prediction_map_2_with_wall[which_neuron] = corr_2d(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "prediction_map_3_without_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_all_1[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_3[:,:,which_neuron];\n",
    "    prediction_map_3_without_wall[which_neuron] = corr_2d(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "prediction_map_3_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in candidate_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_3[:,:,which_neuron];\n",
    "    prediction_map_3_with_wall[which_neuron] = corr_2d(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "prediction_map_2_half1_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron = candidate_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_2[:,:,which_neuron];\n",
    "\n",
    "    shift = 0\n",
    "    map1 = which_map_1[55- shift:93 - shift,:];\n",
    "    map2 = which_map_2[55- shift:93 - shift,:];\n",
    "    \n",
    "    prediction_map_2_half1_with_wall[which_neuron] = corr_2d(map1, map2)\n",
    "end\n",
    "\n",
    "\n",
    "prediction_map_2_half2_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron = candidate_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_2[:,:,which_neuron];\n",
    "\n",
    "    shift = 40\n",
    "    map1 = which_map_1[55- shift:93 - shift,:];\n",
    "    map2 = which_map_2[55- shift:93 - shift,:];\n",
    "    \n",
    "    prediction_map_2_half2_with_wall[which_neuron] = corr_2d(map1, map2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f08bbf-897d-4889-9aad-93a04acf01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyimport sklearn.metrics as metrics\n",
    "\n",
    "function find_best_peak(which_map;threshold=8/10,components_size_threshold=20)\n",
    "\n",
    "    components_peaks, img_label_valid, valid_components = map_components_peak(which_map; threshold = threshold, components_size_threshold = components_size_threshold)\n",
    "\n",
    "    peak_values = [numpy.nanpercentile(which_map[img_label_valid .== valid_components[i]], 95) for i in 1:length(valid_components)]\n",
    "    peak_weighted_areas = [numpy.nansum(which_map[img_label_valid .== valid_components[i]]) for i in 1:length(valid_components)]\n",
    "\n",
    "\n",
    "    best_peak = NaN32\n",
    "    if length(peak_values) .> 0\n",
    "        best_peak = components_peaks[findmax(peak_values)[2]]\n",
    "\n",
    "    end\n",
    "\n",
    "    return best_peak\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f062e6-fdb9-4fd8-b38d-65828c26ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_peak_shift_13 = fill(NaN32, n_neuron)\n",
    "@showprogress for neuron_idx in  pass_neurons\n",
    "    map_1 = copy(place_map_all_1[:,:, neuron_idx])\n",
    "    map_3 = copy(place_map_all_3[:,:, neuron_idx])\n",
    "\n",
    "    components_peaks_1, _, valid_components_1 = map_components_peak(map_1, components_size_threshold = 20)\n",
    "    components_peaks_2, _, valid_components_2 = map_components_peak(map_3, components_size_threshold = 20)\n",
    "\n",
    "\n",
    "    pairwise_distances = metrics.pairwise_distances(components_peaks_1, components_peaks_2)\n",
    "    min_distance = minimum(pairwise_distances)\n",
    "    min_peak_shift_13[neuron_idx] = min_distance\n",
    "end\n",
    "\n",
    "low_peak_shift_neuron = findall(min_peak_shift_13.<15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8477afd-3b7a-4efa-852f-6cd936fbb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_neuron = intersect(pass_neurons, findall(pvalue_map_1_without_wall.<0.05), findall(prediction_map_2_with_wall.>prediction_map_2_without_wall), findall(pvalue_map_2_with_wall.<0.05), findall(pvalue_13 .<0.05))\n",
    "\n",
    "BVC_score = (prediction_map_2_with_wall .- prediction_map_2_without_wall)\n",
    "candidate_neuron = candidate_neuron[sortperm(BVC_score[candidate_neuron];rev=true)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb98069-80b5-47b9-b22c-c046831bc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bvc_cell = [51921,39217, 17206, 10414, 3869, 19508, 52748, 14486, 36375, 4960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45cf8f7-01fe-43a3-a267-ac558958c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nonbvc_cell = [42235,40871,37314,1183, 21944, 36012, 46070, 14322, 2841, 7796]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7858a90c-e8fc-4cd3-b873-b966af582dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_map_1_without_wall[plot_bvc_cell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede4b784-85e6-443f-8f5b-eaeea2144cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_map_2_with_wall[plot_bvc_cell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff428df1-76fe-4a51-935b-9ecda94ad729",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_map_3_without_wall[plot_bvc_cell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7022d-f16b-4e48-97c4-78b15c5b1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_13[plot_bvc_cell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6385a-681b-4c6a-81f1-b7ad36f6a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_frame = isfinite.(place_map_all_1[:,:,1]); \n",
    "ymin = findfirst(sum(valid_frame;dims=1).!=0)[2]-1;\n",
    "ymax = findlast(sum(valid_frame;dims=1).!=0)[2]+1;\n",
    "xmin = findfirst(sum(valid_frame;dims=2).!=0)[1]-1;\n",
    "xmax = findlast(sum(valid_frame;dims=2).!=0)[1]+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171d364-5875-472f-8402-4f51d23462fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = \"/home/chuyu/Notebooks/project_place_cell/figures/output/review_figures/bvc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0393c7-95b6-4300-954f-8297154fd2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_neuron = plot_bvc_cell\n",
    "\n",
    "fig = figure(figsize = (40,5*ceil(Int64, length(which_neuron)/10)), dpi=250)\n",
    "\n",
    "which_map = place_map_all_1[:,:,which_neuron];    \n",
    "for i in 1:size(which_map,3)\n",
    "    subplot(3*ceil(Int64, size(which_map,3)/10), 10, i+20*floor(Int32, (i-1)/10))\n",
    "    imshow(which_map[:,:,i]', cmap = \"jet\") \n",
    "\n",
    "    axis(\"off\")\n",
    "    cell_index = which_neuron[i]\n",
    "    score = numpy.round(corr_diff[cell_index],3)\n",
    "    # title(cell_index)\n",
    "    xlim(xmin,xmax)\n",
    "    ylim(ymax,ymin)\n",
    "end\n",
    "\n",
    "which_map = place_map_all_2[:,:,which_neuron];    \n",
    "for i in 1:size(which_map,3)\n",
    "    subplot(3*ceil(Int64, size(which_map,3)/10), 10,i+10+20*floor(Int32, (i-1)/10))\n",
    "    imshow(which_map[:,:,i]', cmap = \"jet\") \n",
    "\n",
    "    axis(\"off\")\n",
    "    cell_index = which_neuron[i]\n",
    "    # title(\"$(cell_index)\" )\n",
    "    xlim(xmin,xmax)\n",
    "    ylim(ymax,ymin)\n",
    "end\n",
    "\n",
    "\n",
    "which_map = place_map_all_3[:,:,which_neuron];    \n",
    "for i in 1:size(which_map,3)\n",
    "    subplot(3*ceil(Int64, size(which_map,3)/10), 10,i+20+20*floor(Int32, (i-1)/10))\n",
    "    imshow(which_map[:,:,i]', cmap = \"jet\") \n",
    "\n",
    "    axis(\"off\")\n",
    "    cell_index = which_neuron[i]\n",
    "    # title(\"$(cell_index)\" )\n",
    "    xlim(xmin,xmax)\n",
    "    ylim(ymax,ymin)\n",
    "end\n",
    "\n",
    "\n",
    "subplots_adjust(left = 0, top = 0.1, right = 0.2, bottom = 0)\n",
    "\n",
    "\n",
    "fig.savefig(joinpath(fig_path, \"bvc_examples.pdf\"), bbox_inches=\"tight\",transparent = true,pad_inches = 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881bac8d-bd62-4cad-87a3-c0694f93d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_neuron = plot_nonbvc_cell\n",
    "\n",
    "fig = figure(figsize = (40,5*ceil(Int64, length(which_neuron)/10)), dpi=250)\n",
    "\n",
    "which_map = place_map_all_1[:,:,which_neuron];    \n",
    "for i in 1:size(which_map,3)\n",
    "    subplot(3*ceil(Int64, size(which_map,3)/10), 10, i+20*floor(Int32, (i-1)/10))\n",
    "    imshow(which_map[:,:,i]', cmap = \"jet\") \n",
    "\n",
    "    axis(\"off\")\n",
    "    cell_index = which_neuron[i]\n",
    "    score = numpy.round(corr_diff[cell_index],3)\n",
    "    # title(cell_index)\n",
    "    xlim(xmin,xmax)\n",
    "    ylim(ymax,ymin)\n",
    "end\n",
    "\n",
    "which_map = place_map_all_2[:,:,which_neuron];    \n",
    "for i in 1:size(which_map,3)\n",
    "    subplot(3*ceil(Int64, size(which_map,3)/10), 10,i+10+20*floor(Int32, (i-1)/10))\n",
    "    imshow(which_map[:,:,i]', cmap = \"jet\") \n",
    "\n",
    "    axis(\"off\")\n",
    "    cell_index = which_neuron[i]\n",
    "    # title(\"$(cell_index)\" )\n",
    "    xlim(xmin,xmax)\n",
    "    ylim(ymax,ymin)\n",
    "end\n",
    "\n",
    "\n",
    "which_map = place_map_all_3[:,:,which_neuron];    \n",
    "for i in 1:size(which_map,3)\n",
    "    subplot(3*ceil(Int64, size(which_map,3)/10), 10,i+20+20*floor(Int32, (i-1)/10))\n",
    "    imshow(which_map[:,:,i]', cmap = \"jet\") \n",
    "\n",
    "    axis(\"off\")\n",
    "    cell_index = which_neuron[i]\n",
    "    # title(\"$(cell_index)\" )\n",
    "    xlim(xmin,xmax)\n",
    "    ylim(ymax,ymin)\n",
    "end\n",
    "\n",
    "\n",
    "subplots_adjust(left = 0, top = 0.1, right = 0.2, bottom = 0)\n",
    "\n",
    "\n",
    "fig.savefig(joinpath(fig_path, \"non_bvc_examples.pdf\"), bbox_inches=\"tight\",transparent = true,pad_inches = 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693707a-0522-4901-8969-2c7d10e3ea6b",
   "metadata": {},
   "source": [
    "# Percentage for all fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff2969-71b1-4b5e-8eb0-6a3d4a843026",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_all = \n",
    "\n",
    "[\n",
    "    [\"20230301_175518\", 7, \"20230301_191802\", 7, \"20230301_202336\", 7, \"chuyu\"],\n",
    "    [\"20230227_155813\", 1, \"20230227_165253\", 1, \"20230227_175948\", 1, \"chuyu\"],\n",
    "    [\"20230301_123207\", 8, \"20230301_132953\", 8, \"20230301_142431\", 8, \"chuyu\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2607053-41e4-47ab-8b93-a6d348c3abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BVC_percentage_all = []\n",
    "BVC_list = []\n",
    "for which_data in 1:length(data_info_all)\n",
    "data_info = data_info_all[which_data]\n",
    "experiment_filename_1 = data_info[1]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "experiment_filename_2 = data_info[3]\n",
    "server_2 = data_info[4]\n",
    "\n",
    "experiment_filename_3 = data_info[5]\n",
    "server_3 = data_info[6]\n",
    "\n",
    "experimenter = \"chuyu\"\n",
    "analyzer = \"chuyu\"\n",
    "\n",
    "\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "ds_save_3 = Dataset(experiment_filename_3, experimenter, gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_3 = Dataset(experiment_filename_3, \"chuyu\", gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\")\n",
    "ds_save_analyzer_3 = Dataset(experiment_filename_3, analyzer, gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\")\n",
    "\n",
    "\n",
    "\n",
    "all_files = readdir(data_path(ds_save_cy_1))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][2]\n",
    "println(save_file_name)\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(data_path(ds_save_cy_1), save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "place_cell_index_1 = HDF5.readmmap(file[\"place_cell_index\"])\n",
    "close(file)\n",
    "    \n",
    "    \n",
    "all_files = readdir(data_path(ds_save_cy_2))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_2, candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "println(save_file_name)\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(data_path(ds_save_cy_2), save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "all_files = readdir(data_path(ds_save_cy_3))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_3, candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "println(save_file_name)\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(data_path(ds_save_cy_3), save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_3 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "specificity_3 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_3 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_3 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "valid_roi_3 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "bvc_filename = joinpath(data_path(ds_save_cy_1), \"BVC_tel_newbound.h5\")\n",
    "bvc_file = h5open(bvc_filename, \"r\")\n",
    "corr_diff = read(bvc_file, \"corr_diff\")\n",
    "popt_all_1 = read(bvc_file, \"popt_all_1\")\n",
    "popt_all_2 = read(bvc_file, \"popt_all_2\")\n",
    "popt_all_3 = read(bvc_file, \"popt_all_3\")\n",
    "candidate_neurons = read(bvc_file, \"candidate_neurons\") .+1\n",
    "predict_map_all_1 = read(bvc_file, \"predict_map_all_1\")\n",
    "predict_map_12_all = read(bvc_file, \"predict_map_12_all\")\n",
    "close(bvc_file)\n",
    "\n",
    "\n",
    "d_1 = popt_all_1[1, candidate_neurons]\n",
    "d_2 = popt_all_2[1, candidate_neurons]\n",
    "d_3 = popt_all_3[1, candidate_neurons]\n",
    "\n",
    "Φ_1 = popt_all_1[2, candidate_neurons]\n",
    "Φ_2 = popt_all_2[2, candidate_neurons]\n",
    "Φ_3 = popt_all_3[2, candidate_neurons]\n",
    "\n",
    "\n",
    "\n",
    "Φ_threshold = sqrt(2)/2\n",
    "\n",
    "\n",
    "Φ_pass = (numpy.cos(Φ_1) .< -Φ_threshold).*(numpy.cos(Φ_3) .< -Φ_threshold)\n",
    "pass_neurons_1 = candidate_neurons[Φ_pass]\n",
    "Φ_pass = (numpy.cos(Φ_1) .> Φ_threshold).*(numpy.cos(Φ_3) .> Φ_threshold)\n",
    "pass_neurons_2 = candidate_neurons[Φ_pass]\n",
    "pass_neurons = union(pass_neurons_1, pass_neurons_2);\n",
    "\n",
    "\n",
    "pvalue_map_1_without_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in pass_neurons\n",
    "    which_map_1 = predict_map_all_1[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_1[:,:,which_neuron];\n",
    "    pvalue_map_1_without_wall[which_neuron] = map_corr_p_value(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "pvalue_map_2_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in pass_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_2[:,:,which_neuron];\n",
    "    pvalue_map_2_with_wall[which_neuron] = map_corr_p_value(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "\n",
    "prediction_map_2_without_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in pass_neurons\n",
    "    which_map_1 = predict_map_all_1[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_2[:,:,which_neuron];\n",
    "    prediction_map_2_without_wall[which_neuron] = corr_2d(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "prediction_map_2_with_wall = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron in pass_neurons\n",
    "    which_map_1 = predict_map_12_all[:,:,which_neuron];\n",
    "    which_map_2 = place_map_all_2[:,:,which_neuron];\n",
    "    prediction_map_2_with_wall[which_neuron] = corr_2d(which_map_1, which_map_2)\n",
    "end\n",
    "\n",
    "pvalue_13 = fill(NaN32, size(place_map_all_1,3))\n",
    "@showprogress for which_neuron = pass_neurons\n",
    "    map1 = place_map_all_1[:,:,which_neuron];\n",
    "    map2 = place_map_all_3[:,:,which_neuron];\n",
    "\n",
    "    pvalue_13[which_neuron] = map_corr_p_value(map1, map2)\n",
    "end   \n",
    "    \n",
    "BVC_neuron = intersect(pass_neurons, findall(pvalue_map_1_without_wall.<0.05), findall(prediction_map_2_with_wall.>prediction_map_2_without_wall), findall(pvalue_map_2_with_wall.<0.05), findall(pvalue_13 .<0.05))\n",
    "println(length(BVC_neuron))\n",
    "\n",
    "    \n",
    "BVC_score = (prediction_map_2_with_wall .- prediction_map_2_without_wall)\n",
    "BVC_neuron = BVC_neuron[sortperm(BVC_score[BVC_neuron];rev=true)]\n",
    "BVC_percentage = length(BVC_neuron)./length(pass_neurons)\n",
    "\n",
    "\n",
    "println(BVC_percentage)\n",
    "    \n",
    "append!(BVC_percentage_all, BVC_percentage)\n",
    "append!(BVC_list, [BVC_neuron])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7658be-108d-42ba-9fb4-f6189a21fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_list = []\n",
    "tel_neuron_list = []\n",
    "for which_data in 1:length(data_info_all)\n",
    "data_info = data_info_all[which_data]\n",
    "experiment_filename_1 = data_info[1]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "experiment_filename_2 = data_info[3]\n",
    "server_2 = data_info[4]\n",
    "\n",
    "experiment_filename_3 = data_info[5]\n",
    "server_3 = data_info[6]\n",
    "\n",
    "experimenter = \"chuyu\"\n",
    "analyzer = \"chuyu\"\n",
    "\n",
    "\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "ds_save_3 = Dataset(experiment_filename_3, experimenter, gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_3 = Dataset(experiment_filename_3, \"chuyu\", gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\")\n",
    "ds_save_analyzer_3 = Dataset(experiment_filename_3, analyzer, gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\")\n",
    "\n",
    "\n",
    "NMF_filename = joinpath(data_path(ds_save_cy_1), \"NMF_merge.h5\")\n",
    "NMF_file = h5open(NMF_filename, \"r\")\n",
    "global Z_all = HDF5.readmmap(NMF_file[\"Z_all\"])\n",
    "global X_all = HDF5.readmmap(NMF_file[\"X_all\"])\n",
    "global Y_all = HDF5.readmmap(NMF_file[\"Y_all\"])\n",
    "global neuron_label = HDF5.readmmap(NMF_file[\"neuron_label\"])\n",
    "A_dF_1 = HDF5.readmmap(NMF_file[\"A_dF\"])\n",
    "close(NMF_file)\n",
    "\n",
    "\n",
    "n_neuron = length(X_all);\n",
    "\n",
    "# whether individual roi belongs to a certain region\n",
    "region_bool_filename = joinpath(data_path(ds_save_cy_1), \"region_roi_bool.h5\")\n",
    "region_bool_file = h5open(region_bool_filename, \"r\")\n",
    "global region_names = read(region_bool_file, \"region_names\")\n",
    "global region_roi_bool = read(region_bool_file, \"region_roi_bool\")\n",
    "close(region_bool_file)\n",
    "\n",
    "\n",
    "# for one merged cell, it belongs to telecephalon if at least one of its roi belongs to telencephalon\n",
    "region_roi_bool_tel = region_roi_bool[:,findall(region_names .== \"Telencephalon -\")][:,1]\n",
    "whether_tel = falses(n_neuron)\n",
    "for which_neuron in Int32.(numpy.unique(neuron_label)[1:end-1])\n",
    "    if sum(region_roi_bool_tel[neuron_label.==which_neuron]) >0\n",
    "        whether_tel[which_neuron] = true\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "all_files = readdir(data_path(ds_save_cy_1))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][2]\n",
    "println(save_file_name)\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(data_path(ds_save_cy_1), save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "place_cell_index_1 = HDF5.readmmap(file[\"place_cell_index\"])\n",
    "close(file)\n",
    "place_cell_index_1 = intersect(place_cell_index_1, findall(whether_tel))\n",
    "\n",
    "    \n",
    "    \n",
    "all_files = readdir(data_path(ds_save_cy_2))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_2, candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "println(save_file_name)\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(data_path(ds_save_cy_2), save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "all_files = readdir(data_path(ds_save_cy_3))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_3, candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "println(save_file_name)\n",
    "n_bins = save_file_name[end-4:end-3]\n",
    "info_filename = joinpath(data_path(ds_save_cy_3), save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_3 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "specificity_3 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_3 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_3 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "valid_roi_1 = findall(isfinite.(specificity_1))\n",
    "valid_roi_2 = findall(isfinite.(specificity_2))\n",
    "valid_roi_3 = findall(isfinite.(specificity_3))\n",
    "\n",
    "append!(PC_list, [intersect(place_cell_index_1, valid_roi_1, valid_roi_2, valid_roi_3)])\n",
    "append!(tel_neuron_list, [intersect(findall(whether_tel), valid_roi_1, valid_roi_2, valid_roi_3)])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88115330-d743-4b08-bdbb-3bdc18657df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_neurons_all = []\n",
    "\n",
    "for which_data in 1:length(data_info_all)\n",
    "data_info = data_info_all[which_data]\n",
    "experiment_filename_1 = data_info[1]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "experiment_filename_2 = data_info[3]\n",
    "server_2 = data_info[4]\n",
    "\n",
    "experiment_filename_3 = data_info[5]\n",
    "server_3 = data_info[6]\n",
    "\n",
    "experimenter = \"chuyu\"\n",
    "analyzer = \"chuyu\"\n",
    "\n",
    "\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "ds_save_3 = Dataset(experiment_filename_3, experimenter, gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_3 = Dataset(experiment_filename_3, \"chuyu\", gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\")\n",
    "ds_save_analyzer_3 = Dataset(experiment_filename_3, analyzer, gethostname() == \"roli-$(server_3)\" ? \"/data\" : \"/nfs/data$(server_3)\")\n",
    "\n",
    "\n",
    "\n",
    "bvc_filename = joinpath(data_path(ds_save_cy_1), \"BVC_tel_newbound.h5\")\n",
    "bvc_file = h5open(bvc_filename, \"r\")\n",
    "corr_diff = read(bvc_file, \"corr_diff\")\n",
    "popt_all_1 = read(bvc_file, \"popt_all_1\")\n",
    "popt_all_2 = read(bvc_file, \"popt_all_2\")\n",
    "popt_all_3 = read(bvc_file, \"popt_all_3\")\n",
    "candidate_neurons = read(bvc_file, \"candidate_neurons\") .+1\n",
    "predict_map_all_1 = read(bvc_file, \"predict_map_all_1\")\n",
    "predict_map_12_all = read(bvc_file, \"predict_map_12_all\")\n",
    "close(bvc_file)\n",
    "\n",
    "\n",
    "d_1 = popt_all_1[1, candidate_neurons]\n",
    "d_2 = popt_all_2[1, candidate_neurons]\n",
    "d_3 = popt_all_3[1, candidate_neurons]\n",
    "\n",
    "Φ_1 = popt_all_1[2, candidate_neurons]\n",
    "Φ_2 = popt_all_2[2, candidate_neurons]\n",
    "Φ_3 = popt_all_3[2, candidate_neurons]\n",
    "\n",
    "\n",
    "\n",
    "Φ_threshold = sqrt(2)/2\n",
    "\n",
    "\n",
    "Φ_pass = (numpy.cos(Φ_1) .< -Φ_threshold).*(numpy.cos(Φ_3) .< -Φ_threshold)\n",
    "pass_neurons_1 = candidate_neurons[Φ_pass]\n",
    "Φ_pass = (numpy.cos(Φ_1) .> Φ_threshold).*(numpy.cos(Φ_3) .> Φ_threshold)\n",
    "pass_neurons_2 = candidate_neurons[Φ_pass]\n",
    "pass_neurons = union(pass_neurons_1, pass_neurons_2);\n",
    "append!(pass_neurons_all, [pass_neurons])\n",
    "\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75fc675-2935-4158-9122-43a69a5bffd0",
   "metadata": {},
   "source": [
    "# BVC percenttage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774f681-a0e0-4f20-895f-b0c82d4f8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "BVC_percentage_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922ab88-78b5-462a-9cfa-ed8e2dda8795",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(BVC_percentage_all) .* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b8591-4186-4cf5-85b7-7d40347465b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(BVC_percentage_all).* 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f87747-b570-4b24-9975-10506eb8ec79",
   "metadata": {},
   "source": [
    "# Candidate length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff3544-8f0a-4565-b1f3-a6646f03b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "[length(x) for x in pass_neurons_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52904f89-9bab-43bf-ac8f-cad834080b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean([length(x) for x in pass_neurons_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea1de2-deec-4558-b8cd-6bedccec07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "std([length(x) for x in pass_neurons_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ab626c-6454-4b2f-a58b-b3d67788e792",
   "metadata": {},
   "source": [
    "# BVC in candidate non PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8d352e-fb71-4c75-8b69-1f618d51f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:length(pass_neurons_all)\n",
    "    println((length(BVC_list[i]) - length(intersect(PC_list[i], BVC_list[i])))/(length(pass_neurons_all[i]) - length(intersect(PC_list[i], pass_neurons_all[i]))))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62ce81-3227-4d3d-80e6-ca8320ca7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean([\n",
    "0.04734073641145529\n",
    "0.050724637681159424\n",
    "0.048280907095830286\n",
    "]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330911b-1fcb-4630-a3f5-f47f598d20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "std([\n",
    "0.04734073641145529\n",
    "0.050724637681159424\n",
    "0.048280907095830286\n",
    "] .* 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ac5fa-df5b-4965-ad3b-057959fa0926",
   "metadata": {},
   "source": [
    "# BVC in candidate PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf6eee-54ca-40dc-85c4-6b6435923c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:length(pass_neurons_all)\n",
    "    println(length(intersect(PC_list[i], BVC_list[i]))/length(intersect(PC_list[i], pass_neurons_all[i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855705a2-6ff9-458e-baa4-77e5889cde18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean([\n",
    "0.03783783783783784\n",
    "0.04375\n",
    "0.0425531914893617\n",
    "]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68639704-0953-4f2f-b20f-0f37381f0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "std([\n",
    "0.03783783783783784\n",
    "0.04375\n",
    "0.0425531914893617\n",
    "] .* 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d1641-3a7a-4ad9-bf66-82655a406f45",
   "metadata": {},
   "source": [
    "# BVC in PC (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83794d95-4b9e-4dcf-bf79-d3db51dfcc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:length(pass_neurons_all)\n",
    "    println(length(intersect(PC_list[i], BVC_list[i]))/length(intersect(PC_list[i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d248d5-329f-4a38-b511-6910d37ddcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean([\n",
    "0.016055045871559634\n",
    "0.02626641651031895\n",
    "0.023980815347721823\n",
    "]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21296f69-d88e-465d-abcd-5e839273e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std([\n",
    "0.016055045871559634\n",
    "0.02626641651031895\n",
    "0.023980815347721823\n",
    "] .* 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b87c61-c8f1-4203-a885-0020cd61021e",
   "metadata": {},
   "source": [
    "# candidate in PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5593f2-af97-4a0a-b961-d22971cb1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:length(pass_neurons_all)\n",
    "    println(length(intersect(PC_list[i], pass_neurons_all[i]))/length(intersect(PC_list[i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76112ebe-47e9-4f23-9cde-919c8b1cd4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean([\n",
    "0.4243119266055046\n",
    "0.600375234521576\n",
    "0.5635491606714629\n",
    "].*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26346cf9-d4d7-48db-bcd2-4144715e31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "std([\n",
    "0.4243119266055046\n",
    "0.600375234521576\n",
    "0.5635491606714629\n",
    "].*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3257c1c-39a6-4300-8f07-456f33c9030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate PC number\n",
    "for i in 1:length(pass_neurons_all)\n",
    "    println(length(intersect(PC_list[i], pass_neurons_all[i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bebb42-8ea0-456d-ba1d-61b114886adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean([\n",
    "185\n",
    "320\n",
    "235\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63901eb2-628e-458c-89d6-d377326fc901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate non-PC number\n",
    "\n",
    "for i in 1:length(pass_neurons_all)\n",
    "    println(length(pass_neurons_all[i]) - length(intersect(PC_list[i], pass_neurons_all[i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de34610-6fe1-4587-9548-5b776884a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean([\n",
    "1711\n",
    "1104\n",
    "1367\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90c0be-3731-490f-9614-b32ba6d436df",
   "metadata": {},
   "source": [
    "# candidate in Tel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ef3fc-4e02-4b08-a3a6-8bf75f14baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:length(pass_neurons_all)\n",
    "    println(length(intersect(tel_neuron_list[i], pass_neurons_all[i]))/length(intersect(tel_neuron_list[i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06e46e4-8d2e-43a4-b6ed-8029f7132482",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean([\n",
    "0.25656292286874155\n",
    "0.24442155853072434\n",
    "0.1958914159941306\n",
    "].*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690cd82-07d2-44fa-a87b-e184ed3ea795",
   "metadata": {},
   "outputs": [],
   "source": [
    "std([\n",
    "0.25656292286874155\n",
    "0.24442155853072434\n",
    "0.1958914159941306\n",
    "].*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2f73b-ab41-4707-bbb2-5606a70173f5",
   "metadata": {},
   "source": [
    "# Tel number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527223c-9bb2-4dd3-bb89-c739b3424801",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:length(pass_neurons_all)\n",
    "    println(length(tel_neuron_list[i]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089e8bc-b947-4e5e-8623-897c65dc2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean([\n",
    "7390\n",
    "5826\n",
    "8178\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3973b-cfd7-4528-9095-c0f43703c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "std([\n",
    "7390\n",
    "5826\n",
    "8178\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d460ebc6-2ecd-4d49-892d-b8afba8202a7",
   "metadata": {},
   "source": [
    "# Tel non candidate number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5683a-1877-4521-a71e-e0b92d231ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:length(pass_neurons_all)\n",
    "    println(length(tel_neuron_list[i]) - length(pass_neurons_all[i]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31096ee9-dd1e-4703-a6cb-9c2fc3936289",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean([\n",
    "5494\n",
    "4402\n",
    "6576\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fbc6cb-cee3-4ccd-85c0-3c39180ac519",
   "metadata": {},
   "source": [
    "# BVC number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187203be-daf0-473f-a9b0-4785853abd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:length(pass_neurons_all)\n",
    "    println((length(BVC_list[i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417cc9bc-4887-47d2-a587-af5f4e35b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean([88\n",
    "70\n",
    "76])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a3afc-debf-45c0-99f5-6f72f770babc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
