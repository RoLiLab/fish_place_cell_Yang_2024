{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76572d-05b0-434d-99fa-d4eb14200c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using DelimitedFiles,HDF5, PyCall, PyPlot, NRRD,FileIO, TiffImages,Images, ProgressMeter, Statistics,LinearAlgebra, NaNStatistics\n",
    "using _Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afe7ce-7ce5-4849-b75e-5c812d46a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyimport numpy\n",
    "@pyimport matplotlib.patches as patches\n",
    "@pyimport scipy.ndimage as ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c54fbe-ec79-48b0-8062-b229b7d361ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../../../functions/func_map.jl\")\n",
    "include(\"../../../functions/func_stat.jl\")\n",
    "include(\"../../../functions/func_data.jl\")\n",
    "include(\"../../../functions/func_plot.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8c75e-94ef-42ef-8f11-c2d819fdd880",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_exp = \n",
    "[\n",
    "    [\"20220406_111526\", 9, \"jen\"],\n",
    "    [\"20220407_090156\", 5, \"jen\"],\n",
    "    [\"20220406_153842\", 9, \"jen\"],\n",
    "    [\"20220407_152537\", 4, \"jen\"],\n",
    "    [\"20220417_165530\", 2, \"jen\"],\n",
    "    [\"20220405_171444\", 25, \"jen\"],\n",
    "    [\"20220416_160516\", 6, \"jen\"]\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f7d502-62ab-495d-beef-520d026a1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_trials_all_fish = []\n",
    "for which_combo = 1:length(data_all_exp)\n",
    "\n",
    "analyzer = \"chuyu\"\n",
    "data_combo = data_all_exp[which_combo]\n",
    "experiment_filename_1 = data_combo[1]\n",
    "server_1 = data_combo[2]\n",
    "\n",
    "experimenter = data_combo[end]\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "\n",
    "\n",
    "all_files = readdir(joinpath(data_path(ds_save_cy_1), \"place_cell_windows\"))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*!occursin(\"shuffleall\", candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "println(save_file_name)\n",
    "info_filename = joinpath(data_path(ds_save_cy_1),\"place_cell_windows\", save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "close(file)\n",
    "save_file_name = candidate_filename[which_file][2]\n",
    "println(save_file_name)\n",
    "info_filename = joinpath(data_path(ds_save_cy_1),\"place_cell_windows\", save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "close(file)\n",
    "\n",
    "all_files = readdir(joinpath(data_path(ds_save_cy_1), \"\"))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*!occursin(\"shuffleall\", candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "println(save_file_name)\n",
    "info_filename = joinpath(data_path(ds_save_cy_1),\"\", save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_cell_index = HDF5.readmmap(file[\"place_cell_index\"])\n",
    "close(file)\n",
    "corr_trials_all = fill(NaN32, size(place_map_all_1,3))\n",
    "\n",
    "for neuron_idx in intersect(place_cell_index)\n",
    "    map_1 = place_map_all_1[:,:, neuron_idx]\n",
    "    map_2 = place_map_all_2[:,:, neuron_idx]\n",
    "    corr_trials_all[neuron_idx] = corr_2d_original(map_1, map_2)\n",
    "end\n",
    "    \n",
    "    append!(corr_trials_all_fish, corr_trials_all[place_cell_index])\n",
    "end\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1518ea-e3cf-454c-b1cf-cef80b43fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanmedian(float32.(corr_trials_all_fish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab0517-cc0a-49d2-bccd-ff53fbed1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanstd(float32.(corr_trials_all_fish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7c739-6ba1-479a-9670-6a6ce7a276f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_combo = 1\n",
    "analyzer = \"chuyu\"\n",
    "data_combo = data_all_exp[which_combo]\n",
    "experiment_filename_1 = data_combo[1]\n",
    "server_1 = data_combo[2]\n",
    "\n",
    "experimenter = data_combo[end]\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "\n",
    "all_files = readdir(joinpath(data_path(ds_save_cy_1), \"\"))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*!occursin(\"shuffleall\", candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "println(save_file_name)\n",
    "info_filename = joinpath(data_path(ds_save_cy_1),\"\", save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "specificity = HDF5.readmmap(file[\"specificity\"])\n",
    "close(file)\n",
    "\n",
    "    \n",
    "    NMF_filename = joinpath(data_path(ds_save_cy_1), \"NMF_merge.h5\")\n",
    "NMF_file = h5open(NMF_filename, \"r\")\n",
    "global Z_all = HDF5.readmmap(NMF_file[\"Z_all\"])\n",
    "global X_all = HDF5.readmmap(NMF_file[\"X_all\"])\n",
    "global Y_all = HDF5.readmmap(NMF_file[\"Y_all\"])\n",
    "global neuron_label = HDF5.readmmap(NMF_file[\"neuron_label\"])\n",
    "close(NMF_file)\n",
    "\n",
    "\n",
    "n_neuron = length(X_all);\n",
    "\n",
    "# whether individual roi belongs to a certain region\n",
    "region_bool_filename = joinpath(data_path(ds_save_cy_1), \"region_roi_bool.h5\")\n",
    "region_bool_file = h5open(region_bool_filename, \"r\")\n",
    "global region_names = read(region_bool_file, \"region_names\")\n",
    "global region_roi_bool = read(region_bool_file, \"region_roi_bool\")\n",
    "close(region_bool_file)\n",
    "\n",
    "\n",
    "# for one merged cell, it belongs to telecephalon if at least one of its roi belongs to telencephalon\n",
    "region_roi_bool_tel = region_roi_bool[:,findall(region_names .== \"Telencephalon -\")][:,1]\n",
    "whether_tel = falses(n_neuron)\n",
    "for which_neuron in Int32.(numpy.unique(neuron_label)[1:end-1])\n",
    "    if sum(region_roi_bool_tel[neuron_label.==which_neuron]) >0\n",
    "        whether_tel[which_neuron] = true\n",
    "    end\n",
    "end\n",
    "    \n",
    "    \n",
    "top_cells = findall(isfinite.(specificity))[reverse(sortperm(specificity[isfinite.(specificity)]))[1:100]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b753c-e2d8-4883-aedd-768f41cf02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cells_percent = []\n",
    "for which_combo = 1:length(data_all_exp)\n",
    "analyzer = \"chuyu\"\n",
    "data_combo = data_all_exp[which_combo]\n",
    "experiment_filename_1 = data_combo[1]\n",
    "server_1 = data_combo[2]\n",
    "\n",
    "experimenter = data_combo[end]\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "\n",
    "all_files = readdir(joinpath(data_path(ds_save_cy_1), \"\"))\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*!occursin(\"shuffleall\", candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "println(save_file_name)\n",
    "info_filename = joinpath(data_path(ds_save_cy_1),\"\", save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "specificity = HDF5.readmmap(file[\"specificity\"])\n",
    "close(file)\n",
    "\n",
    "    \n",
    "    NMF_filename = joinpath(data_path(ds_save_cy_1), \"NMF_merge.h5\")\n",
    "NMF_file = h5open(NMF_filename, \"r\")\n",
    "global Z_all = HDF5.readmmap(NMF_file[\"Z_all\"])\n",
    "global X_all = HDF5.readmmap(NMF_file[\"X_all\"])\n",
    "global Y_all = HDF5.readmmap(NMF_file[\"Y_all\"])\n",
    "global neuron_label = HDF5.readmmap(NMF_file[\"neuron_label\"])\n",
    "close(NMF_file)\n",
    "\n",
    "\n",
    "n_neuron = length(X_all);\n",
    "\n",
    "# whether individual roi belongs to a certain region\n",
    "region_bool_filename = joinpath(data_path(ds_save_cy_1), \"region_roi_bool.h5\")\n",
    "region_bool_file = h5open(region_bool_filename, \"r\")\n",
    "global region_names = read(region_bool_file, \"region_names\")\n",
    "global region_roi_bool = read(region_bool_file, \"region_roi_bool\")\n",
    "close(region_bool_file)\n",
    "\n",
    "\n",
    "# for one merged cell, it belongs to telecephalon if at least one of its roi belongs to telencephalon\n",
    "region_roi_bool_tel = region_roi_bool[:,findall(region_names .== \"Telencephalon -\")][:,1]\n",
    "whether_tel = falses(n_neuron)\n",
    "for which_neuron in Int32.(numpy.unique(neuron_label)[1:end-1])\n",
    "    if sum(region_roi_bool_tel[neuron_label.==which_neuron]) >0\n",
    "        whether_tel[which_neuron] = true\n",
    "    end\n",
    "end\n",
    "    \n",
    "    \n",
    "top_cells = findall(isfinite.(specificity))[reverse(sortperm(specificity[isfinite.(specificity)]))[1:100]]\n",
    "    \n",
    "append!(top_cells_percent, sum(whether_tel[top_cells])/100)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd39c0e-f15e-4df3-857b-a9a3e5c16aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cells_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad3315-5015-48a9-96f5-1666a8af0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(top_cells_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397b97c-4781-4c11-9542-c166644d6389",
   "metadata": {},
   "outputs": [],
   "source": [
    "std(top_cells_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302566d4-2dd9-432c-adf2-6f3b06708887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
