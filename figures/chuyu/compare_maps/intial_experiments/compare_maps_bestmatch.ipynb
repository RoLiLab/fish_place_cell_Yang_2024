{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb80ad-a795-41a0-82fc-8344a095ba0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ProgressMeter, PyCall, PyPlot, Images, HDF5,NaNStatistics, Statistics, DSP, Lasso, JLD2\n",
    "using _Data, _Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d266003-e053-42e1-85af-c2da4fd5c9ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pyimport numpy\n",
    "@pyimport sklearn.decomposition as decomposition\n",
    "@pyimport scipy.stats as stats\n",
    "@pyimport matplotlib.colors as mpl_colors\n",
    "@pyimport matplotlib.cm as cm \n",
    "@pyimport sklearn.cluster as cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa8bf0-3dc3-4d16-b18d-8658763d03ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(\"../../../functions/func_map.jl\")\n",
    "include(\"../../../functions/func_stat.jl\")\n",
    "include(\"../../../functions/func_data.jl\")\n",
    "include(\"../../../functions/func_plot.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb7863-f735-47da-9fb7-f4047a86c0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_info_dict = load(\"/home/chuyu/Notebooks/project_place_cell/figures/chuyu/figure_data_info.jld2\")\n",
    "\n",
    "data_info_all = []\n",
    "for key in keys(data_info_dict)\n",
    "    append!(data_info_all, data_info_dict[key])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59afebe6-86e0-4d77-99e8-dde10f55ebe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_info_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20840dfd-571c-4e72-9944-3f08f8a00065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = \"chuyu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60775aae-2a1c-4456-a75c-e759f81575bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for which_data = 1:length(data_info_all)\n",
    "    # try\n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "    tel_place_cell_index = read(compare_map_file,\"tel_place_cell_index\")\n",
    "    tel_place_cell_index_1 = read(compare_map_file,\"tel_place_cell_index_1\")\n",
    "    tel_place_cell_index_2 = read(compare_map_file,\"tel_place_cell_index_2\")\n",
    "    confined_place_cell_index_1 = read(compare_map_file,\"confined_place_cell_index_1\")\n",
    "    confined_place_cell_index_2 = read(compare_map_file,\"confined_place_cell_index_2\")\n",
    "    confined_place_cell_index = read(compare_map_file,\"confined_place_cell_index\")\n",
    "    close(compare_map_file)\n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = [occursin(\"A_dF\", long_name_files[i])*occursin(\"neuron\", long_name_files[i]) for i in 1:length(long_name_files)]\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_1, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    close(file)\n",
    "\n",
    "\n",
    "    file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "    all_files = readdir(file_folder_2)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = [occursin(\"A_dF\", long_name_files[i])*occursin(\"neuron\", long_name_files[i]) for i in 1:length(long_name_files)]\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_2, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    close(file)\n",
    "\n",
    "    info_filename = joinpath(file_folder_2, \"boundary_morph.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    mapped_map_all = HDF5.readmmap(file[\"mapped_map_all\"])\n",
    "    tel_place_cell_index  = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    close(file)\n",
    "\n",
    "    place_map_all_2 = fill(NaN32, size(place_map_all_1))  \n",
    "    place_map_all_2[:,:,tel_place_cell_index] .= mapped_map_all\n",
    "    invalid_mask = isnan.(place_map_all_1[:,:,tel_place_cell_index_1[1]])\n",
    "    place_map_all_2[invalid_mask,:] .= NaN32\n",
    "\n",
    "\n",
    "\n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_1), \"chamber_geometry_$(experiment_filename_1).h5\"))\n",
    "    global countour_array_1 = read(orientation_correction_file,\"countour_array\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "\n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_1), \"chamber_geometry_$(experiment_filename_1).h5\"))\n",
    "    global countour_array_2 = read(orientation_correction_file,\"countour_array\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "\n",
    "    img_bg_1 = h5open(ds_save_1, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"img_bg\")\n",
    "    end;\n",
    "\n",
    "    img_bg_2 = h5open(ds_save_1, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"img_bg\")\n",
    "    end;\n",
    "\n",
    "    global img_bg_end_1 = img_bg_1[:,:,end]\n",
    "    global img_bg_end_2 = img_bg_2[:,:,end]\n",
    "\n",
    "\n",
    "    global w = size(img_bg_end_1, 1)\n",
    "    global l = size(img_bg_end_1, 2)\n",
    "\n",
    "\n",
    "\n",
    "    valid_index_1, peak_all_1 = neuron_with_valid_peak(tel_place_cell_index, place_map_all_1)\n",
    "    valid_index_2, peak_all_2 = neuron_with_valid_peak(tel_place_cell_index, place_map_all_2)\n",
    "    valid_index = intersect(valid_index_1, valid_index_2)\n",
    "\n",
    "\n",
    "\n",
    "    peak_loc_map_1 = peak_all_1[:,whether_in(tel_place_cell_index, confined_place_cell_index_1)] \n",
    "    peak_loc_map_2 = peak_all_2[:,whether_in(tel_place_cell_index, confined_place_cell_index_2)];\n",
    "    \n",
    "    confined_place_cell_index_1 = confined_place_cell_index_1[findall(isfinite.(peak_loc_map_1[1,:]))]\n",
    "    confined_place_cell_index_2 = confined_place_cell_index_2[findall(isfinite.(peak_loc_map_2[1,:]))]\n",
    "    \n",
    "    peak_loc_map_1 = peak_all_1[:,whether_in(tel_place_cell_index, confined_place_cell_index_1)] \n",
    "    peak_loc_map_2 = peak_all_2[:,whether_in(tel_place_cell_index, confined_place_cell_index_2)];\n",
    "\n",
    "\n",
    "    n_bins = size(place_map_all_1, 1)\n",
    "    for_place_calculation_file = h5open(joinpath(data_path(ds_save_cy_1), \"for_place_calculation_chamber_geometry_$(experiment_filename_1)_n$(n_bins).h5\"))\n",
    "    x_bins = read(for_place_calculation_file,\"x_bins\")\n",
    "    y_bins = read(for_place_calculation_file,\"y_bins\")\n",
    "    close(for_place_calculation_file)\n",
    "\n",
    "    bin_interval = x_bins[2] - x_bins[1]\n",
    "\n",
    "\n",
    "    KMeans_features = cluster.KMeans(n_clusters = 6).fit(hcat(peak_loc_map_1'))\n",
    "    class_1 = KMeans_features.labels_;\n",
    "    KMeans_features = cluster.KMeans(n_clusters = 6).fit(hcat(peak_loc_map_2'))\n",
    "    class_2 = KMeans_features.labels_;\n",
    "\n",
    "    fig = figure()\n",
    "    scatter((peak_loc_map_1[1,whether_in(confined_place_cell_index_1, confined_place_cell_index_1)].-0.5).*bin_interval, (peak_loc_map_1[2,whether_in(confined_place_cell_index_1, confined_place_cell_index_1)].-0.5).*bin_interval, c=class_1[whether_in(confined_place_cell_index_1, confined_place_cell_index_1)], cmap=\"Dark2\", s=10, alpha=0.3)\n",
    "    # colorbar()\n",
    "    imshow(img_bg_end_1', cmap=\"binary\", vmax=2000)\n",
    "    axis(\"off\")\n",
    "    title(experiment_filename_1)\n",
    "\n",
    "\n",
    "\n",
    "    fig = figure()\n",
    "    scatter((peak_loc_map_2[1,whether_in(confined_place_cell_index_2, confined_place_cell_index_1)].-0.5).*bin_interval, (peak_loc_map_2[2,whether_in(confined_place_cell_index_2, confined_place_cell_index_1)].-0.5).*bin_interval, c=class_1[whether_in(confined_place_cell_index_1, confined_place_cell_index_2)], cmap=\"Dark2\", s=10, alpha=0.3)\n",
    "    # colorbar()\n",
    "    imshow(img_bg_end_2', cmap=\"binary\", vmax=2000)\n",
    "    axis(\"off\")\n",
    "\n",
    "\n",
    "\n",
    "    # histogram of peak location change\n",
    "\n",
    "    peak_shift = sqrt.(sum((peak_loc_map_1[:,whether_in(confined_place_cell_index_1, confined_place_cell_index_2)] .- peak_loc_map_2[:,whether_in(confined_place_cell_index_2, confined_place_cell_index_1)]) .^2, dims=1)[1,:])\n",
    "    pixel_size = 20*10^-3\n",
    "    peak_shift_mm = peak_shift *pixel_size*bin_interval\n",
    "\n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_1), \"chamber_geometry_$(experiment_filename_1).h5\"))\n",
    "    chamber_roi_1 = read(orientation_correction_file,\"chamber_roi\")\n",
    "    center_loc_1 = read(orientation_correction_file,\"center_loc\")\n",
    "    countour_array_1 = read(orientation_correction_file,\"countour_array\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "\n",
    "    peak_loc_map_1_rough = (peak_loc_map_1.-0.5).*bin_interval\n",
    "    peak_loc_map_2_rough = (peak_loc_map_2.-0.5).*bin_interval;\n",
    "\n",
    "\n",
    "    peak_distance_center_1_mm = distance_from(peak_loc_map_1_rough', center_loc_1) .*pixel_size\n",
    "    peak_distance_edge_1_mm,_ = distance_to_feature(collect(peak_loc_map_1_rough'), countour_array_1) .*pixel_size\n",
    "\n",
    "\n",
    "\n",
    "    # histogram of PF correlation\n",
    "    n_neuron = size(place_map_all_1, 3)\n",
    "    corr_trials_all = fill(NaN32, n_neuron)\n",
    "    @showprogress for neuron_idx in intersect(valid_roi_1, valid_roi_2)\n",
    "        map_1 = place_map_all_1[:,:, neuron_idx]\n",
    "        map_2 = place_map_all_2[:,:, neuron_idx]\n",
    "        corr_trials_all[neuron_idx] = corr_2d_original(map_1, map_2)\n",
    "    end\n",
    "\n",
    "    # histogram of PV correlation\n",
    "    which_neuron = tel_place_cell_index\n",
    "    mask_valid_1 = isfinite.(place_map_all_1[:,:,confined_place_cell_index_1[1]])\n",
    "    mask_valid_2 = isfinite.(place_map_all_2[:,:,confined_place_cell_index_2[1]])\n",
    "    valid_pixels = findall(mask_valid_1 .* mask_valid_2)\n",
    "\n",
    "        \n",
    "    mean_map_1= numpy.nanmean(place_map_all_1[mask_valid_1, which_neuron], axis=0)\n",
    "    std_map_1= numpy.nanstd(place_map_all_1[mask_valid_1, which_neuron], axis=0)\n",
    "    mean_map_2= numpy.nanmean(place_map_all_2[mask_valid_2, which_neuron], axis=0)\n",
    "    std_map_2= numpy.nanstd(place_map_all_2[mask_valid_2, which_neuron], axis=0)\n",
    "\n",
    "\n",
    "    corr_pv_all = fill(NaN32, length(valid_pixels))\n",
    "    corr_pv_all_normalized = fill(NaN32, length(valid_pixels))\n",
    "    for (i, which_pixel) in enumerate(valid_pixels)\n",
    "        pv1 = place_map_all_1[which_pixel, which_neuron]\n",
    "        pv2 = place_map_all_2[which_pixel, which_neuron]\n",
    "        pv1_normalized = (pv1 .- mean_map_1)./std_map_1\n",
    "        pv2_normalized = (pv2 .- mean_map_2)./std_map_2\n",
    "        corr_pv_all[i] = corr_nan(pv1, pv2)\n",
    "        corr_pv_all_normalized[i] = corr_nan(pv1_normalized, pv2_normalized)\n",
    "    end\n",
    "\n",
    "\n",
    "    pv_map = fill(NaN32, size(place_map_all_1[:,:,1]))\n",
    "    pv_map[valid_pixels] = corr_pv_all\n",
    "\n",
    "\n",
    "    pv_map_normalized = fill(NaN32, size(place_map_all_1[:,:,1]))\n",
    "    pv_map_normalized[valid_pixels] = corr_pv_all_normalized\n",
    "\n",
    "\n",
    "    h5open(joinpath(data_path(ds_save_analyzer_1), \"compare_map_results.h5\"), \"w\") do file\n",
    "        file[\"specificity_1\"] = specificity_1\n",
    "        file[\"specificity_2\"] = specificity_2\n",
    "\n",
    "        file[\"tel_place_cell_index_1\"] = tel_place_cell_index_1\n",
    "        file[\"tel_place_cell_index_2\"] = tel_place_cell_index_2\n",
    "        file[\"tel_place_cell_index\"] = tel_place_cell_index\n",
    "        file[\"confined_place_cell_index\"] = confined_place_cell_index\n",
    "        file[\"confined_place_cell_index_1\"] = confined_place_cell_index_1\n",
    "        file[\"confined_place_cell_index_2\"] = confined_place_cell_index_2\n",
    "        file[\"peak_all_1\"] = peak_all_1\n",
    "        file[\"peak_all_2\"] = peak_all_2\n",
    "        file[\"peak_loc_map_1\"] = peak_loc_map_1\n",
    "        file[\"peak_loc_map_2\"] = peak_loc_map_2\n",
    "        file[\"peak_shift_mm\"] = peak_shift_mm\n",
    "        file[\"peak_distance_center_1_mm\"] = peak_distance_center_1_mm\n",
    "        file[\"peak_distance_edge_1_mm\"] = peak_distance_edge_1_mm\n",
    "        file[\"corr_trials_all\"] = corr_trials_all\n",
    "        file[\"corr_pv_all\"] = corr_pv_all\n",
    "        file[\"corr_pv_all_normalized\"] = corr_pv_all_normalized\n",
    "        file[\"pv_map\"] = pv_map\n",
    "        file[\"pv_map_normalized\"] = pv_map_normalized\n",
    "    end;\n",
    "\n",
    "\n",
    "    # catch e\n",
    "    #     println(e)\n",
    "    # end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f783e05-2ade-4984-bb39-f4e1cf5c49e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    \n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "\n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "    tel_place_cell_index = read(compare_map_file,\"tel_place_cell_index\")\n",
    "    tel_place_cell_index_1 = read(compare_map_file,\"tel_place_cell_index_1\")\n",
    "    tel_place_cell_index_2 = read(compare_map_file,\"tel_place_cell_index_2\")\n",
    "    close(compare_map_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = [occursin(\"A_dF\", long_name_files[i])*occursin(\"neuron\", long_name_files[i]) for i in 1:length(long_name_files)]\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_1, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    close(file)\n",
    "\n",
    "\n",
    "    file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "    all_files = readdir(file_folder_2)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = [occursin(\"A_dF\", long_name_files[i])*occursin(\"neuron\", long_name_files[i]) for i in 1:length(long_name_files)]\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_2, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    close(file)\n",
    "\n",
    "    info_filename = joinpath(file_folder_2, \"boundary_morph.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    mapped_map_all = HDF5.readmmap(file[\"mapped_map_all\"])\n",
    "    tel_place_cell_index  = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    close(file)\n",
    "\n",
    "    place_map_all_2 = fill(NaN32, size(place_map_all_1))  \n",
    "    place_map_all_2[:,:,tel_place_cell_index] .= mapped_map_all\n",
    "    invalid_mask = isnan.(place_map_all_1[:,:,tel_place_cell_index_1[1]])\n",
    "    place_map_all_2[invalid_mask,:] .= NaN32\n",
    "\n",
    "\n",
    "    n_bins = size(place_map_all_1, 1)\n",
    "    n_x = size(place_map_all_1, 1)\n",
    "    n_y = size(place_map_all_1, 2) \n",
    "    n_neurons = size(place_map_all_1, 3)\n",
    "    map_baseline_1 = fill(NaN32, n_neurons)\n",
    "    map_baseline_2 = fill(NaN32, n_neurons);\n",
    "\n",
    "    for neuron_idx = tel_place_cell_index\n",
    "        cur_map = place_map_all_1[:, :, neuron_idx]\n",
    "        map_baseline_1[neuron_idx] = nanmean(cur_map[findall(cur_map .<= nanpctile(cur_map, 20))])\n",
    "        cur_map = place_map_all_2[:, :, neuron_idx]\n",
    "        map_baseline_2[neuron_idx] = nanmean(cur_map[findall(cur_map .<= nanpctile(cur_map, 20))])\n",
    "    end\n",
    "\n",
    "    pseudocount_1 = 10 .- map_baseline_1;\n",
    "    pseudocount_1[findall(pseudocount_1 .< 0)] .= 0; \n",
    "    pseudocount_2 = 10 .- map_baseline_2;\n",
    "    pseudocount_2[findall(pseudocount_2 .< 0)] .= 0; \n",
    "\n",
    "\n",
    "    place_activity_map_dFoF_1 = fill(NaN32, n_x, n_y, n_neurons)\n",
    "    place_activity_map_dFoF_2 = fill(NaN32, n_x, n_y, n_neurons)\n",
    "\n",
    "    PV_correlation_map = fill(NaN32, n_x, n_y)\n",
    "\n",
    "    for neuron_idx = tel_place_cell_index\n",
    "        cur_map = place_map_all_1[:, :, neuron_idx]\n",
    "        cur_map_dFoF = (cur_map .- map_baseline_1[neuron_idx]) ./ (map_baseline_1[neuron_idx] + pseudocount_1[neuron_idx])\n",
    "        place_activity_map_dFoF_1[:, :, neuron_idx] .= cur_map_dFoF\n",
    "\n",
    "        cur_map = place_map_all_2[:, :, neuron_idx]\n",
    "        cur_map_dFoF = (cur_map .- map_baseline_2[neuron_idx]) ./ (map_baseline_2[neuron_idx] + pseudocount_2[neuron_idx])\n",
    "        place_activity_map_dFoF_2[:, :, neuron_idx] .= cur_map_dFoF\n",
    "    end\n",
    "\n",
    "    for i_x = 1:n_x\n",
    "        for i_y = 1:n_y\n",
    "            PV_correlation_map[i_x, i_y] = nancor(place_activity_map_dFoF_1[i_x, i_y, tel_place_cell_index], place_activity_map_dFoF_2[i_x, i_y, tel_place_cell_index])\n",
    "        end\n",
    "    end\n",
    "\n",
    "\n",
    "    h5open(joinpath(file_folder_1, \"compare_map_results.h5\"), \"r+\") do file\n",
    "    if haskey(file, \"pv_map_dFF\")\n",
    "        delete_object(file, \"pv_map_dFF\") \n",
    "    end\n",
    "    file[\"pv_map_dFF\"] = PV_correlation_map\n",
    "    end;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab595925-4d06-4c9c-8459-84e4bf63a66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for which_data = 1:length(data_info_all)\n",
    "    # try\n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "    tel_place_cell_index = read(compare_map_file,\"tel_place_cell_index\")\n",
    "    tel_place_cell_index_1 = read(compare_map_file,\"tel_place_cell_index_1\")\n",
    "    tel_place_cell_index_2 = read(compare_map_file,\"tel_place_cell_index_2\")\n",
    "    confined_place_cell_index_1 = read(compare_map_file,\"confined_place_cell_index_1\")\n",
    "    confined_place_cell_index_2 = read(compare_map_file,\"confined_place_cell_index_2\")\n",
    "    confined_place_cell_index = read(compare_map_file,\"confined_place_cell_index\")\n",
    "    close(compare_map_file)\n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = [occursin(\"A_dF\", long_name_files[i])*occursin(\"neuron\", long_name_files[i]) for i in 1:length(long_name_files)]\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_1, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    close(file)\n",
    "\n",
    "\n",
    "    file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "    all_files = readdir(file_folder_2)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = [occursin(\"A_dF\", long_name_files[i])*occursin(\"neuron\", long_name_files[i]) for i in 1:length(long_name_files)]\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_2, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    close(file)\n",
    "\n",
    "    info_filename = joinpath(file_folder_2, \"boundary_morph.h5\")\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    mapped_map_all = HDF5.readmmap(file[\"mapped_map_all\"])\n",
    "    tel_place_cell_index  = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "    close(file)\n",
    "\n",
    "    place_map_all_2 = fill(NaN32, size(place_map_all_1))  \n",
    "    place_map_all_2[:,:,tel_place_cell_index] .= mapped_map_all\n",
    "    invalid_mask = isnan.(place_map_all_1[:,:,tel_place_cell_index_1[1]])\n",
    "    place_map_all_2[invalid_mask,:] .= NaN32\n",
    "\n",
    "\n",
    "\n",
    "    # histogram of PF correlation\n",
    "    n_neuron = size(place_map_all_1, 3)\n",
    "    corr_trials_all = fill(NaN32, n_neuron)\n",
    "    for neuron_idx in intersect(valid_roi_1, valid_roi_2)\n",
    "        map_1 = place_map_all_1[:,:, neuron_idx]\n",
    "        map_2 = place_map_all_2[:,:, neuron_idx]\n",
    "        corr_trials_all[neuron_idx] = corr_2d_original(map_1, map_2)\n",
    "    end\n",
    "    \n",
    "    \n",
    "    h5open(joinpath(file_folder_1, \"compare_map_results.h5\"), \"r+\") do file\n",
    "\n",
    "        delete_object(file, \"corr_trials_all\")\n",
    "        file[\"corr_trials_all\"] = corr_trials_all\n",
    "\n",
    "    end;\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9e1c0-134a-4691-99db-93faf9cc8bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results.h5\"))\n",
    "    if haskey(compare_map_file, \"pv_map_normalized\")    \n",
    "        println(\"$which_data yes\")\n",
    "    else \n",
    "        println(\"$which_data no\")\n",
    "    end\n",
    "    close(compare_map_file)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14c0bb-c1ec-4912-9b1a-728aa0b80f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.4",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
