{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb80ad-a795-41a0-82fc-8344a095ba0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ProgressMeter, PyCall, PyPlot, Images, HDF5,NaNStatistics, Statistics, DSP, Lasso, JLD2\n",
    "using _Data, _Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d266003-e053-42e1-85af-c2da4fd5c9ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pyimport numpy\n",
    "@pyimport sklearn.decomposition as decomposition\n",
    "@pyimport scipy.stats as stats\n",
    "@pyimport matplotlib.colors as mpl_colors\n",
    "@pyimport matplotlib.cm as cm \n",
    "@pyimport sklearn.cluster as cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa8bf0-3dc3-4d16-b18d-8658763d03ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(\"../../../functions/func_map.jl\")\n",
    "include(\"../../../functions/func_stat.jl\")\n",
    "include(\"../../../functions/func_data.jl\")\n",
    "include(\"../../../functions/func_plot.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb7863-f735-47da-9fb7-f4047a86c0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_info_dict = load(\"/home/chuyu/Notebooks/project_place_cell/figures/chuyu/figure_data_info.jld2\")\n",
    "\n",
    "data_info_all = []\n",
    "for key in keys(data_info_dict)\n",
    "    append!(data_info_all, data_info_dict[key])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20840dfd-571c-4e72-9944-3f08f8a00065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = \"chuyu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f246d505-0db2-48b9-8603-2aeb7661fa62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"place_cell_windows\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d456d4-8028-4676-9de4-5d76b70a5de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for which_data in 1:length(data_info_all)\n",
    "    try\n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    all_files = readdir(data_path(ds_save_cy_1))\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"compar\" for i in 1:length(long_name_files)])\n",
    "    # println(long_name_files[spatial_info_index])\n",
    "    \n",
    "    \n",
    "    # println(which_data)\n",
    "    \n",
    "    path_target = data_path(ds_save_cy_1)\n",
    "    # run(`ls -lha $path_target/compare_map_results_original.h5`)\n",
    "    # run(`ls -lha $path_target/compare_map_results.h5`)\n",
    "    # run(`ls -lha $path_target/compare_map_results_matchangle.h5`)\n",
    "    # run(`ls -lha $path_target/compare_map_results_matchboundary.h5`)\n",
    "    run(`ls -lha $path_target/compare_map_results_early_late.h5`)\n",
    "\n",
    "    catch e\n",
    "        println(e)\n",
    "    end\n",
    "    \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60775aae-2a1c-4456-a75c-e759f81575bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    # try\n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "    confined_place_cell_index = read(compare_map_file,\"confined_place_cell_index\")\n",
    "    tel_place_cell_index = read(compare_map_file,\"tel_place_cell_index\")\n",
    "    pv_map_dFF_12 = read(compare_map_file,\"pv_map_dFF\")\n",
    "\n",
    "    close(compare_map_file)\n",
    "    \n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"place_cell_windows\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    println(save_file_name)   \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1),\"place_cell_windows\", save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1_early = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    specificity_1_early = HDF5.readmmap(file[\"specificity\"])\n",
    "    close(file)\n",
    "        \n",
    "    n_bins = size(place_map_all_1_early, 1)    \n",
    "    n_neuron = size(place_map_all_1_early, 3)   \n",
    "        \n",
    "\n",
    "    save_file_name = candidate_filename[which_file][2]\n",
    "    println(save_file_name)\n",
    "    info_filename = joinpath(data_path(ds_save_cy_1),\"place_cell_windows\", save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1_late = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    specificity_1_late = HDF5.readmmap(file[\"specificity\"])\n",
    "    close(file)\n",
    "        \n",
    "    for_place_calculation_file = h5open(joinpath(data_path(ds_save_cy_1), \"for_place_calculation_chamber_geometry_$(experiment_filename_1)_n$(n_bins).h5\"))\n",
    "    x_bins = read(for_place_calculation_file,\"x_bins\")\n",
    "    y_bins = read(for_place_calculation_file,\"y_bins\")\n",
    "    close(for_place_calculation_file)\n",
    "\n",
    "    bin_interval = x_bins[2] - x_bins[1]\n",
    "\n",
    "\n",
    "    _, peak_loc_map_1_early = neuron_with_valid_peak(confined_place_cell_index, place_map_all_1_early)\n",
    "    _, peak_loc_map_1_late = neuron_with_valid_peak(confined_place_cell_index, place_map_all_1_late)\n",
    "\n",
    "\n",
    "    peak_shift_early_late = sqrt.(sum((peak_loc_map_1_early .- peak_loc_map_1_late) .^2, dims=1)[1,:])\n",
    "    pixel_size = 20*10^-3\n",
    "    peak_shift_early_late_mm = peak_shift_early_late *pixel_size*bin_interval\n",
    "\n",
    "    # histogram of PF correlation\n",
    "    corr_earlylate_all = fill(NaN32, n_neuron)\n",
    "    for neuron_idx in 1:n_neuron\n",
    "        map_1 = place_map_all_1_early[:,:, neuron_idx]\n",
    "        map_2 = place_map_all_1_late[:,:, neuron_idx]\n",
    "        corr_earlylate_all[neuron_idx] = corr_2d_original(map_1, map_2;mask=pv_map_dFF_12)\n",
    "    end\n",
    "\n",
    "\n",
    "    # histogram of PV correlation\n",
    "    which_neuron = tel_place_cell_index\n",
    "    mask_valid_1 = isfinite.(place_map_all_1_early[:,:,confined_place_cell_index[1]])\n",
    "    mask_valid_2 = isfinite.(place_map_all_1_late[:,:,confined_place_cell_index[1]])\n",
    "    valid_pixels = findall(mask_valid_1 .* mask_valid_2)\n",
    "\n",
    "    mean_map_1= nanmean(place_map_all_1_early[mask_valid_1, which_neuron], dims=1)[1,:]\n",
    "    std_map_1= nanstd(place_map_all_1_early[mask_valid_1, which_neuron], dims=1)[1,:]\n",
    "    mean_map_2= nanmean(place_map_all_1_late[mask_valid_2, which_neuron], dims=1)[1,:]\n",
    "    std_map_2= nanstd(place_map_all_1_late[mask_valid_2, which_neuron], dims=1)[1,:]\n",
    "\n",
    "\n",
    "    corr_pv_earlylate_all = fill(NaN32, length(valid_pixels))\n",
    "    corr_pv_earlylate_all_normalized = fill(NaN32, length(valid_pixels))\n",
    "    for (i, which_pixel) in enumerate(valid_pixels)\n",
    "        pv1 = place_map_all_1_early[which_pixel, which_neuron]\n",
    "        pv2 = place_map_all_1_late[which_pixel, which_neuron]\n",
    "        pv1_normalized = (pv1 .- mean_map_1)./std_map_1\n",
    "        pv2_normalized = (pv2 .- mean_map_2)./std_map_2\n",
    "        corr_pv_earlylate_all[i] = corr_nan(pv1, pv2)\n",
    "        corr_pv_earlylate_all_normalized[i] = corr_nan(pv1_normalized, pv2_normalized)\n",
    "    end\n",
    "\n",
    "\n",
    "    pv_map = fill(NaN32, size(place_map_all_1_early[:,:,1]))\n",
    "    pv_map[valid_pixels] = corr_pv_earlylate_all\n",
    "\n",
    "\n",
    "    pv_map_normalized = fill(NaN32, size(place_map_all_1_early[:,:,1]))\n",
    "    pv_map_normalized[valid_pixels] = corr_pv_earlylate_all_normalized\n",
    "\n",
    "\n",
    "    h5open(joinpath(data_path(ds_save_analyzer_1), \"compare_map_results_early_late_original.h5\"), \"w\") do file\n",
    "        file[\"specificity_1_early\"] = specificity_1_early\n",
    "        file[\"specificity_1_late\"] = specificity_1_late\n",
    "        file[\"peak_shift_early_late_mm\"] = peak_shift_early_late_mm\n",
    "        file[\"corr_earlylate_all\"] = corr_earlylate_all\n",
    "        file[\"corr_pv_earlylate_all\"] = corr_pv_earlylate_all\n",
    "        file[\"corr_pv_earlylate_all_normalized\"] = corr_pv_earlylate_all_normalized\n",
    "        file[\"peak_loc_map_1_early\"] = peak_loc_map_1_early\n",
    "        file[\"peak_loc_map_1_late\"] = peak_loc_map_1_late\n",
    "        file[\"confined_place_cell_index\"] = confined_place_cell_index\n",
    "        \n",
    "        file[\"pv_map\"] = pv_map\n",
    "        file[\"pv_map_normalized\"] = pv_map_normalized\n",
    "    end;\n",
    "\n",
    "\n",
    "    # catch e\n",
    "    #     println(e)\n",
    "    # end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cc4f2-3fcd-4082-a2a8-8e45f77ce2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    \n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "\n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "    tel_place_cell_index = read(compare_map_file,\"tel_place_cell_index\")\n",
    "    tel_place_cell_index_1 = read(compare_map_file,\"tel_place_cell_index_1\")\n",
    "    tel_place_cell_index_2 = read(compare_map_file,\"tel_place_cell_index_2\")\n",
    "    close(compare_map_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"place_cell_windows\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    println(save_file_name)   \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1),\"place_cell_windows\", save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "\n",
    "    save_file_name = candidate_filename[which_file][2]\n",
    "    println(save_file_name)\n",
    "    info_filename = joinpath(data_path(ds_save_cy_1),\"place_cell_windows\", save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    close(file)\n",
    "    \n",
    "\n",
    "\n",
    "    n_bins = size(place_map_all_1, 1)\n",
    "    n_x = size(place_map_all_1, 1)\n",
    "    n_y = size(place_map_all_1, 2) \n",
    "    n_neurons = size(place_map_all_1, 3)\n",
    "    map_baseline_1 = fill(NaN32, n_neurons)\n",
    "    map_baseline_2 = fill(NaN32, n_neurons);\n",
    "\n",
    "    for neuron_idx = tel_place_cell_index\n",
    "        cur_map = place_map_all_1[:, :, neuron_idx]\n",
    "        map_baseline_1[neuron_idx] = nanmean(cur_map[findall(cur_map .<= nanpctile(cur_map, 20))])\n",
    "        cur_map = place_map_all_2[:, :, neuron_idx]\n",
    "        map_baseline_2[neuron_idx] = nanmean(cur_map[findall(cur_map .<= nanpctile(cur_map, 20))])\n",
    "    end\n",
    "\n",
    "    pseudocount_1 = 10 .- map_baseline_1;\n",
    "    pseudocount_1[findall(pseudocount_1 .< 0)] .= 0; \n",
    "    pseudocount_2 = 10 .- map_baseline_2;\n",
    "    pseudocount_2[findall(pseudocount_2 .< 0)] .= 0; \n",
    "\n",
    "\n",
    "    place_activity_map_dFoF_1 = fill(NaN32, n_x, n_y, n_neurons)\n",
    "    place_activity_map_dFoF_2 = fill(NaN32, n_x, n_y, n_neurons)\n",
    "\n",
    "    PV_correlation_map = fill(NaN32, n_x, n_y)\n",
    "\n",
    "    for neuron_idx = tel_place_cell_index\n",
    "        cur_map = place_map_all_1[:, :, neuron_idx]\n",
    "        cur_map_dFoF = (cur_map .- map_baseline_1[neuron_idx]) ./ (map_baseline_1[neuron_idx] + pseudocount_1[neuron_idx])\n",
    "        place_activity_map_dFoF_1[:, :, neuron_idx] .= cur_map_dFoF\n",
    "\n",
    "        cur_map = place_map_all_2[:, :, neuron_idx]\n",
    "        cur_map_dFoF = (cur_map .- map_baseline_2[neuron_idx]) ./ (map_baseline_2[neuron_idx] + pseudocount_2[neuron_idx])\n",
    "        place_activity_map_dFoF_2[:, :, neuron_idx] .= cur_map_dFoF\n",
    "    end\n",
    "\n",
    "    for i_x = 1:n_x\n",
    "        for i_y = 1:n_y\n",
    "            PV_correlation_map[i_x, i_y] = nancor(place_activity_map_dFoF_1[i_x, i_y, tel_place_cell_index], place_activity_map_dFoF_2[i_x, i_y, tel_place_cell_index])\n",
    "        end\n",
    "    end\n",
    "\n",
    "\n",
    "    h5open(joinpath(data_path(ds_save_analyzer_1), \"compare_map_results_early_late_original.h5\"), \"r+\") do file\n",
    "    if haskey(file, \"pv_map_dFF\")\n",
    "        delete_object(file, \"pv_map_dFF\") \n",
    "    end\n",
    "    file[\"pv_map_dFF\"] = PV_correlation_map\n",
    "    end;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4961b7e9-a87a-4fbd-a9f8-87cfba40d201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for which_data = 1:length(data_info_all)\n",
    "    # try\n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "    confined_place_cell_index = read(compare_map_file,\"confined_place_cell_index\")\n",
    "    tel_place_cell_index = read(compare_map_file,\"tel_place_cell_index\")\n",
    "    pv_map_dFF_12 = read(compare_map_file,\"pv_map_dFF\")\n",
    "\n",
    "    close(compare_map_file)\n",
    "    \n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"place_cell_windows\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    println(save_file_name)   \n",
    "    info_filename = joinpath(data_path(ds_save_cy_1),\"place_cell_windows\", save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1_early = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    close(file)\n",
    "        \n",
    "        \n",
    "\n",
    "    save_file_name = candidate_filename[which_file][2]\n",
    "    println(save_file_name)\n",
    "    info_filename = joinpath(data_path(ds_save_cy_1),\"place_cell_windows\", save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1_late = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    close(file)\n",
    "        \n",
    "    n_neuron = size(place_map_all_1_late, 3)\n",
    "    # histogram of PF correlation\n",
    "    corr_earlylate_all = fill(NaN32, n_neuron)\n",
    "    for neuron_idx in 1:n_neuron\n",
    "        map_1 = place_map_all_1_early[:,:, neuron_idx]\n",
    "        map_2 = place_map_all_1_late[:,:, neuron_idx]\n",
    "        corr_earlylate_all[neuron_idx] = corr_2d_original(map_1, map_2;mask=pv_map_dFF_12)\n",
    "    end\n",
    "\n",
    "    h5open(joinpath(data_path(ds_save_analyzer_1), \"compare_map_results_early_late_original.h5\"), \"r+\") do file\n",
    "\n",
    "        delete_object(file, \"corr_earlylate_all\")\n",
    "        file[\"corr_earlylate_all\"] = corr_earlylate_all\n",
    "\n",
    "    end;    \n",
    "\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c39c3-547e-4b17-bd65-126ee972dd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
