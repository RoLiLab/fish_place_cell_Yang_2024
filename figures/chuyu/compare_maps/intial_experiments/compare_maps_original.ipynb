{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb80ad-a795-41a0-82fc-8344a095ba0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ProgressMeter, PyCall, PyPlot, Images, HDF5,NaNStatistics, Statistics, DSP, Lasso, JLD2\n",
    "using _Data, _Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d266003-e053-42e1-85af-c2da4fd5c9ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pyimport numpy\n",
    "@pyimport sklearn.decomposition as decomposition\n",
    "@pyimport scipy.stats as stats\n",
    "@pyimport matplotlib.colors as mpl_colors\n",
    "@pyimport matplotlib.cm as cm \n",
    "@pyimport sklearn.cluster as cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa8bf0-3dc3-4d16-b18d-8658763d03ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(\"../../../functions/func_map.jl\")\n",
    "include(\"../../../functions/func_stat.jl\")\n",
    "include(\"../../../functions/func_data.jl\")\n",
    "include(\"../../../functions/func_plot.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb7863-f735-47da-9fb7-f4047a86c0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_info_dict = load(\"/home/chuyu/Notebooks/project_place_cell/figures/chuyu/figure_data_info.jld2\")\n",
    "\n",
    "data_info_all = []\n",
    "for key in keys(data_info_dict)\n",
    "    append!(data_info_all, data_info_dict[key])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20840dfd-571c-4e72-9944-3f08f8a00065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = \"chuyu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ad76b-8e16-4575-ba85-abd3b5e070bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    if candidate_filename[which_file] == []\n",
    "        println(data_info)\n",
    "    end\n",
    "\n",
    "    file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "    all_files = readdir(file_folder_2)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    \n",
    "    \n",
    "    if candidate_filename[which_file] == []\n",
    "        println(data_info)\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a513bb-860e-4a03-9293-77594c7b3160",
   "metadata": {},
   "source": [
    "# original maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118551c6-bac8-48bf-826a-e63820454536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first save the easily calculatable variables\n",
    "\n",
    "@showprogress for which_data = 28:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "    NMF_filename = joinpath(data_path(ds_save_cy_1), \"NMF_merge.h5\")\n",
    "    NMF_file = h5open(NMF_filename, \"r\")\n",
    "    global Z_all = HDF5.readmmap(NMF_file[\"Z_all\"])\n",
    "    global X_all = HDF5.readmmap(NMF_file[\"X_all\"])\n",
    "    global Y_all = HDF5.readmmap(NMF_file[\"Y_all\"])\n",
    "    global neuron_label = HDF5.readmmap(NMF_file[\"neuron_label\"])\n",
    "    close(NMF_file)\n",
    "\n",
    "\n",
    "    n_neuron = length(X_all);\n",
    "\n",
    "    # whether individual roi belongs to a certain region\n",
    "    region_bool_filename = joinpath(data_path(ds_save_cy_1), \"region_roi_bool.h5\")\n",
    "    region_bool_file = h5open(region_bool_filename, \"r\")\n",
    "    global region_names = read(region_bool_file, \"region_names\")\n",
    "    global region_roi_bool = read(region_bool_file, \"region_roi_bool\")\n",
    "    close(region_bool_file)\n",
    "\n",
    "\n",
    "    # for one merged cell, it belongs to telecephalon if at least one of its roi belongs to telencephalon\n",
    "    region_roi_bool_tel = region_roi_bool[:,findall(region_names .== \"Telencephalon -\")][:,1]\n",
    "    whether_tel = falses(n_neuron)\n",
    "    for which_neuron in Int32.(numpy.unique(neuron_label)[1:end-1])\n",
    "        if sum(region_roi_bool_tel[neuron_label.==which_neuron]) >0\n",
    "            whether_tel[which_neuron] = true\n",
    "        end\n",
    "    end\n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_1, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    close(file)\n",
    "\n",
    "\n",
    "    file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "    all_files = readdir(file_folder_2)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_2, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    close(file)\n",
    "\n",
    "    n_bins = size(place_map_all_1, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    place_cell_index_1 = intersect(findall(specificity_population_z_1.>3), findall(specificity_shuffle_z_1.>5), findall(specificity_1.>0.01))\n",
    "    place_cell_index_2 = intersect(findall(specificity_population_z_2.>3), findall(specificity_shuffle_z_2.>5), findall(specificity_2.>0.01))\n",
    "\n",
    "    tel_place_cell_index_1 = intersect(place_cell_index_1, findall(whether_tel))\n",
    "    tel_place_cell_index_2 = intersect(place_cell_index_2, findall(whether_tel))\n",
    "\n",
    "    place_cell_index = union(place_cell_index_1, place_cell_index_2)\n",
    "    tel_place_cell_index = union(tel_place_cell_index_1, tel_place_cell_index_2) #what we should use in following analysis\n",
    "\n",
    "    valid_index_1, peak_all_1 = neuron_with_valid_peak(tel_place_cell_index, place_map_all_1)\n",
    "    valid_index_2, peak_all_2 = neuron_with_valid_peak(tel_place_cell_index, place_map_all_2)\n",
    "    valid_index = intersect(valid_index_1, valid_index_2)\n",
    "\n",
    "    confined_place_cell_index_1 = intersect(tel_place_cell_index[valid_index_1], tel_place_cell_index_1)\n",
    "    confined_place_cell_index_2 = intersect(tel_place_cell_index[valid_index_2], tel_place_cell_index_2)\n",
    "    confined_place_cell_index = intersect(confined_place_cell_index_1, confined_place_cell_index_2)\n",
    "\n",
    "    peak_loc_map_1 = peak_all_1[:,whether_in(tel_place_cell_index, confined_place_cell_index_1)] \n",
    "    peak_loc_map_2 = peak_all_2[:,whether_in(tel_place_cell_index, confined_place_cell_index_2)];\n",
    "\n",
    "    plot_loc(tel_place_cell_index_1; valid_neurons = valid_roi_1, label= length(tel_place_cell_index_1))\n",
    "    plot_loc(tel_place_cell_index_2; valid_neurons = valid_roi_1, label= length(tel_place_cell_index_2))\n",
    "\n",
    "\n",
    "    h5open(joinpath(file_folder_1, \"compare_map_results_original.h5\"), \"w\") do file\n",
    "        file[\"specificity_1\"] = specificity_1\n",
    "        file[\"specificity_2\"] = specificity_2\n",
    "        file[\"tel_place_cell_index_1\"] = tel_place_cell_index_1\n",
    "        file[\"tel_place_cell_index_2\"] = tel_place_cell_index_2\n",
    "        file[\"tel_place_cell_index\"] = tel_place_cell_index\n",
    "\n",
    "        file[\"confined_place_cell_index_1\"] = confined_place_cell_index_1\n",
    "        file[\"confined_place_cell_index_2\"] = confined_place_cell_index_2\n",
    "        file[\"confined_place_cell_index\"] = confined_place_cell_index\n",
    "        file[\"place_cell_index_1\"] = place_cell_index_1\n",
    "        file[\"place_cell_index_2\"] = place_cell_index_2\n",
    "\n",
    "        file[\"peak_loc_map_1\"] = peak_loc_map_1\n",
    "        file[\"peak_loc_map_2\"] = peak_loc_map_2\n",
    "        file[\"peak_all_1\"] = peak_all_1\n",
    "        file[\"peak_all_2\"] = peak_all_2\n",
    "        \n",
    "        file[\"whether_tel\"] = collect(whether_tel)\n",
    "        \n",
    "    end;\n",
    "\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894ebf4-f7b3-4efe-9013-2a247ececef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    \n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    \n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "    if haskey(compare_map_file, \"pv_map_normalized\")    \n",
    "        continue\n",
    "    end\n",
    "    peak_loc_map_1 = read(compare_map_file,\"peak_loc_map_1\")\n",
    "    peak_loc_map_2 = read(compare_map_file,\"peak_loc_map_2\")\n",
    "    confined_place_cell_index_1 = read(compare_map_file,\"confined_place_cell_index_1\")\n",
    "    confined_place_cell_index_2 = read(compare_map_file,\"confined_place_cell_index_2\")\n",
    "    confined_place_cell_index = read(compare_map_file,\"confined_place_cell_index\")\n",
    "    tel_place_cell_index = read(compare_map_file,\"tel_place_cell_index\")\n",
    "    close(compare_map_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_1, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    close(file)\n",
    "\n",
    "\n",
    "    file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "    all_files = readdir(file_folder_2)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_2, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    close(file)\n",
    "\n",
    "    n_bins = size(place_map_all_1, 1)\n",
    "    \n",
    "    \n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_1), \"chamber_geometry_$(experiment_filename_1).h5\"))\n",
    "    global countour_array_1 = read(orientation_correction_file,\"countour_array\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "\n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_2), \"chamber_geometry_$(experiment_filename_2).h5\"))\n",
    "    global countour_array_2 = read(orientation_correction_file,\"countour_array\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "\n",
    "    img_bg_1 = h5open(ds_save_1, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"img_bg\")\n",
    "    end;\n",
    "\n",
    "    img_bg_2 = h5open(ds_save_2, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"img_bg\")\n",
    "    end;\n",
    "\n",
    "    global img_bg_end_1 = img_bg_1[:,:,end]\n",
    "    global img_bg_end_2 = img_bg_2[:,:,end]\n",
    "\n",
    "\n",
    "    global w = size(img_bg_end_1, 1)\n",
    "    global l = size(img_bg_end_1, 2)\n",
    "\n",
    "\n",
    "    \n",
    "    for_place_calculation_file = h5open(joinpath(data_path(ds_save_cy_1), \"for_place_calculation_chamber_geometry_$(experiment_filename_1)_n$(n_bins).h5\"))\n",
    "    x_bins = read(for_place_calculation_file,\"x_bins\")\n",
    "    y_bins = read(for_place_calculation_file,\"y_bins\")\n",
    "    close(for_place_calculation_file)\n",
    "\n",
    "    bin_interval = x_bins[2] - x_bins[1]\n",
    "\n",
    "    KMeans_features = cluster.KMeans(n_clusters = 6).fit(hcat(peak_loc_map_1'))\n",
    "    class_1 = KMeans_features.labels_;\n",
    "    KMeans_features = cluster.KMeans(n_clusters = 6).fit(hcat(peak_loc_map_2'))\n",
    "    class_2 = KMeans_features.labels_;\n",
    "\n",
    "    fig = figure()\n",
    "    scatter((peak_loc_map_1[1,whether_in(confined_place_cell_index_1, confined_place_cell_index_1)].-0.5).*bin_interval, (peak_loc_map_1[2,whether_in(confined_place_cell_index_1, confined_place_cell_index_1)].-0.5).*bin_interval, c=class_1[whether_in(confined_place_cell_index_1, confined_place_cell_index_1)], cmap=\"Dark2\", s=10, alpha=0.3)\n",
    "    # colorbar()\n",
    "    imshow(img_bg_end_1', cmap=\"binary\", vmax=2000)\n",
    "    axis(\"off\")\n",
    "    title(experiment_filename_1)\n",
    "\n",
    "    fig = figure()\n",
    "    scatter((peak_loc_map_2[1,whether_in(confined_place_cell_index_2, confined_place_cell_index_1)].-0.5).*bin_interval, (peak_loc_map_2[2,whether_in(confined_place_cell_index_2, confined_place_cell_index_1)].-0.5).*bin_interval, c=class_1[whether_in(confined_place_cell_index_1, confined_place_cell_index_2)], cmap=\"Dark2\", s=10, alpha=0.3)\n",
    "    # colorbar()\n",
    "    imshow(img_bg_end_2', cmap=\"binary\", vmax=2000)\n",
    "    axis(\"off\")\n",
    "\n",
    "\n",
    "    fig = figure()\n",
    "    scatter((peak_loc_map_1[1,whether_in(confined_place_cell_index_1, confined_place_cell_index_2)].-0.5).*bin_interval, (peak_loc_map_1[2,whether_in(confined_place_cell_index_1, confined_place_cell_index_2)].-0.5).*bin_interval, c=class_2[whether_in(confined_place_cell_index_2, confined_place_cell_index_1)], cmap=\"Dark2\", s=10, alpha=0.3)\n",
    "    # colorbar()\n",
    "    imshow(img_bg_end_1', cmap=\"binary\", vmax=2000)\n",
    "    axis(\"off\")\n",
    "    title(experiment_filename_1)\n",
    "\n",
    "    fig = figure()\n",
    "    scatter((peak_loc_map_2[1,whether_in(confined_place_cell_index_2, confined_place_cell_index_2)].-0.5).*bin_interval, (peak_loc_map_2[2,whether_in(confined_place_cell_index_2, confined_place_cell_index_2)].-0.5).*bin_interval, c=class_2[whether_in(confined_place_cell_index_2, confined_place_cell_index_2)], cmap=\"Dark2\", s=10, alpha=0.3)\n",
    "    # colorbar()\n",
    "    imshow(img_bg_end_2', cmap=\"binary\", vmax=2000)\n",
    "    axis(\"off\")\n",
    "\n",
    "    # histogram of peak location change\n",
    "\n",
    "    peak_shift = sqrt.(sum((peak_loc_map_1[:,whether_in(confined_place_cell_index_1, confined_place_cell_index_2)] .- peak_loc_map_2[:,whether_in(confined_place_cell_index_2, confined_place_cell_index_1)]) .^2, dims=1)[1,:])\n",
    "    pixel_size = 20*10^-3\n",
    "    peak_shift_mm = peak_shift *pixel_size*bin_interval\n",
    "\n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_1), \"chamber_geometry_$(experiment_filename_1).h5\"))\n",
    "    chamber_roi_1 = read(orientation_correction_file,\"chamber_roi\")\n",
    "    center_loc_1 = read(orientation_correction_file,\"center_loc\")\n",
    "    countour_array_1 = read(orientation_correction_file,\"countour_array\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "\n",
    "    peak_loc_map_1_rough = (peak_loc_map_1.-0.5).*bin_interval\n",
    "    peak_loc_map_2_rough = (peak_loc_map_2.-0.5).*bin_interval;\n",
    "\n",
    "\n",
    "    peak_distance_center_1_mm = distance_from(peak_loc_map_1_rough', center_loc_1) .*pixel_size\n",
    "    peak_distance_edge_1_mm,_ = distance_to_feature(collect(peak_loc_map_1_rough'), countour_array_1) .*pixel_size\n",
    "\n",
    "\n",
    "\n",
    "    # histogram of PF correlation\n",
    "\n",
    "    corr_trials_all = fill(NaN32, size(place_map_all_1,3))\n",
    "\n",
    "    for neuron_idx in intersect(valid_roi_1, valid_roi_2)\n",
    "        map_1 = place_map_all_1[:,:, neuron_idx]\n",
    "        map_2 = place_map_all_2[:,:, neuron_idx]\n",
    "        corr_trials_all[neuron_idx] = corr_2d(map_1, map_2)\n",
    "    end\n",
    "\n",
    "\n",
    "    # histogram of PV correlation\n",
    "    which_neuron = tel_place_cell_index\n",
    "    mask_valid_1 = isfinite.(place_map_all_1[:,:,confined_place_cell_index[1]])\n",
    "    mask_valid_2 = isfinite.(place_map_all_2[:,:,confined_place_cell_index[1]])\n",
    "    valid_pixels = findall(mask_valid_1 .* mask_valid_2)\n",
    "\n",
    "    mean_map_1= nanmean(place_map_all_1[valid_pixels, which_neuron], dims=1)[1,:]\n",
    "    std_map_1= nanstd(place_map_all_1[valid_pixels, which_neuron], dims=1)[1,:]\n",
    "    mean_map_2= nanmean(place_map_all_2[valid_pixels, which_neuron], dims=1)[1,:]\n",
    "    std_map_2= nanstd(place_map_all_2[valid_pixels, which_neuron], dims=1)[1,:]\n",
    "\n",
    "\n",
    "    corr_pv_all = fill(NaN32, length(valid_pixels))\n",
    "    corr_pv_all_normalized = fill(NaN32, length(valid_pixels))\n",
    "    for (i, which_pixel) in enumerate(valid_pixels)\n",
    "        pv1 = place_map_all_1[which_pixel, which_neuron]\n",
    "        pv2 = place_map_all_2[which_pixel, which_neuron]\n",
    "        pv1_normalized = (pv1 .- mean_map_1)./std_map_1\n",
    "        pv2_normalized = (pv2 .- mean_map_2)./std_map_2\n",
    "        corr_pv_all[i] = corr_nan(pv1, pv2)\n",
    "        corr_pv_all_normalized[i] = corr_nan(pv1_normalized, pv2_normalized)\n",
    "    end\n",
    "\n",
    "\n",
    "    pv_map = fill(NaN32, size(place_map_all_1[:,:,1]))\n",
    "    pv_map[valid_pixels] = corr_pv_all\n",
    "\n",
    "\n",
    "    pv_map_normalized = fill(NaN32, size(place_map_all_1[:,:,1]))\n",
    "    pv_map_normalized[valid_pixels] = corr_pv_all_normalized\n",
    "\n",
    "    h5open(joinpath(file_folder_1, \"compare_map_results_original.h5\"), \"r+\") do file\n",
    "        file[\"peak_shift_mm\"] = peak_shift_mm\n",
    "        file[\"peak_distance_center_1_mm\"] = peak_distance_center_1_mm\n",
    "        file[\"peak_distance_edge_1_mm\"] = peak_distance_edge_1_mm\n",
    "        file[\"corr_trials_all\"] = corr_trials_all\n",
    "        file[\"corr_pv_all\"] = corr_pv_all\n",
    "        file[\"corr_pv_all_normalized\"] = corr_pv_all_normalized\n",
    "        file[\"pv_map\"] = pv_map\n",
    "        file[\"pv_map_normalized\"] = pv_map_normalized\n",
    "    end;\n",
    "\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11c435-3186-4f7f-a11e-09e9e86dc377",
   "metadata": {},
   "source": [
    "# Correct for wrong normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c50e3-b04e-4034-a8ee-f1ad688d9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    \n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    \n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "\n",
    "    peak_loc_map_1 = read(compare_map_file,\"peak_loc_map_1\")\n",
    "    peak_loc_map_2 = read(compare_map_file,\"peak_loc_map_2\")\n",
    "    confined_place_cell_index_1 = read(compare_map_file,\"confined_place_cell_index_1\")\n",
    "    confined_place_cell_index_2 = read(compare_map_file,\"confined_place_cell_index_2\")\n",
    "    confined_place_cell_index = read(compare_map_file,\"confined_place_cell_index\")\n",
    "    tel_place_cell_index = read(compare_map_file,\"tel_place_cell_index\")\n",
    "    close(compare_map_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_1, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    close(file)\n",
    "\n",
    "\n",
    "    file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "    all_files = readdir(file_folder_2)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_2, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    close(file)\n",
    "\n",
    "    n_bins = size(place_map_all_1, 1)\n",
    "    \n",
    "    \n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_1), \"chamber_geometry_$(experiment_filename_1).h5\"))\n",
    "    global countour_array_1 = read(orientation_correction_file,\"countour_array\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "\n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_2), \"chamber_geometry_$(experiment_filename_2).h5\"))\n",
    "    global countour_array_2 = read(orientation_correction_file,\"countour_array\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "\n",
    "    img_bg_1 = h5open(ds_save_1, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"img_bg\")\n",
    "    end;\n",
    "\n",
    "    img_bg_2 = h5open(ds_save_2, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"img_bg\")\n",
    "    end;\n",
    "\n",
    "    global img_bg_end_1 = img_bg_1[:,:,end]\n",
    "    global img_bg_end_2 = img_bg_2[:,:,end]\n",
    "\n",
    "\n",
    "    global w = size(img_bg_end_1, 1)\n",
    "    global l = size(img_bg_end_1, 2)\n",
    "\n",
    "\n",
    "    \n",
    "    for_place_calculation_file = h5open(joinpath(data_path(ds_save_cy_1), \"for_place_calculation_chamber_geometry_$(experiment_filename_1)_n$(n_bins).h5\"))\n",
    "    x_bins = read(for_place_calculation_file,\"x_bins\")\n",
    "    y_bins = read(for_place_calculation_file,\"y_bins\")\n",
    "    close(for_place_calculation_file)\n",
    "\n",
    "    bin_interval = x_bins[2] - x_bins[1]\n",
    "\n",
    "    KMeans_features = cluster.KMeans(n_clusters = 6).fit(hcat(peak_loc_map_1'))\n",
    "    class_1 = KMeans_features.labels_;\n",
    "    KMeans_features = cluster.KMeans(n_clusters = 6).fit(hcat(peak_loc_map_2'))\n",
    "    class_2 = KMeans_features.labels_;\n",
    "\n",
    "    fig = figure()\n",
    "    scatter((peak_loc_map_1[1,whether_in(confined_place_cell_index_1, confined_place_cell_index_1)].-0.5).*bin_interval, (peak_loc_map_1[2,whether_in(confined_place_cell_index_1, confined_place_cell_index_1)].-0.5).*bin_interval, c=class_1[whether_in(confined_place_cell_index_1, confined_place_cell_index_1)], cmap=\"Dark2\", s=10, alpha=0.3)\n",
    "    # colorbar()\n",
    "    imshow(img_bg_end_1', cmap=\"binary\", vmax=2000)\n",
    "    axis(\"off\")\n",
    "    title(experiment_filename_1)\n",
    "\n",
    "    fig = figure()\n",
    "    scatter((peak_loc_map_2[1,whether_in(confined_place_cell_index_2, confined_place_cell_index_1)].-0.5).*bin_interval, (peak_loc_map_2[2,whether_in(confined_place_cell_index_2, confined_place_cell_index_1)].-0.5).*bin_interval, c=class_1[whether_in(confined_place_cell_index_1, confined_place_cell_index_2)], cmap=\"Dark2\", s=10, alpha=0.3)\n",
    "    # colorbar()\n",
    "    imshow(img_bg_end_2', cmap=\"binary\", vmax=2000)\n",
    "    axis(\"off\")\n",
    "\n",
    "\n",
    "    fig = figure()\n",
    "    scatter((peak_loc_map_1[1,whether_in(confined_place_cell_index_1, confined_place_cell_index_2)].-0.5).*bin_interval, (peak_loc_map_1[2,whether_in(confined_place_cell_index_1, confined_place_cell_index_2)].-0.5).*bin_interval, c=class_2[whether_in(confined_place_cell_index_2, confined_place_cell_index_1)], cmap=\"Dark2\", s=10, alpha=0.3)\n",
    "    # colorbar()\n",
    "    imshow(img_bg_end_1', cmap=\"binary\", vmax=2000)\n",
    "    axis(\"off\")\n",
    "    title(experiment_filename_1)\n",
    "\n",
    "    fig = figure()\n",
    "    scatter((peak_loc_map_2[1,whether_in(confined_place_cell_index_2, confined_place_cell_index_2)].-0.5).*bin_interval, (peak_loc_map_2[2,whether_in(confined_place_cell_index_2, confined_place_cell_index_2)].-0.5).*bin_interval, c=class_2[whether_in(confined_place_cell_index_2, confined_place_cell_index_2)], cmap=\"Dark2\", s=10, alpha=0.3)\n",
    "    # colorbar()\n",
    "    imshow(img_bg_end_2', cmap=\"binary\", vmax=2000)\n",
    "    axis(\"off\")\n",
    "\n",
    "    # histogram of peak location change\n",
    "\n",
    "    peak_shift = sqrt.(sum((peak_loc_map_1[:,whether_in(confined_place_cell_index_1, confined_place_cell_index_2)] .- peak_loc_map_2[:,whether_in(confined_place_cell_index_2, confined_place_cell_index_1)]) .^2, dims=1)[1,:])\n",
    "    pixel_size = 20*10^-3\n",
    "    peak_shift_mm = peak_shift *pixel_size*bin_interval\n",
    "\n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_1), \"chamber_geometry_$(experiment_filename_1).h5\"))\n",
    "    chamber_roi_1 = read(orientation_correction_file,\"chamber_roi\")\n",
    "    center_loc_1 = read(orientation_correction_file,\"center_loc\")\n",
    "    countour_array_1 = read(orientation_correction_file,\"countour_array\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "\n",
    "    peak_loc_map_1_rough = (peak_loc_map_1.-0.5).*bin_interval\n",
    "    peak_loc_map_2_rough = (peak_loc_map_2.-0.5).*bin_interval;\n",
    "\n",
    "\n",
    "    peak_distance_center_1_mm = distance_from(peak_loc_map_1_rough', center_loc_1) .*pixel_size\n",
    "    peak_distance_edge_1_mm,_ = distance_to_feature(collect(peak_loc_map_1_rough'), countour_array_1) .*pixel_size\n",
    "\n",
    "\n",
    "\n",
    "    # histogram of PF correlation\n",
    "\n",
    "    corr_trials_all = fill(NaN32, size(place_map_all_1,3))\n",
    "\n",
    "    for neuron_idx in intersect(valid_roi_1, valid_roi_2)\n",
    "        map_1 = place_map_all_1[:,:, neuron_idx]\n",
    "        map_2 = place_map_all_2[:,:, neuron_idx]\n",
    "        corr_trials_all[neuron_idx] = corr_2d_original(map_1, map_2)\n",
    "    end\n",
    "\n",
    "\n",
    "    # histogram of PV correlation\n",
    "    which_neuron = tel_place_cell_index\n",
    "    mask_valid_1 = isfinite.(place_map_all_1[:,:,confined_place_cell_index[1]])\n",
    "    mask_valid_2 = isfinite.(place_map_all_2[:,:,confined_place_cell_index[1]])\n",
    "    valid_pixels = findall(mask_valid_1 .* mask_valid_2)\n",
    "        \n",
    "    mean_map_1= numpy.nanmean(place_map_all_1[mask_valid_1, which_neuron], axis=0)\n",
    "    std_map_1= numpy.nanstd(place_map_all_1[mask_valid_1, which_neuron], axis=0)\n",
    "    mean_map_2= numpy.nanmean(place_map_all_2[mask_valid_2, which_neuron], axis=0)\n",
    "    std_map_2= numpy.nanstd(place_map_all_2[mask_valid_2, which_neuron], axis=0)\n",
    "\n",
    "    corr_pv_all = fill(NaN32, length(valid_pixels))\n",
    "    corr_pv_all_normalized = fill(NaN32, length(valid_pixels))\n",
    "    for (i, which_pixel) in enumerate(valid_pixels)\n",
    "        pv1 = place_map_all_1[which_pixel, which_neuron]\n",
    "        pv2 = place_map_all_2[which_pixel, which_neuron]\n",
    "        pv1_normalized = (pv1 .- mean_map_1)./std_map_1\n",
    "        pv2_normalized = (pv2 .- mean_map_2)./std_map_2\n",
    "        corr_pv_all[i] = corr_nan(pv1, pv2)\n",
    "        corr_pv_all_normalized[i] = corr_nan(pv1_normalized, pv2_normalized)\n",
    "    end\n",
    "\n",
    "\n",
    "    pv_map = fill(NaN32, size(place_map_all_1[:,:,1]))\n",
    "    pv_map[valid_pixels] = corr_pv_all\n",
    "\n",
    "\n",
    "    pv_map_normalized = fill(NaN32, size(place_map_all_1[:,:,1]))\n",
    "    pv_map_normalized[valid_pixels] = corr_pv_all_normalized\n",
    "    \n",
    "    figure()\n",
    "    imshow(pv_map_normalized)\n",
    "\n",
    "    h5open(joinpath(file_folder_1, \"compare_map_results_original.h5\"), \"r+\") do file\n",
    "        \n",
    "        delete_object(file, \"corr_trials_all\")\n",
    "        delete_object(file, \"corr_pv_all\")\n",
    "        delete_object(file, \"corr_pv_all_normalized\")\n",
    "        delete_object(file, \"pv_map\")\n",
    "        delete_object(file, \"pv_map_normalized\")\n",
    "        file[\"corr_trials_all\"] = corr_trials_all\n",
    "        file[\"corr_pv_all\"] = corr_pv_all\n",
    "        file[\"corr_pv_all_normalized\"] = corr_pv_all_normalized\n",
    "        file[\"pv_map\"] = pv_map\n",
    "        file[\"pv_map_normalized\"] = pv_map_normalized\n",
    "    end;\n",
    "\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7acba8-8024-4179-8052-c8cae96e35bc",
   "metadata": {},
   "source": [
    "# Correct for PV correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657db63-66a0-4a19-9ee9-08494dff5ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    \n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    \n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "\n",
    "    peak_loc_map_1 = read(compare_map_file,\"peak_loc_map_1\")\n",
    "    peak_loc_map_2 = read(compare_map_file,\"peak_loc_map_2\")\n",
    "    confined_place_cell_index_1 = read(compare_map_file,\"confined_place_cell_index_1\")\n",
    "    confined_place_cell_index_2 = read(compare_map_file,\"confined_place_cell_index_2\")\n",
    "    confined_place_cell_index = read(compare_map_file,\"confined_place_cell_index\")\n",
    "    tel_place_cell_index = read(compare_map_file,\"tel_place_cell_index\")\n",
    "    close(compare_map_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_1, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    close(file)\n",
    "\n",
    "\n",
    "    file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "    all_files = readdir(file_folder_2)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_2, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    close(file)\n",
    "\n",
    "\n",
    "\n",
    "    n_bins = size(place_map_all_1, 1)\n",
    "    n_x = size(place_map_all_1, 1)\n",
    "    n_y = size(place_map_all_1, 2) \n",
    "    n_neurons = size(place_map_all_1, 3)\n",
    "    map_baseline_1 = fill(NaN32, n_neurons)\n",
    "    map_baseline_2 = fill(NaN32, n_neurons);\n",
    "\n",
    "    for neuron_idx = tel_place_cell_index\n",
    "        cur_map = place_map_all_1[:, :, neuron_idx]\n",
    "        map_baseline_1[neuron_idx] = nanmean(cur_map[findall(cur_map .<= nanpctile(cur_map, 20))])\n",
    "        cur_map = place_map_all_2[:, :, neuron_idx]\n",
    "        map_baseline_2[neuron_idx] = nanmean(cur_map[findall(cur_map .<= nanpctile(cur_map, 20))])\n",
    "    end\n",
    "\n",
    "    pseudocount_1 = 10 .- map_baseline_1;\n",
    "    pseudocount_1[findall(pseudocount_1 .< 0)] .= 0; \n",
    "    pseudocount_2 = 10 .- map_baseline_2;\n",
    "    pseudocount_2[findall(pseudocount_2 .< 0)] .= 0; \n",
    "\n",
    "\n",
    "    place_activity_map_dFoF_1 = fill(NaN32, n_x, n_y, n_neurons)\n",
    "    place_activity_map_dFoF_2 = fill(NaN32, n_x, n_y, n_neurons)\n",
    "\n",
    "    PV_correlation_map = fill(NaN32, n_x, n_y)\n",
    "\n",
    "    for neuron_idx = tel_place_cell_index\n",
    "        cur_map = place_map_all_1[:, :, neuron_idx]\n",
    "        cur_map_dFoF = (cur_map .- map_baseline_1[neuron_idx]) ./ (map_baseline_1[neuron_idx] + pseudocount_1[neuron_idx])\n",
    "        place_activity_map_dFoF_1[:, :, neuron_idx] .= cur_map_dFoF\n",
    "\n",
    "        cur_map = place_map_all_2[:, :, neuron_idx]\n",
    "        cur_map_dFoF = (cur_map .- map_baseline_2[neuron_idx]) ./ (map_baseline_2[neuron_idx] + pseudocount_2[neuron_idx])\n",
    "        place_activity_map_dFoF_2[:, :, neuron_idx] .= cur_map_dFoF\n",
    "    end\n",
    "\n",
    "    for i_x = 1:n_x\n",
    "        for i_y = 1:n_y\n",
    "            PV_correlation_map[i_x, i_y] = nancor(place_activity_map_dFoF_1[i_x, i_y, tel_place_cell_index], place_activity_map_dFoF_2[i_x, i_y, tel_place_cell_index])\n",
    "        end\n",
    "    end\n",
    "\n",
    "\n",
    "    h5open(joinpath(file_folder_1, \"compare_map_results_original.h5\"), \"r+\") do file\n",
    "        file[\"pv_map_dFF\"] = PV_correlation_map\n",
    "    end;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17be65c-172a-40ae-8a84-eeee136e3c5f",
   "metadata": {},
   "source": [
    "# Correct for PF correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532a595-de6f-4977-a9bf-da3b3676922b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    \n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    \n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "\n",
    "    peak_loc_map_1 = read(compare_map_file,\"peak_loc_map_1\")\n",
    "    peak_loc_map_2 = read(compare_map_file,\"peak_loc_map_2\")\n",
    "    confined_place_cell_index_1 = read(compare_map_file,\"confined_place_cell_index_1\")\n",
    "    confined_place_cell_index_2 = read(compare_map_file,\"confined_place_cell_index_2\")\n",
    "    confined_place_cell_index = read(compare_map_file,\"confined_place_cell_index\")\n",
    "    tel_place_cell_index = read(compare_map_file,\"tel_place_cell_index\")\n",
    "    close(compare_map_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "    all_files = readdir(file_folder_1)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_1, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    close(file)\n",
    "\n",
    "\n",
    "    file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "    all_files = readdir(file_folder_2)\n",
    "    long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "    spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "    candidate_filename = long_name_files[spatial_info_index]\n",
    "    which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "    println(candidate_filename[which_file])\n",
    "    @assert(length(candidate_filename[which_file]) == 1)\n",
    "    save_file_name = candidate_filename[which_file][1]\n",
    "    info_filename = joinpath(file_folder_2, save_file_name)\n",
    "    file = h5open(info_filename, \"r\")\n",
    "    specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "    specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "    specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "    valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "    place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "    close(file)\n",
    "\n",
    "    n_bins = size(place_map_all_1, 1)\n",
    "    \n",
    "\n",
    "\n",
    "    corr_trials_all = fill(NaN32, size(place_map_all_1,3))\n",
    "\n",
    "    for neuron_idx in intersect(valid_roi_1, valid_roi_2)\n",
    "        map_1 = place_map_all_1[:,:, neuron_idx]\n",
    "        map_2 = place_map_all_2[:,:, neuron_idx]\n",
    "        corr_trials_all[neuron_idx] = corr_2d_original(map_1, map_2)\n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "    h5open(joinpath(file_folder_1, \"compare_map_results_original.h5\"), \"r+\") do file\n",
    "        \n",
    "        delete_object(file, \"corr_trials_all\")\n",
    "        file[\"corr_trials_all\"] = corr_trials_all\n",
    "\n",
    "    end;\n",
    "\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a090e-affa-4ad0-ad4b-c76243f459c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "    if haskey(compare_map_file, \"pv_map_normalized\")    \n",
    "        println(\"$which_data yes\")\n",
    "    else \n",
    "        println(\"$which_data no\")\n",
    "    end\n",
    "    close(compare_map_file)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90896c2-5570-4516-a333-5a99754e5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@showprogress for which_data = 1:length(data_info_all)\n",
    "    \n",
    "    data_info = data_info_all[which_data]\n",
    "\n",
    "    experiment_filename_1 = data_info[1]\n",
    "    server_1 = data_info[2]\n",
    "\n",
    "    experiment_filename_2 = data_info[3]\n",
    "    server_2 = data_info[4]\n",
    "\n",
    "    experimenter = data_info[5]\n",
    "\n",
    "    ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "    ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "    ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "    ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "    ds_save_analyzer_2 = Dataset(experiment_filename_2, analyzer, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "\n",
    "    \n",
    "    compare_map_file = h5open(joinpath(data_path(ds_save_cy_1), \"compare_map_results_original.h5\"))\n",
    "\n",
    "    place_cell_index_1 = read(compare_map_file,\"place_cell_index_1\")\n",
    "    place_cell_index_2 = read(compare_map_file,\"place_cell_index_2\")\n",
    "    close(compare_map_file)\n",
    "    \n",
    "    \n",
    "    println(length(place_cell_index_1))\n",
    "    println(length(place_cell_index_2))\n",
    "\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e0f4a-9f5a-4464-958a-6c764772a032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
