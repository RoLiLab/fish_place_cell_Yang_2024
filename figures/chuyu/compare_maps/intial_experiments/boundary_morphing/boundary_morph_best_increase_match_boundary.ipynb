{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12ee01-5172-434d-b3fd-b90c398c00b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!(@isdefined cleanup_hook) && IJulia.push_postexecute_hook(() -> (empty!(In); empty!(Out); GC.gc(true))); cleanup_hook = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b912c67-bb5e-4f76-8d1f-2c06cebd37ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ProgressMeter, PyCall, PyPlot, Images, HDF5,NaNStatistics, Statistics, DSP, Lasso, JLD2\n",
    "using _Data, _Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6153f-aad5-47c8-8f70-4072fb770f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pyimport numpy\n",
    "@pyimport sklearn.decomposition as decomposition\n",
    "@pyimport scipy.stats as stats\n",
    "@pyimport matplotlib.colors as mpl_colors\n",
    "@pyimport matplotlib.cm as cm \n",
    "@pyimport sklearn.cluster as cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e4cae-f0f6-4022-8ece-b654084e500c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(\"../../../functions/func_map.jl\")\n",
    "include(\"../../../functions/func_stat.jl\")\n",
    "include(\"../../../functions/func_data.jl\")\n",
    "include(\"../../../functions/func_plot.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96978e6d-377c-4d25-8a0f-c769dd66f9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_info_dict = load(\"/home/chuyu/Notebooks/project_place_cell/figures/chuyu/figure_data_info.jld2\")\n",
    "\n",
    "data_info_all = []\n",
    "for key in keys(data_info_dict)\n",
    "    if key == key == \"boundary_morphing\"\n",
    "    append!(data_info_all, data_info_dict[key])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5b847-6a6d-4074-a0bb-f1e09d17a846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b271fac-0308-47dd-a400-62d1365576bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_info_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca914f3-7034-49c4-8526-9d4540745251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = \"chuyu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c7a5c-3a1d-4c3b-a139-884f40ab2e32",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41f69d-90d1-401a-9669-eff9ac7d13b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function map_dots_from_boundary(chosen_point; x, y, k)\n",
    "    distance_from_chosen = distance_from(numpy.array(x), chosen_point)\n",
    "    weights = 1 ./(distance_from_chosen .^(k))\n",
    "    \n",
    "    mapped_point = sum(weights .* y)/sum(weights)\n",
    "    return mapped_point\n",
    "end\n",
    "\n",
    "function boundary_morphing_map(example_map, mask_pixels, mask_pixels_array_map, bin_interval)\n",
    "    mapped_map_sum = zeros(Float32, size(example_map))\n",
    "    mapped_map_count = zeros(Float32, size(example_map))\n",
    "    for i in 1:length(mask_pixels_array_map)\n",
    "        index = mask_pixels_array_map[i]./bin_interval\n",
    "        value = example_map[mask_pixels[i]]\n",
    "        mapped_map_sum[floor(Int32, index[1]-1):ceil(Int32, index[1]+1), floor(Int32, index[2]-1):ceil(Int32, index[2]+1)] .+= value\n",
    "        mapped_map_count[floor(Int32, index[1]-1):ceil(Int32, index[1]+1), floor(Int32, index[2]-1):ceil(Int32, index[2]+1)] .+= 1\n",
    "    end\n",
    "\n",
    "    mapped_map = mapped_map_sum./mapped_map_count;\n",
    "    return mapped_map\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0530229-36a9-4367-aac3-e97506b677ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "which_data = 1\n",
    "data_info = data_info_all[which_data]\n",
    "\n",
    "experiment_filename_1 = data_info[3]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "experiment_filename_2 = data_info[1]\n",
    "server_2 = data_info[4]\n",
    "\n",
    "experimenter = data_info[5]\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "    \n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_1), \"chamber_geometry_$(experiment_filename_1).h5\"))\n",
    "    chamber_roi_1 = read(orientation_correction_file,\"chamber_roi\")\n",
    "    countour_array_1 = read(orientation_correction_file,\"countour_array\")\n",
    "    center_loc_1 = read(orientation_correction_file,\"center_loc\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "\n",
    "    img_bg_1 = h5open(ds_save_1, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"img_bg\")\n",
    "    end;\n",
    "\n",
    "    img_bg_end_1 = img_bg_1[:,:,end]\n",
    "    w = size(img_bg_end_1, 1)\n",
    "    l = size(img_bg_end_1, 2)\n",
    "    # check how well they match\n",
    "    img_bg_end_1[chamber_roi_1.!=0].=NaN\n",
    "\n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_2), \"chamber_geometry_$(experiment_filename_2).h5\"))\n",
    "    chamber_roi_2 = read(orientation_correction_file,\"chamber_roi\")\n",
    "    countour_array_2 = read(orientation_correction_file,\"countour_array\")\n",
    "    center_loc_2 = read(orientation_correction_file,\"center_loc\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "    img_bg_2 = h5open(ds_save_2, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"img_bg\")\n",
    "    end;\n",
    "\n",
    "    img_bg_end_2 = img_bg_2[:,:,end]\n",
    "    w = size(img_bg_end_2, 1)\n",
    "    l = size(img_bg_end_2, 2)\n",
    "\n",
    "    # check how well they match\n",
    "    img_bg_end_2[chamber_roi_2.!=0].=NaN\n",
    "    nr_dots = maximum([size(countour_array_1,1), size(countour_array_2,1)])\n",
    "\n",
    "\n",
    "\n",
    "    x1 = numpy.interp(numpy.linspace(0, 1, nr_dots), numpy.linspace(0, 1, size(countour_array_1, 1)), countour_array_1[:,1])\n",
    "    x2 = numpy.interp(numpy.linspace(0, 1, nr_dots), numpy.linspace(0, 1, size(countour_array_1, 1)), countour_array_1[:,2])\n",
    "\n",
    "    y1 = numpy.interp(numpy.linspace(0, 1, nr_dots), numpy.linspace(0, 1, size(countour_array_2, 1)), countour_array_2[:,1])\n",
    "    y2 = numpy.interp(numpy.linspace(0, 1, nr_dots), numpy.linspace(0, 1, size(countour_array_2, 1)), countour_array_2[:,2]);\n",
    "\n",
    "\n",
    "    x = [[x1[i], x2[i]] for i in 1:nr_dots]\n",
    "    y = [[y1[i], y2[i]] for i in 1:nr_dots];\n",
    "\n",
    "    nr_roll_1 = 0\n",
    "    nr_roll_2 = 0\n",
    "\n",
    "    save_file_name = \"boundary_morph_matchboundary.h5\"\n",
    "\n",
    "    boundary_morph_filename = joinpath(data_path(ds_save_analyzer_1), save_file_name)\n",
    "    file_exist = HDF5.ishdf5(boundary_morph_filename)\n",
    "    if file_exist\n",
    "        file = h5open(boundary_morph_filename, \"r\")\n",
    "        if haskey(file, \"nr_roll_1\") && haskey(file, \"nr_roll_1\")\n",
    "            nr_roll_1 = read(file, \"nr_roll_1\")\n",
    "            nr_roll_2 = read(file, \"nr_roll_2\")\n",
    "        end\n",
    "        close(file)\n",
    "\n",
    "    end\n",
    "\n",
    "    x1 = numpy.roll(x1, nr_roll_1)\n",
    "    x2 = numpy.roll(x2, nr_roll_1);\n",
    "    y1 = numpy.roll(y1, nr_roll_2)\n",
    "    y2 = numpy.roll(y2, nr_roll_2);\n",
    "\n",
    "\n",
    "    x = [[x1[i], x2[i]] for i in 1:nr_dots]\n",
    "    y = [[y1[i], y2[i]] for i in 1:nr_dots];\n",
    "\n",
    "\n",
    "figure()\n",
    "scatter(first.(x), last.(x), c=1:length(x), s =3)\n",
    "imshow(img_bg_end_1', cmap=\"gray\", vmax=300)\n",
    "title(experiment_filename_1)\n",
    "\n",
    "figure()\n",
    "scatter(first.(y), last.(y), c=1:length(y), s =3)\n",
    "imshow(img_bg_end_2', cmap=\"gray\", vmax=300)\n",
    "title(experiment_filename_2)\n",
    "    \n",
    "chamber_dots = findall(chamber_roi_1.==1)\n",
    "chamber_dots_array = [[chamber_dots[i][1], chamber_dots[i][2]] for i in 1:length(chamber_dots)];\n",
    "\n",
    "chamber_dots_array_sample = chamber_dots_array[numpy.random.choice(1:length(chamber_dots_array), 1000, replace=false)]\n",
    "chamber_dots_array_reconstruct = map_dots_from_boundary.(chamber_dots_array_sample, x= x, y =x, k= 2);\n",
    "chamber_dots_array_map = map_dots_from_boundary.(chamber_dots_array_sample, x= x, y =y, k= 2);\n",
    "    \n",
    "err = norm.(chamber_dots_array_sample .- chamber_dots_array_reconstruct)\n",
    "# figure()\n",
    "# hist(err)\n",
    "\n",
    "\n",
    "file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "all_files = readdir(file_folder_1)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "println(candidate_filename[which_file])\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "info_filename = joinpath(file_folder_1, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "all_files = readdir(file_folder_2)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "println(candidate_filename[which_file])\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "info_filename = joinpath(file_folder_2, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "precise_loc = false\n",
    "save_file_name = \"compare_map_results_original.h5\"\n",
    "compare_filename = joinpath(data_path(ds_save_cy_2), save_file_name)\n",
    "file = h5open(compare_filename, \"r\")\n",
    "tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "peak_loc_map_1 = HDF5.readmmap(file[\"peak_loc_map_1\"])\n",
    "peak_loc_map_2 = HDF5.readmmap(file[\"peak_loc_map_2\"])\n",
    "if haskey(file, \"peak_loc_map_1_precise\")\n",
    "    precise_loc = true\n",
    "    peak_loc_map_1_precise  = HDF5.readmmap(file[\"peak_loc_map_1_precise\"])\n",
    "    peak_loc_map_2_precise  = HDF5.readmmap(file[\"peak_loc_map_2_precise\"])\n",
    "end\n",
    "close(file)\n",
    "    \n",
    "    \n",
    "chosen_neuron = tel_place_cell_index;\n",
    "which_neuron = chosen_neuron[1]\n",
    "    \n",
    "n_pos = size(place_map_all_1,1);\n",
    "for_place_calculation_file = h5open(joinpath(data_path(ds_save_cy_1), \"for_place_calculation_chamber_geometry_$(experiment_filename_1)_n$(n_pos).h5\"))\n",
    "x_bins = read(for_place_calculation_file,\"x_bins\")\n",
    "y_bins = read(for_place_calculation_file,\"y_bins\")\n",
    "mask_valid = read(for_place_calculation_file,\"mask_valid\")\n",
    "close(for_place_calculation_file)\n",
    "    \n",
    "bin_interval = x_bins[2] - x_bins[1]\n",
    "    \n",
    "mask_pixels = findall(mask_valid)\n",
    "mask_pixels_array = [[(mask_pixels[i][1] .-0.5)*bin_interval, (mask_pixels[i][2] .-0.5)*bin_interval] for i in 1:length(mask_pixels)]\n",
    "mask_pixels_array_map = map_dots_from_boundary.(mask_pixels_array, x= x, y =y, k= 2);\n",
    "\n",
    "figure()\n",
    "scatter(first.(mask_pixels_array), last.(mask_pixels_array), c=1:length(mask_pixels_array), cmap=\"Dark2\")\n",
    "scatter(first.(x), last.(x), c=1:length(x))\n",
    "# axis(\"square\")\n",
    "title(experiment_filename_1)\n",
    "figure()\n",
    "scatter(first.(mask_pixels_array_map), last.(mask_pixels_array_map), c=1:length(mask_pixels_array_map), cmap=\"Dark2\")\n",
    "scatter(first.(y), last.(y), c=1:length(y))\n",
    "axis(\"square\")\n",
    "title(experiment_filename_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1dc937-cc67-4251-a92a-37fab6eb9608",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_roi = intersect(valid_roi_1, valid_roi_2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb142992-37ee-4c73-8846-7579383f8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_offset = round.(Int32, (numpy.linspace(0, length(y1), 72)))\n",
    "\n",
    "corr_trials_all_degree = fill(NaN32, length(list_offset), length(chosen_neuron))\n",
    "mapped_map_all_degree = fill(NaN32, length(list_offset), size(place_map_all_1, 1), size(place_map_all_1,2), length(chosen_neuron))\n",
    "\n",
    "@showprogress for (i,offset) in enumerate(list_offset)\n",
    "\n",
    "    y1_roll = numpy.roll(y1, offset)\n",
    "    y2_roll = numpy.roll(y2, offset);\n",
    "\n",
    "    y_roll = [[y1_roll[i], y2_roll[i]] for i in 1:nr_dots];\n",
    "\n",
    "    mask_pixels_array_map = map_dots_from_boundary.(mask_pixels_array, x= x, y =y_roll, k= 2);\n",
    "\n",
    "    \n",
    "    mapped_map_all = fill(NaN32, size(place_map_all_1, 1), size(place_map_all_1,2), length(chosen_neuron))\n",
    "    for (i_neuron, which_neuron) in enumerate(chosen_neuron)\n",
    "        example_map = place_map_all_1[:,:,which_neuron]\n",
    "        mapped_map_all[:,:,i_neuron] = boundary_morphing_map(example_map, mask_pixels, mask_pixels_array_map, bin_interval)\n",
    "    end\n",
    "    \n",
    "    mapped_map_all_degree[i, :,:,:] .= mapped_map_all\n",
    "\n",
    "\n",
    "    corr_trials_all = fill(NaN32, length(chosen_neuron))\n",
    "\n",
    "    for (i_neuron, which_neuron) in enumerate(chosen_neuron)\n",
    "        map_1 = place_map_all_2[:,:, which_neuron]\n",
    "        map_2 = mapped_map_all[:,:, i_neuron]\n",
    "        corr_trials_all[i_neuron] = corr_2d(map_1, map_2)\n",
    "    end\n",
    "    \n",
    "    \n",
    "    corr_trials_all_degree[i, :] .= corr_trials_all\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d2531-d6e6-46c2-a9bb-736d2f433996",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_trials_all_degree_mean = nanmean(corr_trials_all_degree, dims=2)[:,1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626c2c9-75bf-41ac-8f6e-be5e45c73e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum(corr_trials_all_degree_mean) - corr_trials_all_degree_mean[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc42d7-e31f-4a73-9274-83ee3d98b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_all = fill(NaN32, sum(whether_in(chosen_neuron , valid_roi)), sum(whether_in(chosen_neuron , valid_roi)), length(list_offset))\n",
    "\n",
    "@showprogress for (i,offset) in enumerate(list_offset)\n",
    "    mapped_map_all = mapped_map_all_degree[i, :,:,whether_in(chosen_neuron , valid_roi)]\n",
    "    map1_reshape = reshape(mapped_map_all, size(mapped_map_all,1)*size(mapped_map_all,2), size(mapped_map_all, 3))\n",
    "    map2_reshape = reshape(place_map_all_2[:,:, intersect(chosen_neuron , valid_roi)], size(mapped_map_all,1)*size(mapped_map_all,2), size(mapped_map_all, 3));\n",
    "    corr_matrix_all[:,:,i] = corr_nan_matrix_2(map1_reshape, map2_reshape)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f1eb11-7adc-417c-9164-0d2451e63333",
   "metadata": {},
   "outputs": [],
   "source": [
    "    h5open(joinpath(data_path(ds_save_analyzer_1), \"boundary_morph_boundary_random.h5\"), \"w\") do file\n",
    "        file[\"corr_matrix_all\"] = corr_matrix_all\n",
    "\n",
    "    end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a436ce5-91ac-41c4-bd37-6f4c2cfdbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_corr_all_angle = fill(NaN32, size(corr_matrix_all, 3))\n",
    "for i in 1:size(corr_matrix_all, 3)\n",
    "    corr_matrix_this_angle = corr_matrix_all[:, :, i]\n",
    "    diag_corr_matrix_this_angle = [corr_matrix_this_angle[which_neuron, which_neuron] for which_neuron in 1:size(corr_matrix_this_angle, 1)]\n",
    "    mean_corr_all_angle[i] = nanmean(diag_corr_matrix_this_angle)\n",
    "end\n",
    "increase_original = maximum(mean_corr_all_angle) - mean_corr_all_angle[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96177eed-5757-47d2-8429-a973c4a04119",
   "metadata": {},
   "outputs": [],
   "source": [
    "increase_random_all = []\n",
    "@showprogress for i_random in 1:1000\n",
    "    random_idx = collect(1:size(corr_matrix_all, 1))\n",
    "    numpy.random.shuffle(random_idx)\n",
    "    \n",
    "    mean_corr_all_angle = fill(NaN32, size(corr_matrix_all, 3))\n",
    "    for i in 1:size(corr_matrix_all, 3)\n",
    "        corr_matrix_this_angle = corr_matrix_all[:, :, i]\n",
    "        corr_matrix_this_angle_random = corr_matrix_this_angle[:, random_idx]\n",
    "        diag_corr_matrix_this_angle = [corr_matrix_this_angle_random[which_neuron, which_neuron] for which_neuron in 1:size(corr_matrix_this_angle_random, 1)]\n",
    "        mean_corr_all_angle[i] = nanmean(diag_corr_matrix_this_angle)\n",
    "    end\n",
    "    append!(increase_random_all, maximum(mean_corr_all_angle) - mean_corr_all_angle[1])\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de8fb7-6b30-437a-bef1-4da0d924479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(increase_random_all, bins=100)\n",
    "axvline(increase_original, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b0775-a173-4338-9f42-6d291315bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = sum(increase_original.>increase_random_all)/length(increase_random_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a906fe-fc52-471c-abab-b964c19d06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5open(joinpath(data_path(ds_save_analyzer_1), \"boundary_morph_boundary_random.h5\"), \"r+\") do file\n",
    "    file[\"significance\"] = significance\n",
    "    file[\"increase_original\"] = increase_original\n",
    "    file[\"increase_random_all\"] = Float32.(increase_random_all)\n",
    "    \n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39f43b-fea2-47ff-8c0f-fd675442f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5open(joinpath(data_path(ds_save_analyzer_1), \"boundary_morph_boundary_random.h5\"), \"r+\") do file\n",
    "    file[\"mapped_map_all_degree\"] = mapped_map_all_degree\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad4ac52-213a-45ce-bc02-1d9f43aae4a6",
   "metadata": {},
   "source": [
    "# Process all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbb37c-52cc-4051-95d5-4535733edb58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for which_data = 1:length(data_info_all)\n",
    "data_info = data_info_all[which_data]\n",
    "\n",
    "experiment_filename_1 = data_info[3]\n",
    "server_1 = data_info[2]\n",
    "\n",
    "experiment_filename_2 = data_info[1]\n",
    "server_2 = data_info[4]\n",
    "\n",
    "experimenter = data_info[5]\n",
    "ds_save_1 = Dataset(experiment_filename_1, experimenter, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_cy_1 = Dataset(experiment_filename_1, \"chuyu\", gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "ds_save_analyzer_1 = Dataset(experiment_filename_1, analyzer, gethostname() == \"roli-$(server_1)\" ? \"/data\" : \"/nfs/data$(server_1)\")\n",
    "\n",
    "ds_save_2 = Dataset(experiment_filename_2, experimenter, gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\") # This example dataset is on roli-9, so the path is different depending on whether you're trying to access the file from roli-9\n",
    "ds_save_cy_2 = Dataset(experiment_filename_2, \"chuyu\", gethostname() == \"roli-$(server_2)\" ? \"/data\" : \"/nfs/data$(server_2)\")\n",
    "\n",
    "    \n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_1), \"chamber_geometry_$(experiment_filename_1).h5\"))\n",
    "    chamber_roi_1 = read(orientation_correction_file,\"chamber_roi\")\n",
    "    countour_array_1 = read(orientation_correction_file,\"countour_array\")\n",
    "    center_loc_1 = read(orientation_correction_file,\"center_loc\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "\n",
    "    img_bg_1 = h5open(ds_save_1, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"img_bg\")\n",
    "    end;\n",
    "\n",
    "    img_bg_end_1 = img_bg_1[:,:,end]\n",
    "    w = size(img_bg_end_1, 1)\n",
    "    l = size(img_bg_end_1, 2)\n",
    "    # check how well they match\n",
    "    img_bg_end_1[chamber_roi_1.!=0].=NaN\n",
    "\n",
    "    # orientation-corrected background image and chamber roi image\n",
    "    orientation_correction_file = h5open(joinpath(data_path(ds_save_cy_2), \"chamber_geometry_$(experiment_filename_2).h5\"))\n",
    "    chamber_roi_2 = read(orientation_correction_file,\"chamber_roi\")\n",
    "    countour_array_2 = read(orientation_correction_file,\"countour_array\")\n",
    "    center_loc_2 = read(orientation_correction_file,\"center_loc\")\n",
    "    close(orientation_correction_file)\n",
    "\n",
    "    img_bg_2 = h5open(ds_save_2, \"behavior.h5\"; raw = true) do file\n",
    "        read(file, \"img_bg\")\n",
    "    end;\n",
    "\n",
    "    img_bg_end_2 = img_bg_2[:,:,end]\n",
    "    w = size(img_bg_end_2, 1)\n",
    "    l = size(img_bg_end_2, 2)\n",
    "\n",
    "    # check how well they match\n",
    "    img_bg_end_2[chamber_roi_2.!=0].=NaN\n",
    "    nr_dots = maximum([size(countour_array_1,1), size(countour_array_2,1)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    x1 = numpy.interp(numpy.linspace(0, 1, nr_dots), numpy.linspace(0, 1, size(countour_array_1, 1)), countour_array_1[:,1])\n",
    "    x2 = numpy.interp(numpy.linspace(0, 1, nr_dots), numpy.linspace(0, 1, size(countour_array_1, 1)), countour_array_1[:,2])\n",
    "\n",
    "    y1 = numpy.interp(numpy.linspace(0, 1, nr_dots), numpy.linspace(0, 1, size(countour_array_2, 1)), countour_array_2[:,1])\n",
    "    y2 = numpy.interp(numpy.linspace(0, 1, nr_dots), numpy.linspace(0, 1, size(countour_array_2, 1)), countour_array_2[:,2]);\n",
    "\n",
    "\n",
    "    x = [[x1[i], x2[i]] for i in 1:nr_dots]\n",
    "    y = [[y1[i], y2[i]] for i in 1:nr_dots];\n",
    "\n",
    "    nr_roll_1 = 0\n",
    "    nr_roll_2 = 0\n",
    "\n",
    "    save_file_name = \"boundary_morph_matchboundary.h5\"\n",
    "\n",
    "    boundary_morph_filename = joinpath(data_path(ds_save_analyzer_1), save_file_name)\n",
    "    file_exist = HDF5.ishdf5(boundary_morph_filename)\n",
    "    if file_exist\n",
    "        file = h5open(boundary_morph_filename, \"r\")\n",
    "        if haskey(file, \"nr_roll_1\") && haskey(file, \"nr_roll_1\")\n",
    "            nr_roll_1 = read(file, \"nr_roll_1\")\n",
    "            nr_roll_2 = read(file, \"nr_roll_2\")\n",
    "        end\n",
    "        close(file)\n",
    "\n",
    "    end\n",
    "\n",
    "    x1 = numpy.roll(x1, nr_roll_1)\n",
    "    x2 = numpy.roll(x2, nr_roll_1);\n",
    "    y1 = numpy.roll(y1, nr_roll_2)\n",
    "    y2 = numpy.roll(y2, nr_roll_2);\n",
    "\n",
    "\n",
    "    x = [[x1[i], x2[i]] for i in 1:nr_dots]\n",
    "    y = [[y1[i], y2[i]] for i in 1:nr_dots];\n",
    "\n",
    "figure()\n",
    "scatter(first.(x), last.(x), c=1:length(x), s =3)\n",
    "imshow(img_bg_end_1', cmap=\"gray\", vmax=300)\n",
    "title(experiment_filename_1)\n",
    "\n",
    "figure()\n",
    "scatter(first.(y), last.(y), c=1:length(y), s =3)\n",
    "imshow(img_bg_end_2', cmap=\"gray\", vmax=300)\n",
    "title(experiment_filename_2)\n",
    "    \n",
    "chamber_dots = findall(chamber_roi_1.==1)\n",
    "chamber_dots_array = [[chamber_dots[i][1], chamber_dots[i][2]] for i in 1:length(chamber_dots)];\n",
    "\n",
    "chamber_dots_array_sample = chamber_dots_array[numpy.random.choice(1:length(chamber_dots_array), 1000, replace=false)]\n",
    "chamber_dots_array_reconstruct = map_dots_from_boundary.(chamber_dots_array_sample, x= x, y =x, k= 2);\n",
    "chamber_dots_array_map = map_dots_from_boundary.(chamber_dots_array_sample, x= x, y =y, k= 2);\n",
    "    \n",
    "err = norm.(chamber_dots_array_sample .- chamber_dots_array_reconstruct)\n",
    "# figure()\n",
    "# hist(err)\n",
    "\n",
    "\n",
    "file_folder_1 = joinpath(data_path(ds_save_cy_1), \"\")\n",
    "all_files = readdir(file_folder_1)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_1, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "println(candidate_filename[which_file])\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "info_filename = joinpath(file_folder_1, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "place_map_all_1 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "specificity_1 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_1 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_1 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "valid_roi_1 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "file_folder_2 = joinpath(data_path(ds_save_cy_2), \"\")\n",
    "all_files = readdir(file_folder_2)\n",
    "long_name_files = all_files[findall([length(all_files[i])>6 for i in 1:length(all_files)])]\n",
    "spatial_info_index = findall([long_name_files[i][1:6]==\"neuron\" for i in 1:length(long_name_files)])\n",
    "candidate_filename = long_name_files[spatial_info_index]\n",
    "which_file = [occursin(experiment_filename_2, candidate_filename[i])*occursin(\"A_dF\", candidate_filename[i]) for i in 1:length(candidate_filename)]\n",
    "println(candidate_filename[which_file])\n",
    "@assert(length(candidate_filename[which_file]) == 1)\n",
    "save_file_name = candidate_filename[which_file][1]\n",
    "info_filename = joinpath(file_folder_2, save_file_name)\n",
    "file = h5open(info_filename, \"r\")\n",
    "specificity_2 = HDF5.readmmap(file[\"specificity\"])\n",
    "specificity_population_z_2 = HDF5.readmmap(file[\"specificity_population_z\"])\n",
    "specificity_shuffle_z_2 = HDF5.readmmap(file[\"specificity_shuffle_z\"])\n",
    "valid_roi_2 = HDF5.readmmap(file[\"valid_neurons\"])\n",
    "place_map_all_2 = HDF5.readmmap(file[\"place_map_all\"])\n",
    "close(file)\n",
    "\n",
    "\n",
    "precise_loc = false\n",
    "save_file_name = \"compare_map_results_original.h5\"\n",
    "compare_filename = joinpath(data_path(ds_save_cy_2), save_file_name)\n",
    "file = h5open(compare_filename, \"r\")\n",
    "tel_place_cell_index = HDF5.readmmap(file[\"tel_place_cell_index\"])\n",
    "peak_loc_map_1 = HDF5.readmmap(file[\"peak_loc_map_1\"])\n",
    "peak_loc_map_2 = HDF5.readmmap(file[\"peak_loc_map_2\"])\n",
    "if haskey(file, \"peak_loc_map_1_precise\")\n",
    "    precise_loc = true\n",
    "    peak_loc_map_1_precise  = HDF5.readmmap(file[\"peak_loc_map_1_precise\"])\n",
    "    peak_loc_map_2_precise  = HDF5.readmmap(file[\"peak_loc_map_2_precise\"])\n",
    "end\n",
    "close(file)\n",
    "    \n",
    "    \n",
    "chosen_neuron = tel_place_cell_index;\n",
    "which_neuron = chosen_neuron[1]\n",
    "    \n",
    "n_pos = size(place_map_all_1,1);\n",
    "for_place_calculation_file = h5open(joinpath(data_path(ds_save_cy_1), \"for_place_calculation_chamber_geometry_$(experiment_filename_1)_n$(n_pos).h5\"))\n",
    "x_bins = read(for_place_calculation_file,\"x_bins\")\n",
    "y_bins = read(for_place_calculation_file,\"y_bins\")\n",
    "mask_valid = read(for_place_calculation_file,\"mask_valid\")\n",
    "close(for_place_calculation_file)\n",
    "    \n",
    "bin_interval = x_bins[2] - x_bins[1]\n",
    "    \n",
    "mask_pixels = findall(mask_valid)\n",
    "mask_pixels_array = [[(mask_pixels[i][1] .-0.5)*bin_interval, (mask_pixels[i][2] .-0.5)*bin_interval] for i in 1:length(mask_pixels)]\n",
    "mask_pixels_array_map = map_dots_from_boundary.(mask_pixels_array, x= x, y =y, k= 2);\n",
    "\n",
    "figure()\n",
    "scatter(first.(mask_pixels_array), last.(mask_pixels_array), c=1:length(mask_pixels_array), cmap=\"Dark2\")\n",
    "scatter(first.(x), last.(x), c=1:length(x))\n",
    "# axis(\"square\")\n",
    "title(experiment_filename_1)\n",
    "figure()\n",
    "scatter(first.(mask_pixels_array_map), last.(mask_pixels_array_map), c=1:length(mask_pixels_array_map), cmap=\"Dark2\")\n",
    "scatter(first.(y), last.(y), c=1:length(y))\n",
    "axis(\"square\")\n",
    "title(experiment_filename_2)\n",
    "\n",
    "\n",
    "valid_roi = intersect(valid_roi_1, valid_roi_2);\n",
    "\n",
    "\n",
    "list_offset = round.(Int32, (numpy.linspace(0, length(y1), 72)))\n",
    "\n",
    "corr_trials_all_degree = fill(NaN32, length(list_offset), length(chosen_neuron))\n",
    "mapped_map_all_degree = fill(NaN32, length(list_offset), size(place_map_all_1, 1), size(place_map_all_1,2), length(chosen_neuron))\n",
    "\n",
    "@showprogress for (i,offset) in enumerate(list_offset)\n",
    "\n",
    "    y1_roll = numpy.roll(y1, offset)\n",
    "    y2_roll = numpy.roll(y2, offset);\n",
    "\n",
    "    y_roll = [[y1_roll[i], y2_roll[i]] for i in 1:nr_dots];\n",
    "\n",
    "    mask_pixels_array_map = map_dots_from_boundary.(mask_pixels_array, x= x, y =y_roll, k= 2);\n",
    "\n",
    "    \n",
    "    mapped_map_all = fill(NaN32, size(place_map_all_1, 1), size(place_map_all_1,2), length(chosen_neuron))\n",
    "    for (i_neuron, which_neuron) in enumerate(chosen_neuron)\n",
    "        example_map = place_map_all_1[:,:,which_neuron]\n",
    "        mapped_map_all[:,:,i_neuron] = boundary_morphing_map(example_map, mask_pixels, mask_pixels_array_map, bin_interval)\n",
    "    end\n",
    "    \n",
    "    mapped_map_all_degree[i, :,:,:] .= mapped_map_all\n",
    "\n",
    "\n",
    "    corr_trials_all = fill(NaN32, length(chosen_neuron))\n",
    "\n",
    "    for (i_neuron, which_neuron) in enumerate(chosen_neuron)\n",
    "        map_1 = place_map_all_2[:,:, which_neuron]\n",
    "        map_2 = mapped_map_all[:,:, i_neuron]\n",
    "        corr_trials_all[i_neuron] = corr_2d(map_1, map_2)\n",
    "    end\n",
    "    \n",
    "    \n",
    "    corr_trials_all_degree[i, :] .= corr_trials_all\n",
    "end\n",
    "\n",
    "\n",
    "corr_matrix_all = fill(NaN32, sum(whether_in(chosen_neuron , valid_roi)), sum(whether_in(chosen_neuron , valid_roi)), length(list_offset))\n",
    "\n",
    "@showprogress for (i,offset) in enumerate(list_offset)\n",
    "    mapped_map_all = mapped_map_all_degree[i, :,:,whether_in(chosen_neuron , valid_roi)]\n",
    "    map1_reshape = reshape(mapped_map_all, size(mapped_map_all,1)*size(mapped_map_all,2), size(mapped_map_all, 3))\n",
    "    map2_reshape = reshape(place_map_all_2[:,:, intersect(chosen_neuron , valid_roi)], size(mapped_map_all,1)*size(mapped_map_all,2), size(mapped_map_all, 3));\n",
    "    corr_matrix_all[:,:,i] = corr_nan_matrix_2(map1_reshape, map2_reshape)\n",
    "end\n",
    "\n",
    "\n",
    "h5open(joinpath(data_path(ds_save_analyzer_1), \"boundary_morph_boundary_random.h5\"), \"w\") do file\n",
    "    file[\"corr_matrix_all\"] = corr_matrix_all\n",
    "    file[\"mapped_map_all_degree\"] = mapped_map_all_degree\n",
    "\n",
    "end;\n",
    "\n",
    "\n",
    "mean_corr_all_angle = fill(NaN32, size(corr_matrix_all, 3))\n",
    "for i in 1:size(corr_matrix_all, 3)\n",
    "    corr_matrix_this_angle = corr_matrix_all[:, :, i]\n",
    "    diag_corr_matrix_this_angle = [corr_matrix_this_angle[which_neuron, which_neuron] for which_neuron in 1:size(corr_matrix_this_angle, 1)]\n",
    "    mean_corr_all_angle[i] = nanmean(diag_corr_matrix_this_angle)\n",
    "end\n",
    "increase_original = maximum(mean_corr_all_angle) - mean_corr_all_angle[1]\n",
    "\n",
    "\n",
    "increase_random_all = []\n",
    "\n",
    "initial_corr_random_all = []\n",
    "best_corr_random_all = []\n",
    "\n",
    "@showprogress for i_random in 1:1000\n",
    "    random_idx = collect(1:size(corr_matrix_all, 1))\n",
    "    numpy.random.shuffle(random_idx)\n",
    "    \n",
    "    mean_corr_all_angle = fill(NaN32, size(corr_matrix_all, 3))\n",
    "    for i in 1:size(corr_matrix_all, 3)\n",
    "        corr_matrix_this_angle = corr_matrix_all[:, :, i]\n",
    "        corr_matrix_this_angle_random = corr_matrix_this_angle[:, random_idx]\n",
    "        diag_corr_matrix_this_angle = [corr_matrix_this_angle_random[which_neuron, which_neuron] for which_neuron in 1:size(corr_matrix_this_angle_random, 1)]\n",
    "        mean_corr_all_angle[i] = nanmean(diag_corr_matrix_this_angle)\n",
    "    end\n",
    "    append!(increase_random_all, maximum(mean_corr_all_angle) - mean_corr_all_angle[1])\n",
    "    \n",
    "    \n",
    "    append!(initial_corr_random_all, mean_corr_all_angle[1])\n",
    "    append!(best_corr_random_all, maximum(mean_corr_all_angle))\n",
    "    \n",
    "end\n",
    "\n",
    "figure()\n",
    "hist(increase_random_all, bins=100)\n",
    "axvline(increase_original, color=\"r\")\n",
    "title(experiment_filename_1)\n",
    "\n",
    "significance = sum(increase_original.>increase_random_all)/length(increase_random_all)\n",
    "\n",
    "h5open(joinpath(data_path(ds_save_analyzer_1), \"boundary_morph_boundary_random.h5\"), \"r+\") do file\n",
    "    file[\"significance\"] = significance\n",
    "    file[\"increase_original\"] = increase_original\n",
    "    file[\"increase_random_all\"] = Float32.(increase_random_all)\n",
    "    file[\"initial_corr_random_all\"] = Float32.(initial_corr_random_all)\n",
    "    file[\"best_corr_random_all\"] = Float32.(best_corr_random_all)\n",
    "    \n",
    "\n",
    "end;\n",
    "    \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de7e876-85a4-4f6f-8fc5-e58b2bb8cc10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
